{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrated Explanations for Binary Classification\n",
    "## Ablatioon Analysis\n",
    "\n",
    "Author: Tuwe Löfström (tuwe.lofstrom@ju.se)  \n",
    "Copyright 2023 Tuwe Löfström  \n",
    "License: BSD 3 clause\n",
    "Sources:\n",
    "1. [\"Calibrated Explanations: with Uncertainty Information and Counterfactuals\"](https://arxiv.org/abt/2305.02305) by [Helena Löfström](https://github.com/Moffran), [Tuwe Löfström](https://github.com/tuvelofstrom), Ulf Johansson, and Cecilia Sönströd.\n",
    "\n",
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Import results from the pickled result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_ablation.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "data_characteristics = {'colic': 60, \n",
    "                        'creditA': 43, \n",
    "                        'diabetes': 9, \n",
    "                        'german': 28, \n",
    "                        'haberman': 4, \n",
    "                        'haberman': 4,\n",
    "                        'heartC': 23,\n",
    "                        'heartH': 21,\n",
    "                        'heartS': 14,\n",
    "                        'hepati': 20,\n",
    "                        'iono': 34,\n",
    "                        'je4042': 9,\n",
    "                        'je4243': 9, \n",
    "                        'kc1': 22,\n",
    "                        'kc2': 22,\n",
    "                        'kc3': 40,\n",
    "                        'liver': 7,\n",
    "                        'pc1req': 9,\n",
    "                        'pc4': 38,\n",
    "                        'sonar': 61,\n",
    "                        'spect': 23,\n",
    "                        'spectf': 45,\n",
    "                        'transfusion': 5,\n",
    "                        'ttt': 28,\n",
    "                        'vote': 17,\n",
    "                        'wbc': 10,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Ablation analysis\n",
    "The ablation analysis is focused on evaluating how tth algorithm i affected by the calibration size and the number of percentiles sampled for numerical features. It is using a similar setup as the stability experiment, but with the following changes:\n",
    "* The number of percentiles sampled for numerical features is varied between 1, 2, 3 (default), 4, and 10.\n",
    "* The calibration size is varied between 10%, 20% and 40% of the data not used for testing.\n",
    "* Test size is fixed to 10% of the data. \n",
    "* Only one repetition per percentile and calibration size is used.\n",
    "\n",
    "Everything was run on 25 datasets. See the `Classification_Experiment_Ablation.py` for details on the experiment.\n",
    "\n",
    "The tabulated results are the mean variance of the ablation measured over per calibration size or percentile sampling. The variance is measured per instance and computed over the runs having the same calibration size/percentile sampling on the feature importance weight of the most influential feature, defined as the feature most often having highest absolute feature importance weight. The average variance is computed over the entire test set. The most influential feature is used since it is the feature that is most likely to be used in a decision but also the feature with the greatest expected variation (as a consequence of the weights having the highest absolute values). \n",
    "\n",
    "#### 3.1 Calibration Size\n",
    "First out is a table with results per calibration size. Since different sampling sizes may result in different results for numerical features, the mean variance is only expected to be 0 for categorical-only datasets. The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & xGB & xGB & xGB & xGB & xGB & xGB & RF & RF & RF & RF & RF & RF \\\\\n",
      "Calibration Size & 0.1 & 0.2 & 0.4 & 0.1 & 0.2 & 0.4 & 0.1 & 0.2 & 0.4 & 0.1 & 0.2 & 0.4\\\\\n",
      "Dataset & CE & CE & CE & CCE & CCE & CCE & CE & CE & CE & CCE & CCE & CCE \\\\\n",
      "\\hline\n",
      "haberman & 1.5e-03 & 2.4e-03 & 1.9e-03 & 1.5e-03 & 2.4e-03 & 1.9e-03 & 7.3e-04 & 2.1e-03 & 2.1e-03 & 7.3e-04 & 2.1e-03 & 2.1e-03 \\\\\n",
      "heartC & 1.3e-06 & 4.0e-05 & 5.1e-05 & 1.3e-06 & 4.0e-05 & 5.1e-05 & 1.2e-05 & 3.8e-05 & 3.4e-05 & 1.2e-05 & 3.8e-05 & 3.4e-05 \\\\\n",
      "heartH & 9.1e-05 & 8.8e-05 & 7.9e-05 & 9.1e-05 & 8.8e-05 & 7.9e-05 & 3.7e-07 & 9.7e-06 & 7.2e-06 & 3.7e-07 & 9.7e-06 & 7.2e-06 \\\\\n",
      "heartS & 1.5e-04 & 2.2e-04 & 2.1e-04 & 1.5e-04 & 2.2e-04 & 2.1e-04 & 1.3e-05 & 2.3e-05 & 1.5e-05 & 1.3e-05 & 2.3e-05 & 1.5e-05 \\\\\n",
      "hepati & 7.6e-05 & 4.6e-05 & 3.6e-05 & 7.6e-05 & 4.6e-05 & 3.6e-05 & 7.0e-05 & 5.4e-05 & 4.9e-05 & 7.0e-05 & 5.4e-05 & 4.9e-05 \\\\\n",
      "je4243 & 9.8e-05 & 2.8e-04 & 2.3e-04 & 9.8e-05 & 2.8e-04 & 2.3e-04 & 3.1e-04 & 4.9e-04 & 3.9e-04 & 3.1e-04 & 4.9e-04 & 3.9e-04 \\\\\n",
      "kc2 & 1.2e-04 & 1.7e-04 & 2.0e-04 & 1.2e-04 & 1.7e-04 & 2.0e-04 & 2.7e-05 & 4.0e-05 & 3.2e-05 & 2.7e-05 & 4.0e-05 & 3.2e-05 \\\\\n",
      "kc3 & 4.4e-05 & 2.9e-05 & 3.3e-05 & 4.4e-05 & 2.9e-05 & 3.3e-05 & 1.4e-05 & 1.7e-05 & 3.2e-05 & 1.4e-05 & 1.7e-05 & 3.2e-05 \\\\\n",
      "pc1req & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 7.0e-35 & 1.2e-34 & 1.3e-34 & 7.0e-35 & 1.2e-34 & 1.3e-34 \\\\\n",
      "spect & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 1.1e-34 & 1.9e-34 & 1.3e-34 & 1.1e-34 & 1.9e-34 & 1.3e-34 \\\\\n",
      "transfusion & 5.9e-04 & 5.5e-04 & 5.0e-04 & 5.9e-04 & 5.5e-04 & 5.0e-04 & 3.6e-04 & 3.1e-04 & 2.7e-04 & 3.6e-04 & 3.1e-04 & 2.7e-04 \\\\\n",
      "vote & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 0.0e+00 & 1.7e-35 & 8.3e-36 & 1.9e-35 & 1.7e-35 & 8.3e-36 & 1.9e-35 \\\\\n",
      "wbc & 2.5e-04 & 5.6e-04 & 7.4e-04 & 2.5e-04 & 5.6e-04 & 7.4e-04 & 3.5e-04 & 6.1e-04 & 6.1e-04 & 3.5e-04 & 6.1e-04 & 6.1e-04 \\\\\n",
      "\\hline\n",
      "Average & 2.3e-04 & 3.4e-04 & 3.1e-04 & 2.3e-04 & 3.4e-04 & 3.1e-04 & 1.5e-04 & 2.8e-04 & 2.7e-04 & 1.5e-04 & 2.8e-04 & 2.7e-04 \\\\\n"
     ]
    }
   ],
   "source": [
    "ranking = {}\n",
    "val = {}\n",
    "average_results = {}\n",
    "n = results['test_size']\n",
    "cal_sizes = results['calibration_sizes']\n",
    "perc_samples = results['sample_percentiles']\n",
    "\n",
    "for a in ['xGB', 'RF']:\n",
    "    for cal in cal_sizes:\n",
    "        average_results[a+'_'+str(cal)+'_ce'] = []\n",
    "        average_results[a+'_'+str(cal)+'_cce'] = []\n",
    "\n",
    "print(' & xGB & xGB & xGB & xGB & xGB & xGB & RF & RF & RF & RF & RF & RF \\\\\\\\\\nCalibration Size', end='')\n",
    "for i in range(2):\n",
    "    for key in ['ce', 'cce']:  \n",
    "        for cal in cal_sizes:\n",
    "            print(f' & {cal}',end='')\n",
    "print('\\\\\\\\')\n",
    "print('Dataset & CE & CE & CE & CCE & CCE & CCE & CE & CE & CE & CCE & CCE & CCE \\\\\\\\\\n\\\\hline')\n",
    "for d in np.sort([k for k in results.keys()]):\n",
    "    if d in ['test_size', 'calibration_sizes', 'sample_percentiles']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    for a in results[d]:\n",
    "        ablation = results[d][a]['ablation']\n",
    "        \n",
    "        for key in ['ce', 'cce']:    \n",
    "            n = len(ablation[key][cal_sizes[0]][str(perc_samples[0])][0])\n",
    "            ranks = []\n",
    "            values = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                value = []\n",
    "                for cal in ablation[key]:\n",
    "                    for p in ablation[key][cal]:\n",
    "                        rank.append(np.argsort(np.abs(ablation[key][cal][p][0][j]['predict']))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "                values.append(value)\n",
    "            ranking[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            # print(ranking[key])\n",
    "            \n",
    "            value = []\n",
    "            for cal in ablation[key]: \n",
    "                print(' & ', end='')  \n",
    "                for j in range(n):\n",
    "                    values = [ablation[key][cal][p][0][j]['predict'][ranking[key][j][0]] for p in ablation[key][cal]]\n",
    "                    value.append([np.mean(values), np.var(values)])\n",
    "                val[key] = value \n",
    "\n",
    "                res = np.mean([t[1] for t in val[key]])\n",
    "                average_results[a+'_'+str(cal)+'_'+key].append(res)\n",
    "                print(f'{res:.1e}',end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']:  \n",
    "        for cal in ablation[key]:\n",
    "            print(' & ', end='')\n",
    "            print(f'{np.mean(average_results[a+\"_\"+str(cal)+\"_\"+key]):.1e}',end='')\n",
    "print(' \\\\\\\\')\n",
    "# df = pd.DataFrame.from_dict(average_results, orient='index')\n",
    "# display (df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most interesting observation from the results above is that difference in mean variance is fairly low between the different calibration sizes. This indicates that the calibration size does not have a large impact on the feature importance weights. In fact, a smaller calibration set even tend to have a lower mean variance.\n",
    "#### 3.2 Percentile Sampling\n",
    "Below are the results per percentile sampling. The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & xGB & xGB & xGB & xGB & xGB & xGB & RF & RF & RF & RF & RF & RF \\\\\n",
      "Sample Size & 1 & 2 & 3 & 4 & 9 & 1 & 2 & 3 & 4 & 9 & 1 & 2 & 3 & 4 & 9 & 1 & 2 & 3 & 4 & 9\\\\\n",
      "Dataset & CE & CE & CE & CCE & CCE & CCE & CE & CE & CE & CCE & CCE & CCE \\\\\n",
      "\\hline\n",
      "haberman & 0.00084 & 0.00084 & 0.00084 & 0.00084 & 0.00084 & 0.00084 & 0.00084 & 0.00084 & 0.00084 & 0.00084 & 0.002 & 0.002 & 0.002 & 0.002 & 0.002 & 0.002 & 0.002 & 0.002 & 0.002 & 0.002 \\\\\n",
      "heartC & 7.3e-05 & 7.3e-05 & 7.3e-05 & 7.3e-05 & 7.3e-05 & 7.3e-05 & 7.3e-05 & 7.3e-05 & 7.3e-05 & 7.3e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 & 2.6e-05 \\\\\n",
      "heartH & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 2e-06 & 2e-06 & 2e-06 & 2e-06 & 2e-06 & 2e-06 & 2e-06 & 2e-06 & 2e-06 & 2e-06 \\\\\n",
      "heartS & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 7.5e-07 & 7.5e-07 & 7.5e-07 & 7.5e-07 & 7.5e-07 & 7.5e-07 & 7.5e-07 & 7.5e-07 & 7.5e-07 & 7.5e-07 \\\\\n",
      "hepati & 1.7e-05 & 1.7e-05 & 1.7e-05 & 1.7e-05 & 1.7e-05 & 1.7e-05 & 1.7e-05 & 1.7e-05 & 1.7e-05 & 1.7e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 \\\\\n",
      "je4243 & 0.00011 & 0.00011 & 0.00011 & 0.00011 & 0.00011 & 0.00011 & 0.00011 & 0.00011 & 0.00011 & 0.00011 & 0.0002 & 0.0002 & 0.0002 & 0.0002 & 0.0002 & 0.0002 & 0.0002 & 0.0002 & 0.0002 & 0.0002 \\\\\n",
      "kc2 & 0.00028 & 0.00028 & 0.00028 & 0.00028 & 0.00028 & 0.00028 & 0.00028 & 0.00028 & 0.00028 & 0.00028 & 1.8e-05 & 1.8e-05 & 1.8e-05 & 1.8e-05 & 1.8e-05 & 1.8e-05 & 1.8e-05 & 1.8e-05 & 1.8e-05 & 1.8e-05 \\\\\n",
      "kc3 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 4e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 & 6.1e-05 \\\\\n",
      "pc1req & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 1.4e-34 & 1.4e-34 & 1.4e-34 & 1.4e-34 & 1.4e-34 & 1.4e-34 & 1.4e-34 & 1.4e-34 & 1.4e-34 & 1.4e-34 \\\\\n",
      "spect & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 \\\\\n",
      "transfusion & 0.00039 & 0.00039 & 0.00039 & 0.00039 & 0.00039 & 0.00039 & 0.00039 & 0.00039 & 0.00039 & 0.00039 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 & 0.00019 \\\\\n",
      "vote & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 0.0 & 4.2e-35 & 4.2e-35 & 4.2e-35 & 4.2e-35 & 4.2e-35 & 4.2e-35 & 4.2e-35 & 4.2e-35 & 4.2e-35 & 4.2e-35 \\\\\n",
      "wbc & 0.0011 & 0.0011 & 0.0011 & 0.0011 & 0.0011 & 0.0011 & 0.0011 & 0.0011 & 0.0011 & 0.0011 & 0.00061 & 0.00061 & 0.00061 & 0.00061 & 0.00061 & 0.00061 & 0.00061 & 0.00061 & 0.00061 & 0.00061 \\\\\n",
      "\\hline\n",
      "Average & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 & 0.00024 \\\\\n"
     ]
    }
   ],
   "source": [
    "ranking = {}\n",
    "val = {}\n",
    "average_results = {}\n",
    "n = results['test_size']\n",
    "cal_sizes = results['calibration_sizes']\n",
    "perc_samples = results['sample_percentiles']\n",
    "\n",
    "for a in ['xGB', 'RF']:\n",
    "    for p in perc_samples:\n",
    "        average_results[a+'_'+str(p)+'_ce'] = []\n",
    "        average_results[a+'_'+str(p)+'_cce'] = []\n",
    "\n",
    "print(' & xGB & xGB & xGB & xGB & xGB & xGB & RF & RF & RF & RF & RF & RF \\\\\\\\\\nSample Size', end='')\n",
    "for i in range(2):\n",
    "    for key in ['ce', 'cce']:  \n",
    "        for p in perc_samples:\n",
    "            print(f' & {str(len(p))}',end='')\n",
    "print('\\\\\\\\')\n",
    "print('Dataset & CE & CE & CE & CCE & CCE & CCE & CE & CE & CE & CCE & CCE & CCE \\\\\\\\\\n\\\\hline')\n",
    "for d in np.sort([k for k in results.keys()]):\n",
    "    if d in ['test_size', 'calibration_sizes', 'sample_percentiles']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    for a in results[d]:\n",
    "        ablation = results[d][a]['ablation']\n",
    "        \n",
    "        for key in ['ce', 'cce']:    \n",
    "            n = len(ablation[key][cal_sizes[0]][str(perc_samples[0])][0])\n",
    "            ranks = []\n",
    "            values = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                value = []\n",
    "                for cal in ablation[key]:\n",
    "                    for p in ablation[key][cal]:\n",
    "                        rank.append(np.argsort(np.abs(ablation[key][cal][p][0][j]['predict']))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "                values.append(value)\n",
    "            ranking[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            # print(ranking[key])\n",
    "            \n",
    "            value = []\n",
    "            for p in ablation[key][cal]: \n",
    "                print(' & ', end='')  \n",
    "                for j in range(n):\n",
    "                    values = [ablation[key][cal][p][0][j]['predict'][ranking[key][j][0]] for p in ablation[key][cal]]\n",
    "                    value.append([np.mean(values), np.var(values)])\n",
    "                val[key] = value \n",
    "\n",
    "                res = np.mean([t[1] for t in val[key]]) # mean of instance variance\n",
    "                average_results[a+'_'+p+'_'+key].append(res)\n",
    "                print(f'{res:.2}',end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']:  \n",
    "        for p in ablation[key][cal]:\n",
    "            print(' & ', end='')\n",
    "            print(f'{np.mean(average_results[a+\"_\"+p+\"_\"+key]):.2}',end='')\n",
    "print(' \\\\\\\\')\n",
    "# df = pd.DataFrame.from_dict(average_results, orient='index')\n",
    "# display (df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if there is some difference in the mean variance when varying the percentile sampling, the difference can be attributed only to the difference in underlying ML algorithm. This indicates that the percentile sampling does not have a large impact on the feature importance weights. \n",
    "\n",
    "### 4 Computing time\n",
    "Now, lets look at the runtime taken to compute the explanations. The tabulated runtimes are the average time in seconds per instance. First, detailed results per calibration size AND percentile sampling is shown, then results aggregated per calibration size and percentile sampling are shown separately. The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime & xGB_ce_0.1_1 & xGB_ce_0.1_2 & xGB_ce_0.1_3 & xGB_ce_0.1_4 & xGB_ce_0.1_9 & xGB_ce_0.2_1 & xGB_ce_0.2_2 & xGB_ce_0.2_3 & xGB_ce_0.2_4 & xGB_ce_0.2_9 & xGB_ce_0.4_1 & xGB_ce_0.4_2 & xGB_ce_0.4_3 & xGB_ce_0.4_4 & xGB_ce_0.4_9 & xGB_cce_0.1_1 & xGB_cce_0.1_2 & xGB_cce_0.1_3 & xGB_cce_0.1_4 & xGB_cce_0.1_9 & xGB_cce_0.2_1 & xGB_cce_0.2_2 & xGB_cce_0.2_3 & xGB_cce_0.2_4 & xGB_cce_0.2_9 & xGB_cce_0.4_1 & xGB_cce_0.4_2 & xGB_cce_0.4_3 & xGB_cce_0.4_4 & xGB_cce_0.4_9 & RF_ce_0.1_1 & RF_ce_0.1_2 & RF_ce_0.1_3 & RF_ce_0.1_4 & RF_ce_0.1_9 & RF_ce_0.2_1 & RF_ce_0.2_2 & RF_ce_0.2_3 & RF_ce_0.2_4 & RF_ce_0.2_9 & RF_ce_0.4_1 & RF_ce_0.4_2 & RF_ce_0.4_3 & RF_ce_0.4_4 & RF_ce_0.4_9 & RF_cce_0.1_1 & RF_cce_0.1_2 & RF_cce_0.1_3 & RF_cce_0.1_4 & RF_cce_0.1_9 & RF_cce_0.2_1 & RF_cce_0.2_2 & RF_cce_0.2_3 & RF_cce_0.2_4 & RF_cce_0.2_9 & RF_cce_0.4_1 & RF_cce_0.4_2 & RF_cce_0.4_3 & RF_cce_0.4_4 & RF_cce_0.4_9 &  \\\\\n",
      "\\hline\n",
      "haberman & 0.02 & 0.04 & 0.05 & 0.07 & 0.15 & 0.02 & 0.04 & 0.05 & 0.07 & 0.15 & 0.02 & 0.04 & 0.06 & 0.07 & 0.15 & 0.02 & 0.04 & 0.05 & 0.07 & 0.15 & 0.02 & 0.04 & 0.06 & 0.07 & 0.15 & 0.02 & 0.04 & 0.06 & 0.07 & 0.15 & 0.05 & 0.09 & 0.13 & 0.18 & 0.39 & 0.05 & 0.09 & 0.14 & 0.18 & 0.38 & 0.05 & 0.09 & 0.13 & 0.18 & 0.38 & 0.05 & 0.09 & 0.13 & 0.17 & 0.39 & 0.05 & 0.09 & 0.13 & 0.18 & 0.38 & 0.05 & 0.09 & 0.13 & 0.17 & 0.38 & 4 \\\\\n",
      "heartC & 0.12 & 0.15 & 0.18 & 0.21 & 0.34 & 0.14 & 0.16 & 0.19 & 0.22 & 0.35 & 0.14 & 0.17 & 0.20 & 0.22 & 0.36 & 0.14 & 0.17 & 0.20 & 0.24 & 0.41 & 0.15 & 0.18 & 0.22 & 0.26 & 0.44 & 0.16 & 0.19 & 0.23 & 0.27 & 0.46 & 0.32 & 0.39 & 0.47 & 0.53 & 0.85 & 0.35 & 0.40 & 0.47 & 0.56 & 0.86 & 0.34 & 0.41 & 0.47 & 0.55 & 0.89 & 0.34 & 0.44 & 0.53 & 0.61 & 1.08 & 0.37 & 0.45 & 0.54 & 0.62 & 1.08 & 0.38 & 0.47 & 0.56 & 0.68 & 1.12 & 23 \\\\\n",
      "heartH & 0.10 & 0.13 & 0.15 & 0.18 & 0.30 & 0.12 & 0.15 & 0.17 & 0.20 & 0.31 & 0.12 & 0.15 & 0.17 & 0.20 & 0.32 & 0.11 & 0.14 & 0.18 & 0.20 & 0.36 & 0.13 & 0.16 & 0.20 & 0.23 & 0.40 & 0.13 & 0.17 & 0.20 & 0.24 & 0.43 & 0.27 & 0.33 & 0.40 & 0.45 & 0.77 & 0.29 & 0.36 & 0.42 & 0.49 & 0.79 & 0.29 & 0.36 & 0.43 & 0.47 & 0.79 & 0.29 & 0.37 & 0.45 & 0.53 & 0.90 & 0.32 & 0.40 & 0.50 & 0.58 & 1.01 & 0.31 & 0.42 & 0.49 & 0.58 & 1.04 & 21 \\\\\n",
      "heartS & 0.09 & 0.12 & 0.15 & 0.18 & 0.31 & 0.10 & 0.13 & 0.15 & 0.18 & 0.32 & 0.10 & 0.13 & 0.16 & 0.18 & 0.32 & 0.10 & 0.13 & 0.18 & 0.21 & 0.40 & 0.11 & 0.15 & 0.18 & 0.22 & 0.39 & 0.11 & 0.15 & 0.19 & 0.23 & 0.42 & 0.23 & 0.30 & 0.37 & 0.44 & 0.77 & 0.24 & 0.31 & 0.38 & 0.45 & 0.77 & 0.24 & 0.31 & 0.37 & 0.44 & 0.78 & 0.25 & 0.35 & 0.44 & 0.53 & 0.98 & 0.26 & 0.35 & 0.45 & 0.53 & 0.95 & 0.27 & 0.36 & 0.45 & 0.54 & 1.00 & 14 \\\\\n",
      "hepati & 0.10 & 0.13 & 0.16 & 0.19 & 0.35 & 0.12 & 0.15 & 0.18 & 0.21 & 0.36 & 0.12 & 0.15 & 0.19 & 0.22 & 0.38 & 0.11 & 0.15 & 0.18 & 0.24 & 0.42 & 0.13 & 0.17 & 0.21 & 0.25 & 0.44 & 0.13 & 0.18 & 0.22 & 0.26 & 0.47 & 0.26 & 0.35 & 0.41 & 0.53 & 0.92 & 0.30 & 0.37 & 0.44 & 0.49 & 0.89 & 0.28 & 0.35 & 0.44 & 0.53 & 0.93 & 0.28 & 0.38 & 0.48 & 0.60 & 1.09 & 0.32 & 0.43 & 0.51 & 0.59 & 1.07 & 0.30 & 0.42 & 0.52 & 0.63 & 1.14 & 20 \\\\\n",
      "je4243 & 0.06 & 0.09 & 0.13 & 0.17 & 0.35 & 0.06 & 0.10 & 0.13 & 0.17 & 0.37 & 0.07 & 0.10 & 0.15 & 0.18 & 0.38 & 0.06 & 0.10 & 0.14 & 0.17 & 0.36 & 0.06 & 0.10 & 0.14 & 0.17 & 0.35 & 0.07 & 0.11 & 0.15 & 0.18 & 0.38 & 0.15 & 0.25 & 0.34 & 0.43 & 0.96 & 0.15 & 0.26 & 0.35 & 0.46 & 0.94 & 0.16 & 0.26 & 0.36 & 0.45 & 0.94 & 0.15 & 0.24 & 0.34 & 0.43 & 0.96 & 0.15 & 0.26 & 0.35 & 0.45 & 0.96 & 0.16 & 0.26 & 0.35 & 0.44 & 0.94 & 9 \\\\\n",
      "kc2 & 0.12 & 0.23 & 0.34 & 0.45 & 0.96 & 0.13 & 0.25 & 0.35 & 0.45 & 0.99 & 0.15 & 0.26 & 0.37 & 0.47 & 1.00 & 0.15 & 0.29 & 0.41 & 0.55 & 1.18 & 0.17 & 0.30 & 0.44 & 0.58 & 1.22 & 0.19 & 0.34 & 0.49 & 0.63 & 1.30 & 0.30 & 0.57 & 0.83 & 1.09 & 2.46 & 0.33 & 0.58 & 0.88 & 1.14 & 2.44 & 0.33 & 0.59 & 0.86 & 1.12 & 2.43 & 0.36 & 0.70 & 1.02 & 1.33 & 3.42 & 0.39 & 0.73 & 1.13 & 1.44 & 2.97 & 0.42 & 0.78 & 1.12 & 1.48 & 3.29 & 22 \\\\\n",
      "kc3 & 0.24 & 0.46 & 0.66 & 0.86 & 1.85 & 0.25 & 0.46 & 0.66 & 0.87 & 1.82 & 0.26 & 0.46 & 0.67 & 0.85 & 1.83 & 0.30 & 0.56 & 0.81 & 1.04 & 2.22 & 0.30 & 0.55 & 0.79 & 1.00 & 2.13 & 0.31 & 0.57 & 0.81 & 1.04 & 2.18 & 0.58 & 1.10 & 1.53 & 2.09 & 4.48 & 0.60 & 1.09 & 1.56 & 2.02 & 4.41 & 0.59 & 1.11 & 1.52 & 1.98 & 4.25 & 0.70 & 1.31 & 1.96 & 2.50 & 5.57 & 0.68 & 1.28 & 1.81 & 2.37 & 5.13 & 0.72 & 1.29 & 1.82 & 2.38 & 5.11 & 40 \\\\\n",
      "pc1req & 0.07 & 0.07 & 0.07 & 0.08 & 0.10 & 0.07 & 0.07 & 0.08 & 0.09 & 0.11 & 0.08 & 0.09 & 0.10 & 0.10 & 0.13 & 0.06 & 0.07 & 0.07 & 0.07 & 0.10 & 0.07 & 0.08 & 0.08 & 0.09 & 0.11 & 0.08 & 0.08 & 0.10 & 0.10 & 0.14 & 0.16 & 0.18 & 0.19 & 0.20 & 0.27 & 0.18 & 0.19 & 0.21 & 0.22 & 0.30 & 0.20 & 0.21 & 0.23 & 0.24 & 0.31 & 0.17 & 0.17 & 0.19 & 0.20 & 0.26 & 0.18 & 0.19 & 0.22 & 0.23 & 0.30 & 0.20 & 0.21 & 0.23 & 0.25 & 0.31 & 9 \\\\\n",
      "spect & 0.12 & 0.13 & 0.13 & 0.13 & 0.13 & 0.14 & 0.13 & 0.14 & 0.14 & 0.13 & 0.13 & 0.14 & 0.14 & 0.13 & 0.13 & 0.12 & 0.12 & 0.13 & 0.13 & 0.14 & 0.13 & 0.14 & 0.14 & 0.13 & 0.13 & 0.14 & 0.13 & 0.13 & 0.14 & 0.13 & 0.31 & 0.32 & 0.32 & 0.32 & 0.32 & 0.31 & 0.33 & 0.31 & 0.31 & 0.31 & 0.31 & 0.31 & 0.32 & 0.33 & 0.32 & 0.33 & 0.34 & 0.33 & 0.31 & 0.31 & 0.31 & 0.31 & 0.31 & 0.31 & 0.31 & 0.30 & 0.32 & 0.31 & 0.32 & 0.32 & 23 \\\\\n",
      "transfusion & 0.03 & 0.05 & 0.07 & 0.10 & 0.21 & 0.03 & 0.05 & 0.08 & 0.10 & 0.22 & 0.03 & 0.05 & 0.07 & 0.10 & 0.22 & 0.03 & 0.05 & 0.08 & 0.10 & 0.21 & 0.03 & 0.05 & 0.08 & 0.12 & 0.21 & 0.03 & 0.05 & 0.08 & 0.10 & 0.22 & 0.07 & 0.12 & 0.19 & 0.24 & 0.53 & 0.07 & 0.12 & 0.18 & 0.24 & 0.52 & 0.06 & 0.12 & 0.18 & 0.23 & 0.50 & 0.07 & 0.13 & 0.18 & 0.24 & 0.52 & 0.07 & 0.12 & 0.18 & 0.24 & 0.51 & 0.07 & 0.12 & 0.18 & 0.23 & 0.51 & 5 \\\\\n",
      "vote & 0.09 & 0.09 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.09 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.10 & 0.23 & 0.23 & 0.23 & 0.23 & 0.24 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.24 & 0.24 & 0.23 & 0.23 & 0.23 & 0.23 & 0.23 & 0.22 & 0.22 & 0.23 & 0.23 & 0.23 & 17 \\\\\n",
      "wbc & 0.07 & 0.11 & 0.15 & 0.18 & 0.35 & 0.07 & 0.11 & 0.14 & 0.17 & 0.35 & 0.07 & 0.11 & 0.14 & 0.18 & 0.35 & 0.07 & 0.12 & 0.16 & 0.19 & 0.37 & 0.08 & 0.13 & 0.17 & 0.22 & 0.44 & 0.09 & 0.14 & 0.18 & 0.23 & 0.44 & 0.17 & 0.27 & 0.38 & 0.45 & 0.91 & 0.16 & 0.26 & 0.35 & 0.44 & 0.90 & 0.17 & 0.28 & 0.37 & 0.48 & 0.92 & 0.18 & 0.30 & 0.40 & 0.48 & 0.97 & 0.19 & 0.32 & 0.43 & 0.57 & 1.14 & 0.20 & 0.34 & 0.45 & 0.59 & 1.09 & 10 \\\\\n",
      "\\hline\n",
      "Average & 0.09 & 0.14 & 0.18 & 0.22 & 0.42 & 0.10 & 0.15 & 0.19 & 0.23 & 0.43 & 0.11 & 0.15 & 0.19 & 0.23 & 0.44 & 0.10 & 0.16 & 0.21 & 0.26 & 0.49 & 0.11 & 0.17 & 0.22 & 0.27 & 0.50 & 0.12 & 0.17 & 0.23 & 0.28 & 0.52 & 0.24 & 0.34 & 0.45 & 0.55 & 1.07 & 0.25 & 0.35 & 0.45 & 0.56 & 1.06 & 0.25 & 0.36 & 0.45 & 0.56 & 1.05 & 0.26 & 0.39 & 0.51 & 0.63 & 1.28 & 0.27 & 0.40 & 0.52 & 0.64 & 1.23 & 0.28 & 0.41 & 0.53 & 0.66 & 1.27 & 16.7 \\\\\n",
      "\n",
      "Runtime Calibrations Sizes & xGB_ce_0.1 & xGB_ce_0.2 & xGB_ce_0.4 & xGB_cce_0.1 & xGB_cce_0.2 & xGB_cce_0.4 & RF_ce_0.1 & RF_ce_0.2 & RF_ce_0.4 & RF_cce_0.1 & RF_cce_0.2 & RF_cce_0.4 &  \\\\\n",
      "\\hline\n",
      "Average & 0.21 & 0.22 & 0.22 & 0.24 & 0.25 & 0.26 & 0.53 & 0.53 & 0.53 & 0.62 & 0.61 & 0.63 \\\\\n",
      "\n",
      "Runtime Sample Sizes & xGB_ce_1 & xGB_ce_2 & xGB_ce_3 & xGB_ce_4 & xGB_ce_9 & xGB_cce_1 & xGB_cce_2 & xGB_cce_3 & xGB_cce_4 & xGB_cce_9 & RF_ce_1 & RF_ce_2 & RF_ce_3 & RF_ce_4 & RF_ce_9 & RF_cce_1 & RF_cce_2 & RF_cce_3 & RF_cce_4 & RF_cce_9 &  \\\\\n",
      "\\hline\n",
      "Average & 0.10 & 0.14 & 0.19 & 0.23 & 0.43 & 0.11 & 0.16 & 0.22 & 0.27 & 0.51 & 0.25 & 0.35 & 0.45 & 0.56 & 1.06 & 0.27 & 0.40 & 0.52 & 0.64 & 1.26 \\\\\n"
     ]
    }
   ],
   "source": [
    "timer = []\n",
    "n = results['test_size']\n",
    "cal_sizes = results['calibration_sizes']\n",
    "perc_samples = results['sample_percentiles']\n",
    "average_time = {}\n",
    "average_time['num_features'] = []\n",
    "print('Runtime & ', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']:            \n",
    "        for cal in ablation[key]:\n",
    "            for p in perc_samples:\n",
    "                average_time[a+\"_\"+key+\"_\"+str(cal)+\"_\"+str(p)] = []\n",
    "                average_time[a+\"_\"+key+\"_\"+str(cal)+\"_\"+str(p)] = []\n",
    "                print(f'{a+\"_\"+key+\"_\"+str(cal)+\"_\"+str(len(p))} & ',end='')\n",
    "print(' \\\\\\\\\\n\\\\hline')\n",
    "\n",
    "for d in np.sort(np.sort([k for k in results.keys()])):\n",
    "    if d in ['test_size', 'calibration_sizes', 'sample_percentiles']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    for a in results[d]:\n",
    "        n = len(results[d][a]['ablation']['ce'][cal_sizes[0]][str(perc_samples[0])][0])\n",
    "        for key in ['ce', 'cce']:  \n",
    "            a_time = results[d][a]['timer']\n",
    "            for cal in ablation[key]:\n",
    "                for p in ablation[key][cal]:          \n",
    "                    print(' & ', end='')\n",
    "                    res = np.mean([t/n for t in a_time[key][cal][p]])\n",
    "                    average_time[a+\"_\"+key+\"_\"+str(cal)+\"_\"+p].append(res)\n",
    "                    average_time['num_features'].append(data_characteristics[d])\n",
    "                    print(f'{res:.2f}',end='')\n",
    "    print(f' & {data_characteristics[d]}', end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']: \n",
    "            for cal in ablation[key]:\n",
    "                for p in ablation[key][cal]:           \n",
    "                    print(' & ', end='')\n",
    "                    print(f'{np.mean(average_time[a+\"_\"+key+\"_\"+str(cal)+\"_\"+p]):.2f}',end='')\n",
    "print(f' & {np.mean(average_time[\"num_features\"]):.1f}', end='')\n",
    "print(' \\\\\\\\')\n",
    "\n",
    "\n",
    "print('\\nRuntime Calibrations Sizes & ', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']:            \n",
    "        for cal in ablation[key]:\n",
    "            print(f'{a+\"_\"+key+\"_\"+str(cal)} & ',end='')\n",
    "print(' \\\\\\\\\\n\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']: \n",
    "        for cal in ablation[key]:      \n",
    "            print(' & ', end='')\n",
    "            print(f'{np.mean([average_time[a+\"_\"+key+\"_\"+str(cal)+\"_\"+p] for p in ablation[key][cal]]):.2f}',end='')\n",
    "print(' \\\\\\\\')\n",
    "\n",
    "print('\\nRuntime Sample Sizes & ', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']:            \n",
    "        for p in perc_samples:\n",
    "            print(f'{a+\"_\"+key+\"_\"+str(len(p))} & ',end='')\n",
    "print(' \\\\\\\\\\n\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    for key in ['ce', 'cce']:           \n",
    "        for p in perc_samples:     \n",
    "            print(' & ', end='')\n",
    "            print(f'{np.mean([average_time[a+\"_\"+key+\"_\"+str(cal)+\"_\"+str(p)] for cal in ablation[key]]):.2f}',end='')\n",
    "print(' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results regarding runtime are as can be expected and the observations are summarized below:\n",
    "* The runtime increases with the number of percentiles sampled for numerical features.\n",
    "* The runtime increases with the calibration size, even if the difference in runtime is fairly small.\n",
    "* CE is faster than CCE, as expected. The reason is that CCE will generally require additional calculations than CE, at least for numerical features.\n",
    "* The runtime tend to increase with the number of features, even if it is not a linear increase. This is due to the fact that categorical features with many categories are more expensive to compute, at least as long as the sampling size is small. Consequently, the number of categorical features together with the number of categories per feature is more important than the total number of features, especially when the sampling size (only affecting numerical features) is small.\n",
    "* The greatest difference in runtime can be attributed to the underlying model, indicating that the choice of model used will have a great impact on runtime.\n",
    "### 5 Conclusion\n",
    "Consequently, the individual parameter that influence runtime most is the number of percentiles sampled for numerical features. As this tend to have a very small impact on the feature importance, it may be a reason to consider decreasing the number of percentiles sampled by default for numerical features (currently the default is 3: [25, 50, 75])."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "168dd73c7a7b76a0355e35f33a90e68c167b1dbb1e524891be00dd5c7b8524eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
