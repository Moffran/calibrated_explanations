{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrated_explanations v0.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from crepes import ConformalPredictiveSystem\n",
    "from crepes.extras import binning, DifficultyEstimator\n",
    "\n",
    "from calibrated_explanations import  VennAbers, __version__\n",
    "from calibrated_explanations.utils import transform_to_numeric\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"calibrated_explanations {__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = {'COMPAS': 'classification', 'Adult': 'classification', 'German': 'classification', 'Housing': 'regression', 'CaC': 'regression'}\n",
    "results = {}\n",
    "for name, type in datasets.items():\n",
    "    results[name] = {}\n",
    "    results[name]['type'] = type\n",
    "    for category in ['mondrian', 'mondrian_x', 'model_split']:\n",
    "        results[name][category] = {'time': 0, 'base': 0, 'rand': 0, 'race': 0, 'sex': 0, 'age': 0, 'edu': 0, 'crm': 0}\n",
    "\n",
    "num_bins = 5\n",
    "num_rep = 1\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(y_true, low, up):\n",
    "    return np.mean((y_true >= low) & (y_true <= up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS\n",
    "Data preprocessing from [this notebook](https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_COMPAS_with_SHAP.ipynb#scrollTo=KF00pJvkeicT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18316, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'COMPAS'\n",
    "df = pd.read_csv('https://storage.googleapis.com/what-if-tool-resources/computefest2019/cox-violent-parsed_filt.csv')\n",
    "print(df.shape)\n",
    "# Preprocess the data\n",
    "\n",
    "# Filter out entries with no indication of recidivism or no compass score\n",
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['decile_score'] != -1]\n",
    "\n",
    "\n",
    "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
    "df['score_text'] = np.where(df['score_text'] == 'Low', 'Low', 'Not Low')\n",
    "\n",
    "target = 'score_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'score_text']\n",
    "# 'age_cat', 'is_recid', 'vr_charge_desc',  'c_charge_desc',, 'is_violent_recid''vr_charge_degree', 'c_charge_degree', 'decile_score', \n",
    "df = df[features_to_keep]\n",
    "df, categorical_features, categorical_labels, target_labels, mappings = transform_to_numeric(df, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count',\n",
      "       'juv_other_count', 'priors_count', 'score_text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "race = 2\n",
    "age = 1\n",
    "sex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 20 # number of instances to test\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop([target],axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':race, 'sex':sex, 'age':age}\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=num_bins)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():                \n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=num_bins)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "    \n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=num_bins)\n",
    "        age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()                \n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                uncal = model.predict_proba(X_test_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['uncal'][attr].append(uncal[:,1])\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t CondIncl\t CondExcl\t ModelSplit\n",
      "base width: \t 0.0075 \t 0.0082 \t 0.0074\n",
      "rand width: \t 0.0226 \t 0.0234 \t 0.0205\n",
      "race width: \t 0.0184 \t 0.0198 \t 0.0177\n",
      "sex width: \t 0.0118 \t 0.0126 \t 0.0111\n",
      "age width: \t 0.0218 \t 0.0250 \t 0.0214\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): .3f} \\t{np.mean(mondrian_x[\"width\"][attr]): .3f} \\t{np.mean(model_split[\"width\"][attr]): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t CondIncl\t CondExcl\t ModelSplit\t CondIncl\t CondExcl\t ModelSplit\n",
      "Category\t VA\t VA\t VA\t Uncal\t Uncal\t Uncal\n",
      "base Accuracy: \t 0.7783 \t 0.7514 \t 0.7753 \t 0.7769 \t 0.7528 \t 0.7743\n",
      "rand Accuracy: \t 0.7743 \t 0.7489 \t 0.7318 \t 0.7769 \t 0.7528 \t 0.7339\n",
      "race Accuracy: \t 0.7765 \t 0.7542 \t 0.7736 \t 0.7769 \t 0.7528 \t 0.7736\n",
      "sex Accuracy: \t 0.7785 \t 0.7528 \t 0.7742 \t 0.7769 \t 0.7528 \t 0.7724\n",
      "age Accuracy: \t 0.7770 \t 0.7476 \t 0.7712 \t 0.7769 \t 0.7528 \t 0.7723\n",
      "\n",
      "base LogLoss: \t 0.4612 \t 0.4973 \t 0.4644 \t 0.7691 \t 0.6797 \t 0.8008\n",
      "rand LogLoss: \t 0.4660 \t 0.5009 \t 0.5367 \t 0.7691 \t 0.6797 \t 0.9092\n",
      "race LogLoss: \t 0.4608 \t 0.4865 \t 0.4648 \t 0.7691 \t 0.6797 \t 0.8268\n",
      "sex LogLoss: \t 0.4618 \t 0.4962 \t 0.4653 \t 0.7691 \t 0.6797 \t 0.7937\n",
      "age LogLoss: \t 0.4611 \t 0.4957 \t 0.4688 \t 0.7691 \t 0.6797 \t 0.8015\n"
     ]
    }
   ],
   "source": [
    "print('\\t CondIncl\\t CondExcl\\t ModelSplit\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "print('Category\\t VA\\t VA\\t VA\\t Uncal\\t Uncal\\t Uncal')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .3f} \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .3f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .3f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .3f} \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .3f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .3f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .3f} \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .3f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .3f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .3f} \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .3f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .3f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Adult'\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<=50K', 1: '>50K'}\n"
     ]
    }
   ],
   "source": [
    "df = X\n",
    "target = 'Income'\n",
    "y = y.replace('<=50K.', '<=50K')\n",
    "y = y.replace('>50K.', '>50K')\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "edu = 3\n",
    "race = 8\n",
    "sex = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':race, 'sex':sex, 'edu':edu}\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():            \n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n"
     ]
    }
   ],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'edu': X_train[:,edu]}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        try:\n",
    "            for attr in attribute_names:\n",
    "                for bin in np.unique(train_bins[attr]):\n",
    "                    X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                    y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                    X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                    y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                    X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                    y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                    if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    model = RandomForestClassifier()\n",
    "                    model.fit(X_train_bin,y_train_bin)\n",
    "                    uncal = model.predict_proba(X_test_bin)\n",
    "                    va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                    proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                    model_split['uncal'][attr].append(uncal[:,1])\n",
    "                    model_split['proba'][attr].append(proba[:,1])\n",
    "                    model_split['low'][attr].append(low)\n",
    "                    model_split['high'][attr].append(high)\n",
    "                    model_split['width'][attr].append(high - low)\n",
    "                    model_split['y'][attr].append(y_test_bin)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'attr: {attr} bin: {bin}')    \n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t CondIncl\t CondExcl\t ModelSplit\n",
      "base width: \t 0.0029 \t 0.0029 \t 0.0030\n",
      "rand width: \t 0.0098 \t 0.0095 \t 0.0099\n",
      "race width: \t 0.0068 \t 0.0067 \t 0.0069\n",
      "sex width: \t 0.0046 \t 0.0045 \t 0.0048\n",
      "edu width: \t 0.0161 \t 0.0147 \t 0.0152\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): .3f} \\t{np.mean(mondrian_x[\"width\"][attr]): .3f} \\t{np.mean(model_split[\"width\"][attr]): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t CondIncl\t CondExcl\t ModelSplit\t CondIncl\t CondExcl\t ModelSplit\n",
      "Category\t VA\t VA\t VA\t Uncal\t Uncal\t Uncal\n",
      "base Accuracy: \t 0.8553 \t 0.8330 \t 0.8558 \t 0.8558 \t 0.8326 \t 0.8559\n",
      "rand Accuracy: \t 0.8544 \t 0.8324 \t 0.8497 \t 0.8558 \t 0.8326 \t 0.8491\n",
      "race Accuracy: \t 0.8548 \t 0.8329 \t 0.8530 \t 0.8558 \t 0.8326 \t 0.8530\n",
      "sex Accuracy: \t 0.8555 \t 0.8318 \t 0.8556 \t 0.8558 \t 0.8326 \t 0.8552\n",
      "edu Accuracy: \t 0.8561 \t 0.8344 \t 0.8520 \t 0.8558 \t 0.8326 \t 0.8502\n",
      "\n",
      "base LogLoss: \t 0.3175 \t 0.3588 \t 0.3169 \t 0.3674 \t 0.4111 \t 0.3596\n",
      "rand LogLoss: \t 0.3197 \t 0.3604 \t 0.3286 \t 0.3674 \t 0.4111 \t 0.3570\n",
      "race LogLoss: \t 0.3179 \t 0.3587 \t 0.3217 \t 0.3674 \t 0.4111 \t 0.3641\n",
      "sex LogLoss: \t 0.3166 \t 0.3585 \t 0.3197 \t 0.3674 \t 0.4111 \t 0.3713\n",
      "edu LogLoss: \t 0.3189 \t 0.3587 \t 0.3284 \t 0.3674 \t 0.4111 \t 0.3916\n"
     ]
    }
   ],
   "source": [
    "print('\\t CondIncl\\t CondExcl\\t ModelSplit\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "print('Category\\t VA\\t VA\\t VA\\t Uncal\\t Uncal\\t Uncal')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .3f} \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .3f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .3f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .3f} \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .3f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .3f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .3f} \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .3f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .3f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .3f} \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .3f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .3f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'German'\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = statlog_german_credit_data.variables.description[:-1]\n",
    "feature_names[0] = 'Status'\n",
    "feature_names[7] = 'Installment rate'\n",
    "feature_names[15] = 'Existing credits'\n",
    "feature_names[17] = 'Num people liable'\n",
    "target_labels = {1: 'Good', 0: 'Bad'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         Status\n",
      "1                       Duration\n",
      "2                 Credit history\n",
      "3                        Purpose\n",
      "4                  Credit amount\n",
      "5          Savings account/bonds\n",
      "6       Present employment since\n",
      "7               Installment rate\n",
      "8        Personal status and sex\n",
      "9     Other debtors / guarantors\n",
      "10       Present residence since\n",
      "11                      Property\n",
      "12                           Age\n",
      "13       Other installment plans\n",
      "14                       Housing\n",
      "15              Existing credits\n",
      "16                           Job\n",
      "17             Num people liable\n",
      "18                     Telephone\n",
      "19                foreign worker\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)\n",
    "age = 12\n",
    "sex = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X\n",
    "target = 'Class'\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, _, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values\n",
    "y[y == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'sex':sex, 'age':age}\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=num_bins)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():\n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=num_bins)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=num_bins)\n",
    "        age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()                \n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                uncal = model.predict_proba(X_test_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['uncal'][attr].append(uncal[:,1])\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t CondIncl\t CondExcl\t ModelSplit\n",
      "base width: \t 0.0429 \t 0.0407 \t 0.0450\n",
      "rand width: \t 0.1227 \t 0.1232 \t 0.1235\n",
      "sex width: \t 0.0964 \t 0.0909 \t 0.0943\n",
      "age width: \t 0.1228 \t 0.1187 \t 0.1130\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): .3f} \\t{np.mean(mondrian_x[\"width\"][attr]): .3f} \\t{np.mean(model_split[\"width\"][attr]): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t CondIncl\t CondExcl\t ModelSplit\t CondIncl\t CondExcl\t ModelSplit\n",
      "Category\t VA\t VA\t VA\t Uncal\t Uncal\t Uncal\n",
      "base Accuracy: \t 0.7710 \t 0.7540 \t 0.7530 \t 0.7710 \t 0.7520 \t 0.7580\n",
      "rand Accuracy: \t 0.7600 \t 0.7450 \t 0.7250 \t 0.7710 \t 0.7520 \t 0.7230\n",
      "sex Accuracy: \t 0.7440 \t 0.7440 \t 0.7260 \t 0.7710 \t 0.7520 \t 0.7300\n",
      "age Accuracy: \t 0.7610 \t 0.7460 \t 0.7310 \t 0.7710 \t 0.7520 \t 0.7390\n",
      "\n",
      "base LogLoss: \t 0.5036 \t 0.5143 \t 0.5090 \t 0.5009 \t 0.5125 \t 0.5046\n",
      "rand LogLoss: \t 0.5070 \t 0.5382 \t 0.5448 \t 0.5009 \t 0.5125 \t 0.5369\n",
      "sex LogLoss: \t 0.5105 \t 0.5167 \t 0.5396 \t 0.5009 \t 0.5125 \t 0.5597\n",
      "age LogLoss: \t 0.5108 \t 0.5211 \t 0.5539 \t 0.5009 \t 0.5125 \t 0.5298\n"
     ]
    }
   ],
   "source": [
    "print('\\t CondIncl\\t CondExcl\\t ModelSplit\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "print('Category\\t VA\\t VA\\t VA\\t Uncal\\t Uncal\\t Uncal')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .3f} \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .3f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .3f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .3f} \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .3f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .3f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .3f} \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .3f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .3f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .3f} \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .3f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .3f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Housing'\n",
    "df = pd.read_csv('../data/reg/HousingData.csv', na_values='NA')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]\n",
    "print(feature_names)\n",
    "crm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'MEDV'\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "Xd, yd = df.drop(target,axis=1), df[target]\n",
    "X, y = df.drop(target,axis=1).values, df[target].values\n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Regression\n",
    "Default confidence of 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'crm':crm}\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['median'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['median'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=num_bins)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        residuals_cal = model.predict(x_cal) - y_cal\n",
    "        y_test_hat = model.predict(x_test)\n",
    "        mondrian_x['y'].append(y_test)        \n",
    "        \n",
    "        for attr, a in attributes.items():                \n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian_x['uncal'][attr].append(y_test_hat)\n",
    "            mondrian_x['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian_x['low'][attr].append(values[:,0])\n",
    "            mondrian_x['high'][attr].append(values[:,2])\n",
    "            mondrian_x['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['median'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['median'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=num_bins)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian['uncal'][attr].append(y_test_hat)\n",
    "            mondrian['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian['low'][attr].append(values[:,0])\n",
    "            mondrian['high'][attr].append(values[:,2])\n",
    "            mondrian['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['median'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['median'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=num_bins)\n",
    "        crm_train_bin = binning(X_train[:,crm], crm_cal_boundaries)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'crm': crm_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin,:]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin,:]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin,:]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestRegressor()\n",
    "                model.fit(X_train_bin, y_train_bin)\n",
    "                \n",
    "                residuals_cal = model.predict(X_cal_bin) - y_cal_bin\n",
    "                y_test_bin_hat = model.predict(X_test_bin)\n",
    "            \n",
    "                cps[attr] = ConformalPredictiveSystem()\n",
    "                cps[attr].fit(residuals_cal)\n",
    "                values = cps[attr].predict(y_test_bin_hat, lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "                model_split['uncal'][attr].append(y_test_bin_hat)\n",
    "                model_split['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "                model_split['low'][attr].append(values[:,0])\n",
    "                model_split['high'][attr].append(values[:,2])\n",
    "                model_split['width'][attr].append(values[:,2]-values[:,0])\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['median'][attr] = np.concatenate(mondrian_x['median'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['median'][attr] = np.concatenate(mondrian['median'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['median'][attr] = np.concatenate(model_split['median'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t CondIncl\t CondExcl\t ModelSplit\n",
      "base width: \t 10.785 \t 9.203 \t 10.047\n",
      "rand width: \t 13.852 \t 15.709 \t 19.781\n",
      "crm width: \t 13.084 \t 13.155 \t 17.124\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print('Category\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): .3f} \\t{np.mean(mondrian_x[\"width\"][attr]): .3f} \\t{np.mean(model_split[\"width\"][attr]): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t CondIncl\t CondExcl\t ModelSplit\t CondIncl\t CondExcl\t ModelSplit\n",
      "Category\t VA\t VA\t VA\t Uncal\t Uncal\t Uncal\n",
      "base Coverage: \t 0.929 \t 0.878 \t 0.909\n",
      "rand Coverage: \t 0.919 \t 0.896 \t 0.914\n",
      "crm Coverage: \t 0.896 \t 0.888 \t 0.911\n",
      "base R2: \t 0.857 \t 0.841 \t 0.855 \t 0.859 \t 0.842 \t 0.862\n",
      "rand R2: \t 0.855 \t 0.833 \t 0.692 \t 0.859 \t 0.842 \t 0.710\n",
      "crm R2: \t 0.856 \t 0.829 \t 0.816 \t 0.859 \t 0.842 \t 0.829\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print('\\t CondIncl\\t CondExcl\\t ModelSplit\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "print('Category\\t VA\\t VA\\t VA\\t Uncal\\t Uncal\\t Uncal')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Coverage: \\t{coverage(mondrian[\"y\"], mondrian[\"low\"][attr], mondrian[\"high\"][attr]): .3f} \\t{coverage(mondrian_x[\"y\"], mondrian_x[\"low\"][attr], mondrian_x[\"high\"][attr]): .3f} \\t{coverage(model_split[\"y\"][attr], model_split[\"low\"][attr], model_split[\"high\"][attr]): .3f}')\n",
    "# for attr in attribute_names:\n",
    "#     print(f'{attr} MAE: \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"median\"][attr]): .3f} \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .3f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"median\"][attr]): .3f}', end='')\n",
    "#     print(f' \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .3f} \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .3f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .3f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} R2: \\t{r2_score(mondrian[\"y\"], mondrian[\"median\"][attr]): .3f} \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .3f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"median\"][attr]): .3f}', end='')    \n",
    "    print(f' \\t{r2_score(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .3f} \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .3f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities and Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CaC'\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('../data/reg/communities.csv')\n",
    "\n",
    "# Remove columns with missing values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Remove string columns\n",
    "df = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:state, 1:fold, 2:population, 3:householdsize, 4:racepctblack, 5:racePctWhite, 6:racePctAsian, 7:racePctHisp, 8:agePct12t21, 9:agePct12t29, 10:agePct16t24, 11:agePct65up, 12:numbUrban, 13:pctUrban, 14:medIncome, 15:pctWWage, 16:pctWFarmSelf, 17:pctWInvInc, 18:pctWSocSec, 19:pctWPubAsst, 20:pctWRetire, 21:medFamInc, 22:perCapInc, 23:whitePerCap, 24:blackPerCap, 25:indianPerCap, 26:AsianPerCap, 27:HispPerCap, 28:NumUnderPov, 29:PctPopUnderPov, 30:PctLess9thGrade, 31:PctNotHSGrad, 32:PctBSorMore, 33:PctUnemployed, 34:PctEmploy, 35:PctEmplManu, 36:PctEmplProfServ, 37:PctOccupManu, 38:PctOccupMgmtProf, 39:MalePctDivorce, 40:MalePctNevMarr, 41:FemalePctDiv, 42:TotalPctDiv, 43:PersPerFam, 44:PctFam2Par, 45:PctKids2Par, 46:PctYoungKids2Par, 47:PctTeen2Par, 48:PctWorkMomYoungKids, 49:PctWorkMom, 50:NumIlleg, 51:PctIlleg, 52:NumImmig, 53:PctImmigRecent, 54:PctImmigRec5, 55:PctImmigRec8, 56:PctImmigRec10, 57:PctRecentImmig, 58:PctRecImmig5, 59:PctRecImmig8, 60:PctRecImmig10, 61:PctSpeakEnglOnly, 62:PctNotSpeakEnglWell, 63:PctLargHouseFam, 64:PctLargHouseOccup, 65:PersPerOccupHous, 66:PersPerOwnOccHous, 67:PersPerRentOccHous, 68:PctPersOwnOccup, 69:PctPersDenseHous, 70:PctHousLess3BR, 71:MedNumBR, 72:HousVacant, 73:PctHousOccup, 74:PctHousOwnOcc, 75:PctVacantBoarded, 76:PctVacMore6Mos, 77:MedYrHousBuilt, 78:PctHousNoPhone, 79:PctWOFullPlumb, 80:OwnOccLowQuart, 81:OwnOccMedVal, 82:OwnOccHiQuart, 83:RentLowQ, 84:RentMedian, 85:RentHighQ, 86:MedRent, 87:MedRentPctHousInc, 88:MedOwnCostPctInc, 89:MedOwnCostPctIncNoMtg, 90:NumInShelters, 91:NumStreet, 92:PctForeignBorn, 93:PctBornSameState, 94:PctSameHouse85, 95:PctSameCity85, 96:PctSameState85, 97:LandArea, 98:PopDens, 99:PctUsePubTrans, 100:LemasPctOfficDrugUn, "
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    print(f'{i}:{feature_name}', end=\", \") \n",
    "blk = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ViolentCrimesPerPop'\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd, yd = df.drop(target,axis=1), df[target]\n",
    "X, y = df.drop(target,axis=1).values, df[target].values\n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':blk}\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['median'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['median'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=num_bins)\n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        residuals_cal = model.predict(x_cal) - y_cal\n",
    "        y_test_hat = model.predict(x_test)\n",
    "        mondrian_x['y'].append(y_test)        \n",
    "        \n",
    "        for attr, a in attributes.items():                \n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian_x['uncal'][attr].append(y_test_hat)\n",
    "            mondrian_x['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian_x['low'][attr].append(values[:,0])\n",
    "            mondrian_x['high'][attr].append(values[:,2])\n",
    "            mondrian_x['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, blk]\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['median'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['median'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=num_bins)\n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian['uncal'][attr].append(y_test_hat)\n",
    "            mondrian['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian['low'][attr].append(values[:,0])\n",
    "            mondrian['high'][attr].append(values[:,2])\n",
    "            mondrian['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, blk]\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['median'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['median'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed(l)\n",
    "    indices = np.random.permutation(no_of_instances)\n",
    "    X = X[indices,:]\n",
    "    y = y[indices]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=num_bins)\n",
    "        blk_train_bin = binning(X_train[:,blk], blk_cal_boundaries)  \n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)  \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=num_bins)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': blk_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin,:]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin,:]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin,:]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestRegressor()\n",
    "\n",
    "                model.fit(X_train_bin, y_train_bin)\n",
    "                \n",
    "                residuals_cal = model.predict(X_cal_bin) - y_cal_bin\n",
    "                y_test_bin_hat = model.predict(X_test_bin)\n",
    "            \n",
    "                cps[attr] = ConformalPredictiveSystem()\n",
    "                cps[attr].fit(residuals_cal)\n",
    "                values = cps[attr].predict(y_test_bin_hat, lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "                model_split['uncal'][attr].append(y_test_bin_hat)\n",
    "                model_split['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "                model_split['low'][attr].append(values[:,0])\n",
    "                model_split['high'][attr].append(values[:,2])\n",
    "                model_split['width'][attr].append(values[:,2]-values[:,0])\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['median'][attr] = np.concatenate(mondrian_x['median'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['median'][attr] = np.concatenate(mondrian['median'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['median'][attr] = np.concatenate(model_split['median'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t CondIncl\t CondExcl\t ModelSplit\n",
      "base width: \t 0.4536 \t 0.4654 \t 0.4662\n",
      "rand width: \t 0.4936 \t 0.4938 \t 0.5273\n",
      "race width: \t 0.4630 \t 0.4358 \t 0.4591\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): .3f} \\t{np.mean(mondrian_x[\"width\"][attr]): .3f} \\t{np.mean(model_split[\"width\"][attr]): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t CondIncl\t CondExcl\t ModelSplit\t CondIncl\t CondExcl\t ModelSplit\n",
      "Category\t VA\t VA\t VA\t Uncal\t Uncal\t Uncal\n",
      "base Coverage: \t 0.8912 \t 0.9017 \t 0.9047\n",
      "rand Coverage: \t 0.8987 \t 0.9062 \t 0.9032\n",
      "race Coverage: \t 0.9203 \t 0.8811 \t 0.9062\n",
      "base R2: \t 0.6320 \t 0.6171 \t 0.6325 \t 0.6429 \t 0.6376 \t 0.6452\n",
      "rand R2: \t 0.6307 \t 0.6154 \t 0.5938 \t 0.6429 \t 0.6376 \t 0.6094\n",
      "race R2: \t 0.6271 \t 0.6142 \t 0.6045 \t 0.6429 \t 0.6376 \t 0.6284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print('\\t CondIncl\\t CondExcl\\t ModelSplit\\t CondIncl\\t CondExcl\\t ModelSplit')\n",
    "print('Category\\t VA\\t VA\\t VA\\t Uncal\\t Uncal\\t Uncal')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Coverage: \\t{coverage(mondrian[\"y\"], mondrian[\"low\"][attr], mondrian[\"high\"][attr]): .3f} \\t{coverage(mondrian_x[\"y\"], mondrian_x[\"low\"][attr], mondrian_x[\"high\"][attr]): .3f} \\t{coverage(model_split[\"y\"][attr], model_split[\"low\"][attr], model_split[\"high\"][attr]): .3f}')\n",
    "# for attr in attribute_names:\n",
    "#     print(f'{attr} MAE: \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"median\"][attr]): .3f} \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .3f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"median\"][attr]): .3f}', end='')\n",
    "#     print(f' \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .3f} \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .3f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .3f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} R2: \\t{r2_score(mondrian[\"y\"], mondrian[\"median\"][attr]): .3f} \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .3f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"median\"][attr]): .3f}', end='')    \n",
    "    print(f' \\t{r2_score(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .3f} \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .3f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\t CondIncl\t CondExcl\t ModelSplit\tType\n",
      "COMPAS\t 16.02\t\t 13.03\t\t 90.55\t\tclassification\n",
      "Adult\t 64.59\t\t 71.45\t\t 295.07\t\tclassification\n",
      "German\t 4.41\t\t 4.86\t\t 36.44\t\tclassification\n",
      "Housing\t 5.29\t\t 5.33\t\t 27.29\t\tregression\n",
      "CaC\t 133.45\t\t 138.94\t\t 383.80\t\tregression\n"
     ]
    }
   ],
   "source": [
    "categories = ['mondrian','mondrian_x','model_split',]\n",
    "print('Dataset\\t CondIncl\\t CondExcl\\t ModelSplit\\tType')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for category in categories:\n",
    "        print(f'{results[name][category][\"time\"]: 0.2f}\\t\\t', end='')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Width\n",
    "#### Mondrian vs model split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPAS\t CondIncl\t CondExcl\t ModelSplit\t\n",
      "base\t 0.008\t\t 0.008\t\t 0.007\t\t\n",
      "rand\t 0.023\t\t 0.023\t\t 0.021\t\t\n",
      "race\t 0.018\t\t 0.020\t\t 0.018\t\t\n",
      "sex\t 0.012\t\t 0.013\t\t 0.011\t\t\n",
      "age\t 0.022\t\t 0.025\t\t 0.021\t\t\n",
      "\n",
      "Adult\t CondIncl\t CondExcl\t ModelSplit\t\n",
      "base\t 0.003\t\t 0.003\t\t 0.003\t\t\n",
      "rand\t 0.010\t\t 0.010\t\t 0.010\t\t\n",
      "race\t 0.007\t\t 0.007\t\t 0.007\t\t\n",
      "sex\t 0.005\t\t 0.005\t\t 0.005\t\t\n",
      "edu\t 0.016\t\t 0.015\t\t 0.015\t\t\n",
      "\n",
      "German\t CondIncl\t CondExcl\t ModelSplit\t\n",
      "base\t 0.043\t\t 0.041\t\t 0.045\t\t\n",
      "rand\t 0.123\t\t 0.123\t\t 0.123\t\t\n",
      "sex\t 0.096\t\t 0.091\t\t 0.094\t\t\n",
      "age\t 0.123\t\t 0.119\t\t 0.113\t\t\n",
      "\n",
      "Housing\t CondIncl\t CondExcl\t ModelSplit\t\n",
      "base\t 8.499\t\t 9.810\t\t 9.780\t\t\n",
      "rand\t 11.790\t\t 14.632\t\t 18.927\t\t\n",
      "crm\t 11.776\t\t 14.733\t\t 15.895\t\t\n",
      "\n",
      "CaC\t CondIncl\t CondExcl\t ModelSplit\t\n",
      "base\t 0.454\t\t 0.465\t\t 0.466\t\t\n",
      "rand\t 0.494\t\t 0.494\t\t 0.527\t\t\n",
      "race\t 0.463\t\t 0.436\t\t 0.459\t\t\n",
      "\n"
     ]
    }
   ],
   "source": [
    "heading = {'mondrian':'CondIncl', 'mondrian_x':'CondExcl', 'model_split':'ModelSplit'}\n",
    "for name, type in datasets.items():\n",
    "    print(name, end='\\t')\n",
    "    for category in categories:\n",
    "        print(f' {heading[category]}', end='\\t')\n",
    "    print('')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        if results[name][category][attr] > 0:\n",
    "            print(attr, end='\\t')\n",
    "            for category in categories:\n",
    "                val = results[name][category][attr]\n",
    "                print(f'{val: 0.3f}', end='\\t\\t')       \n",
    "            print('')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t\n",
      "Dataset\t base\t\t rand\t\t race\t\t sex\t\t age\t\t edu\t\t crm\t\tType\n",
      "COMPAS\t 0.008\t\t 0.023\t\t 0.018\t\t 0.012\t\t 0.022\t\t -\t\t -\t\tclassification\n",
      "Adult\t 0.003\t\t 0.010\t\t 0.007\t\t 0.005\t\t -\t\t 0.016\t\t -\t\tclassification\n",
      "German\t 0.043\t\t 0.123\t\t -\t\t 0.096\t\t 0.123\t\t -\t\t -\t\tclassification\n",
      "Housing\t 8.499\t\t 11.790\t\t -\t\t -\t\t -\t\t -\t\t 11.776\t\tregression\n",
      "CaC\t 0.454\t\t 0.494\t\t 0.463\t\t -\t\t -\t\t -\t\t -\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        for category in ['mondrian']:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mondrian With Excluded Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t mondrian_x\t mondrian_x\t mondrian_x\t mondrian_x\t mondrian_x\t mondrian_x\t mondrian_x\t\n",
      "Dataset\t base\t\t rand\t\t race\t\t sex\t\t age\t\t edu\t\t crm\t\tType\n",
      "COMPAS\t 0.008\t\t 0.023\t\t 0.020\t\t 0.013\t\t 0.025\t\t -\t\t -\t\tclassification\n",
      "Adult\t 0.003\t\t 0.010\t\t 0.007\t\t 0.005\t\t -\t\t 0.015\t\t -\t\tclassification\n",
      "German\t 0.041\t\t 0.123\t\t -\t\t 0.091\t\t 0.119\t\t -\t\t -\t\tclassification\n",
      "Housing\t 9.810\t\t 14.632\t\t -\t\t -\t\t -\t\t -\t\t 14.733\t\tregression\n",
      "CaC\t 0.465\t\t 0.494\t\t 0.436\t\t -\t\t -\t\t -\t\t -\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian_x'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian_x']:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian_x'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian_x']:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian_x'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        for category in ['mondrian_x']:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t model_split\t model_split\t model_split\t model_split\t model_split\t model_split\t model_split\t\n",
      "Dataset\t base\t\t rand\t\t race\t\t sex\t\t age\t\t edu\t\t crm\t\tType\n",
      "COMPAS\t 0.007\t\t 0.021\t\t 0.018\t\t 0.011\t\t 0.021\t\t -\t\t -\t\tclassification\n",
      "Adult\t 0.003\t\t 0.010\t\t 0.007\t\t 0.005\t\t -\t\t 0.015\t\t -\t\tclassification\n",
      "German\t 0.045\t\t 0.123\t\t -\t\t 0.094\t\t 0.113\t\t -\t\t -\t\tclassification\n",
      "Housing\t 9.780\t\t 18.927\t\t -\t\t -\t\t -\t\t -\t\t 15.895\t\tregression\n",
      "CaC\t 0.466\t\t 0.527\t\t 0.459\t\t -\t\t -\t\t -\t\t -\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['model_split'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['model_split']:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['model_split'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['model_split']:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['model_split'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        for category in ['model_split']:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
