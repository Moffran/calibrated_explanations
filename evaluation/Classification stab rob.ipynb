{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrated Explanations for Binary Classification\n",
    "## Stability and Robustness\n",
    "\n",
    "Author: Tuwe Löfström (tuwe.lofstrom@ju.se)  \n",
    "Copyright 2023 Tuwe Löfström  \n",
    "License: BSD 3 clause\n",
    "Sources:\n",
    "1. [\"Calibrated Explanations: with Uncertainty Information and Counterfactuals\"](https://arxiv.org/abt/2305.02305) by [Helena Löfström](https://github.com/Moffran), [Tuwe Löfström](https://github.com/tuvelofstrom), Ulf Johansson, and Cecilia Sönströd.\n",
    "\n",
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Import results from the pickled result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_stab_rob.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Stability and Robustness\n",
    "Create a table with the robustness and stability results. The stability results stem from experiements where the same model, calibration set and test set have been exaplained 30 times. The only source of variation is the random seed. The robustness restults stem from experiments where training and calibration sets have been randomly resampled before a new model have been trained and explained. The experiment where run 30 times and the test set was the same for all models. The robustness is measured in this way to avoid inferring perturbed instances which are not from the same distribution as the test instances being explained. The probability estimate of each of the models was computed on the same test set, as comparison to the robustness results. The expectationis that a stable and robust explanation method should result in low variance in the feature importance weights.\n",
    "\n",
    "Everything was run on 25 datasets. See the `Classification_Experiment stab rob.py` for details on the experiment.\n",
    "\n",
    "The tabulated results are the mean variance of the stability and robustness measured over the 30 runs and 20 instances. The variance is measured per instance and computed over the 30 runs on the feature importance weight of the most influential feature, defined as the feature most often having highest absolut feature importance weight. The average variance is computed over the 20 instances. The most influential feature is used since it is the feature that is most likely to be used in a decision but also the feature with the greatest expected variation (as a consequence of the weights having the highest absolute values). \n",
    "\n",
    "The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & xGB & xGB & xGB & xGB & xGB & RF & RF & RF & RF & RF \\\\\n",
      "Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness & Model Variance & CE Stability & CCE Stability & CE Robustness & CCE Robustness & Model Variance \\\\\n",
      "\\hline\n",
      "pc1req & 7.7e-35 & 7.7e-35 & 1.4e-02 & 1.4e-02 & 3.6e-02 & 1.8e-33 & 1.8e-33 & 1.4e-02 & 1.4e-02 & 2.4e-02 \\\\\n",
      "haberman & 5.2e-34 & 5.2e-34 & 9.7e-03 & 9.7e-03 & 2.8e-02 & 1.2e-33 & 1.2e-33 & 1.1e-02 & 1.1e-02 & 2.4e-02 \\\\\n",
      "hepati & 1.9e-34 & 1.9e-34 & 2.2e-02 & 2.2e-02 & 2.7e-02 & 5.2e-33 & 5.2e-33 & 1.4e-02 & 1.4e-02 & 2.3e-02 \\\\\n",
      "transfusion & 2.8e-34 & 2.8e-34 & 8.7e-03 & 8.7e-03 & 2.5e-02 & 2.9e-33 & 2.9e-33 & 7.9e-03 & 7.9e-03 & 2.4e-02 \\\\\n",
      "spect & 0.0e+00 & 0.0e+00 & 7.2e-03 & 7.2e-03 & 2.2e-02 & 1.5e-33 & 1.5e-33 & 6.0e-03 & 6.0e-03 & 2.0e-02 \\\\\n",
      "heartS & 1.6e-33 & 1.6e-33 & 1.9e-02 & 1.9e-02 & 2.2e-02 & 4.3e-33 & 4.3e-33 & 1.7e-02 & 1.7e-02 & 2.0e-02 \\\\\n",
      "heartH & 2.6e-33 & 2.6e-33 & 1.7e-02 & 1.7e-02 & 2.1e-02 & 4.9e-33 & 4.9e-33 & 1.1e-02 & 1.1e-02 & 2.0e-02 \\\\\n",
      "heartC & 0.0e+00 & 0.0e+00 & 1.2e-02 & 1.2e-02 & 2.0e-02 & 2.7e-33 & 2.7e-33 & 1.2e-02 & 1.2e-02 & 2.0e-02 \\\\\n",
      "je4243 & 5.3e-34 & 5.3e-34 & 1.0e-02 & 1.0e-02 & 2.1e-02 & 5.0e-33 & 5.0e-33 & 9.7e-03 & 9.7e-03 & 2.0e-02 \\\\\n",
      "vote & 0.0e+00 & 0.0e+00 & 1.4e-02 & 1.4e-02 & 2.0e-02 & 6.5e-33 & 6.5e-33 & 1.1e-02 & 1.1e-02 & 1.9e-02 \\\\\n",
      "kc2 & 7.7e-34 & 7.7e-34 & 1.8e-02 & 1.8e-02 & 2.0e-02 & 5.0e-34 & 5.0e-34 & 7.2e-03 & 7.2e-03 & 1.9e-02 \\\\\n",
      "\\hline\n",
      "Average & 6.0e-34 & 6.0e-34 & 1.4e-02 & 1.4e-02 & 2.4e-02 & 3.3e-33 & 3.3e-33 & 1.1e-02 & 1.1e-02 & 2.1e-02 \\\\\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats as st\n",
    "stab_rank = {}\n",
    "stab_val = {}\n",
    "stab_res = {}\n",
    "rob_rank = {}\n",
    "rob_val = {}\n",
    "rob_proba = []\n",
    "average_results = {}\n",
    "for a in ['xGB', 'RF']:\n",
    "    average_results[a+'_stab_ce'] = []\n",
    "    average_results[a+'_stab_cce'] = []\n",
    "    average_results[a+'_rob_ce'] = []\n",
    "    average_results[a+'_rob_cce'] = []\n",
    "    average_results[a+'_rob_proba'] = []\n",
    "\n",
    "n = results['test_size']\n",
    "r = results['num_rep']\n",
    "\n",
    "print(' & xGB & xGB & xGB & xGB & xGB & RF & RF & RF & RF & RF \\\\\\\\')\n",
    "print('Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness & Model Variance & CE Stability & CCE Stability & CE Robustness & CCE Robustness & Model Variance \\\\\\\\\\n\\\\hline')\n",
    "for d in results:\n",
    "    if d in ['test_size', 'num_rep']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    for a in results[d]:\n",
    "        print(' & ', end='')\n",
    "        stability = results[d][a]['stability']\n",
    "        robustness = results[d][a]['robustness']\n",
    "        \n",
    "        for key in ['ce', 'cce']:    \n",
    "            ranks = []\n",
    "            values = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                value = []\n",
    "                for i in range(r):\n",
    "                    rank.append(np.argsort(np.abs(stability[key][i][j]['predict']))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "                values.append(value)\n",
    "            stab_rank[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            value = []\n",
    "            for j in range(n):\n",
    "                value.append([np.mean([stability[key][i][j]['predict'][stab_rank[key][j][0]] for i in range(r)]), np.var([stability[key][i][j]['predict'][stab_rank[key][j][0]] for i in range(r)])])\n",
    "            stab_val[key] = value \n",
    "            \n",
    "            ranks = []\n",
    "            values = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                value = []\n",
    "                for i in range(r):\n",
    "                    rank.append(np.argsort(np.abs(robustness[key][i][j]['predict']))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "                values.append(value)\n",
    "            rob_rank[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            value = []\n",
    "            for j in range(n):\n",
    "                value.append([np.mean([robustness[key][i][j]['predict'][rob_rank[key][j][0]] for i in range(r)]), np.var([robustness[key][i][j]['predict'][rob_rank[key][j][0]] for i in range(r)])])\n",
    "            rob_val[key] = value\n",
    "        \n",
    "        for inst in range(n):\n",
    "            rob_proba.append(np.var([robustness['proba'][j][inst] for j in range(r)]))\n",
    "        \n",
    "        # print(stab_rank)\n",
    "        # print(stab_val)\n",
    "        average_results[a+'_stab_ce'].append(np.mean([t[1] for t in stab_val[\"ce\"]]))\n",
    "        average_results[a+'_stab_cce'].append(np.mean([t[1] for t in stab_val[\"cce\"]]))\n",
    "        average_results[a+'_rob_ce'].append(np.mean([t[1] for t in rob_val[\"ce\"]]))\n",
    "        average_results[a+'_rob_cce'].append(np.mean([t[1] for t in rob_val[\"cce\"]]))\n",
    "        average_results[a+'_rob_proba'].append(np.mean(rob_proba))\n",
    "        # print(f'{np.mean([t[1] if t[1] > 1e-20 else 0 for t in stab_val[\"ce\"]]):.1e} & {np.mean([t[1] if t[1] > 1e-20 else 0 for t in stab_val[\"cce\"]]):.1e} & ',end='')\n",
    "        # print(f'{np.mean([t[1] if t[1] > 1e-20 else 0 for t in rob_val[\"ce\"]]):.1e} & {np.mean([t[1] if t[1] > 1e-20 else 0 for t in rob_val[\"cce\"]]):.1e} & ',end='')\n",
    "        print(f'{np.mean([t[1] for t in stab_val[\"ce\"]]):.1e} & {np.mean([t[1] for t in stab_val[\"cce\"]]):.1e} & ',end='')\n",
    "        print(f'{np.mean([t[1] for t in rob_val[\"ce\"]]):.1e} & {np.mean([t[1] for t in rob_val[\"cce\"]]):.1e} & ',end='')\n",
    "        print(f'{np.mean(rob_proba):.1e}', end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    print(' & ', end='')\n",
    "    print(f'{np.mean(average_results[a+\"_stab_ce\"]):.1e} & {np.mean(average_results[a+\"_stab_cce\"]):.1e} & ',end='')\n",
    "    print(f'{np.mean(average_results[a+\"_rob_ce\"]):.1e} & {np.mean(average_results[a+\"_rob_cce\"]):.1e} & ',end='')\n",
    "    print(f'{np.mean(average_results[a+\"_rob_proba\"]):.1e}', end='')\n",
    "print(' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the stability is practically 0 for both factual CE (CE) and conterfactual CE (CCE), illustrating that the method is stable by definition. The robustness is also low, even if the mean variance is non-negligible. However, the robustness is low in comparison to the variance of the probability estimates used as reference, having on average about half the size of the variance of the probability estimates. This indicates that the method is fairly robust to perturbations such as variations of the calibration set and the model. \n",
    "\n",
    "### 4 Computing time\n",
    "Now, lets look at the times taken to compute the explanations. The tabulated computing times are the average time in seconds. The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " & xGB & xGB & xGB & xGB & RF & RF & RF & RF \\\\\n",
      "Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness  & CE Stability & CCE Stability& CE Robustness & CCE Robustness \\\\\n",
      "\\hline\n",
      "pc1req & 0.09 & 0.09 & 0.09 & 0.09 & 0.23 & 0.23 & 0.23 & 0.23 \\\\\n",
      "haberman & 0.06 & 0.06 & 0.06 & 0.06 & 0.14 & 0.14 & 0.14 & 0.15 \\\\\n",
      "hepati & 0.19 & 0.23 & 0.20 & 0.23 & 0.47 & 0.55 & 0.46 & 0.55 \\\\\n",
      "transfusion & 0.08 & 0.08 & 0.08 & 0.08 & 0.18 & 0.18 & 0.19 & 0.19 \\\\\n",
      "spect & 0.15 & 0.15 & 0.15 & 0.15 & 0.34 & 0.34 & 0.33 & 0.32 \\\\\n",
      "heartS & 0.16 & 0.19 & 0.16 & 0.19 & 0.37 & 0.44 & 0.38 & 0.45 \\\\\n",
      "heartH & 0.17 & 0.20 & 0.17 & 0.20 & 0.42 & 0.48 & 0.44 & 0.52 \\\\\n",
      "heartC & 0.20 & 0.23 & 0.21 & 0.25 & 0.51 & 0.56 & 0.50 & 0.58 \\\\\n",
      "je4243 & 0.16 & 0.16 & 0.16 & 0.16 & 0.38 & 0.38 & 0.40 & 0.40 \\\\\n",
      "vote & 0.11 & 0.11 & 0.11 & 0.10 & 0.25 & 0.25 & 0.24 & 0.24 \\\\\n",
      "kc2 & 0.37 & 0.49 & 0.40 & 0.51 & 0.91 & 1.19 & 0.93 & 1.19 \\\\\n",
      "\\hline\n",
      "Average & 0.16 & 0.18 & 0.16 & 0.18 & 0.38 & 0.43 & 0.39 & 0.44 \\\\\n"
     ]
    }
   ],
   "source": [
    "s_timer = []\n",
    "r_timer = []\n",
    "n = results['test_size']\n",
    "r = results['num_rep']\n",
    "average_time = {}\n",
    "for a in ['xGB', 'RF']:\n",
    "    average_time[a+'_stab_ce'] = []\n",
    "    average_time[a+'_stab_cce'] = []\n",
    "    average_time[a+'_rob_ce'] = []\n",
    "    average_time[a+'_rob_cce'] = []\n",
    "\n",
    "print(' & xGB & xGB & xGB & xGB & RF & RF & RF & RF \\\\\\\\')\n",
    "print('Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness  & CE Stability & CCE Stability& CE Robustness & CCE Robustness \\\\\\\\\\n\\\\hline')\n",
    "for d in results:\n",
    "    if d in ['test_size', 'num_rep']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    for a in results[d]:\n",
    "        print(' & ', end='')\n",
    "        s_time = results[d][a]['stab_timer']\n",
    "        r_time = results[d][a]['rob_timer']\n",
    "        average_time[a+'_stab_ce'].append(np.mean([t/n for t in s_time[\"ce\"]]))\n",
    "        average_time[a+'_stab_cce'].append(np.mean([t/n for t in s_time[\"cce\"]]))\n",
    "        average_time[a+'_rob_ce'].append(np.mean([t/n for t in r_time[\"ce\"]]))\n",
    "        average_time[a+'_rob_cce'].append(np.mean([t/n for t in r_time[\"cce\"]]))\n",
    "        print(f'{np.mean([t/n for t in s_time[\"ce\"]]):.2f} & {np.mean([t/n for t in s_time[\"cce\"]]):.2f} & ',end='')\n",
    "        print(f'{np.mean([t/n for t in r_time[\"ce\"]]):.2f} & {np.mean([t/n for t in r_time[\"cce\"]]):.2f}',end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    print(' & ', end='')\n",
    "    print(f'{np.mean(average_time[a+\"_stab_ce\"]):.2f} & {np.mean(average_time[a+\"_stab_cce\"]):.2f} & ',end='')\n",
    "    print(f'{np.mean(average_time[a+\"_rob_ce\"]):.2f} & {np.mean(average_time[a+\"_rob_cce\"]):.2f}',end='')\n",
    "print(' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the computing time is fairly low for both CE and CCE. As expected, there is very little difference between the two methods. The computing time for the factual CE is slightly lower than for the CCE. This is because the CCE method computes the counterfactuals, which occasionally require some additional calculations. The main difference in time stems from the underlying model used, with xGBoost being about twice as fast as Random Forest. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "168dd73c7a7b76a0355e35f33a90e68c167b1dbb1e524891be00dd5c7b8524eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
