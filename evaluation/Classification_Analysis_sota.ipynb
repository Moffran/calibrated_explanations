{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrated Explanations for Binary Classification\n",
    "## Stability and Robustness\n",
    "\n",
    "Author: Tuwe Löfström (tuwe.lofstrom@ju.se)  \n",
    "Copyright 2023 Tuwe Löfström  \n",
    "License: BSD 3 clause\n",
    "Sources:\n",
    "1. [\"Calibrated Explanations: with Uncertainty Information and Counterfactuals\"](https://arxiv.org/abt/2305.02305) by [Helena Löfström](https://github.com/Moffran), [Tuwe Löfström](https://github.com/tuvelofstrom), Ulf Johansson, and Cecilia Sönströd.\n",
    "\n",
    "### 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import stats as st"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Import results from the pickled result file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results_sota.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "with open('results_stab_rob.pkl', 'rb') as f:\n",
    "    ce = pickle.load(f)\n",
    "data_characteristics = {'colic': 60, \n",
    "                        'creditA': 43, \n",
    "                        'diabetes': 9, \n",
    "                        'german': 28, \n",
    "                        'haberman': 4, \n",
    "                        'haberman': 4,\n",
    "                        'heartC': 23,\n",
    "                        'heartH': 21,\n",
    "                        'heartS': 14,\n",
    "                        'hepati': 20,\n",
    "                        'iono': 34,\n",
    "                        'je4042': 9,\n",
    "                        'je4243': 9, \n",
    "                        'kc1': 22,\n",
    "                        'kc2': 22,\n",
    "                        'kc3': 40,\n",
    "                        'liver': 7,\n",
    "                        'pc1req': 9,\n",
    "                        'pc4': 38,\n",
    "                        'sonar': 61,\n",
    "                        'spect': 23,\n",
    "                        'spectf': 45,\n",
    "                        'transfusion': 5,\n",
    "                        'ttt': 28,\n",
    "                        'vote': 17,\n",
    "                        'wbc': 10,}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Stability and Robustness\n",
    "Create a table with the robustness and stability results. The stability results stem from experiments where the same model, calibration set and test set have been explained 30 times. The only source of variation is the random seed. The robustness results stem from experiments where training and calibration sets have been randomly resampled before a new model have been trained and explained. The experiment where run 30 times and the test set was the same for all models. The robustness is measured in this way to avoid inferring perturbed instances which are not from the same distribution as the test instances being explained. The probability estimate of each of the models was computed on the same test set, as comparison to the robustness results. The expectation is that a stable and robust explanation method should result in low variance in the feature importance weights.\n",
    "\n",
    "Everything was run on 25 datasets. See the `Classification_Experiment_stab_rob.py` for details on the experiment.\n",
    "\n",
    "The tabulated results are the mean variance of the stability and robustness measured over the 30 runs and 20 instances. The variance is measured per instance and computed over the 30 runs on the feature importance weight of the most influential feature, defined as the feature most often having highest absolute feature importance weight. The average variance is computed over the 20 instances. The most influential feature is used since it is the feature that is most likely to be used in a decision but also the feature with the greatest expected variation (as a consequence of the weights having the highest absolute values). \n",
    "\n",
    "The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stability & xGB & xGB & xGB & xGB & xGB & xGB \\\\\n",
      "Dataset & CE & CCE & L_VA & S_VA & L & S \\\\\n",
      "\\hline\n",
      "colic & 3.9e-35 & 3.9e-35 & 1.4e-08 & 3.2e-33 & 3.8e-05 & 8.8e-05 \\\\\n",
      "creditA & 1.5e-34 & 1.5e-34 & 1.1e-61 & 0.0e+00 & 3.8e-05 & 1.5e-04 \\\\\n",
      "diabetes & 1.2e-33 & 1.2e-33 & 3.7e-11 & 0.0e+00 & 9.0e-05 & 3.1e-33 \\\\\n",
      "german & 1.2e-34 & 1.2e-34 & 5.6e-11 & 9.1e-33 & 8.0e-05 & 9.5e-05 \\\\\n",
      "haberman & 5.2e-34 & 5.2e-34 & 1.1e-63 & 0.0e+00 & 1.0e-04 & 2.7e-33 \\\\\n",
      "heartC & 0.0e+00 & 0.0e+00 & 1.8e-10 & 1.2e-32 & 7.1e-05 & 1.1e-04 \\\\\n",
      "heartH & 2.6e-33 & 2.6e-33 & 1.9e-10 & 0.0e+00 & 5.4e-05 & 9.1e-05 \\\\\n",
      "heartS & 1.6e-33 & 1.6e-33 & 7.1e-11 & 6.3e-33 & 6.2e-05 & 5.7e-05 \\\\\n",
      "hepati & 1.9e-34 & 1.9e-34 & 6.5e-05 & 4.9e-33 & 3.0e-05 & 5.9e-05 \\\\\n",
      "iono & 4.1e-35 & 4.1e-35 & 3.3e-05 & 1.0e-32 & 8.6e-05 & 1.3e-04 \\\\\n",
      "je4042 & 1.5e-33 & 1.5e-33 & 1.6e-06 & 1.1e-32 & 9.6e-05 & 4.8e-33 \\\\\n",
      "je4243 & 5.3e-34 & 5.3e-34 & 5.3e-06 & 1.9e-34 & 9.2e-05 & 2.1e-33 \\\\\n",
      "kc1 & 5.4e-34 & 5.4e-34 & 1.4e-05 & 0.0e+00 & 1.1e-04 & 9.1e-05 \\\\\n",
      "kc2 & 7.7e-34 & 7.7e-34 & 3.6e-64 & 0.0e+00 & 6.7e-05 & 1.9e-04 \\\\\n",
      "kc3 & 1.4e-35 & 1.4e-35 & 4.1e-06 & 0.0e+00 & 2.6e-05 & 8.1e-05 \\\\\n",
      "liver & 2.2e-33 & 2.2e-33 & 1.2e-63 & 0.0e+00 & 1.1e-04 & 5.9e-33 \\\\\n",
      "pc1req & 7.7e-35 & 7.7e-35 & 1.2e-11 & 3.1e-33 & 7.7e-05 & 5.1e-33 \\\\\n",
      "pc4 & 3.7e-34 & 3.7e-34 & 8.8e-63 & 0.0e+00 & 4.1e-05 & 1.6e-04 \\\\\n",
      "sonar & 1.8e-34 & 1.8e-34 & 7.9e-07 & 7.7e-35 & 8.8e-05 & 1.3e-04 \\\\\n",
      "spect & 0.0e+00 & 0.0e+00 & 3.2e-12 & 1.1e-32 & 1.4e-05 & 3.1e-05 \\\\\n",
      "spectf & 4.6e-34 & 4.6e-34 & 6.9e-66 & 0.0e+00 & 2.8e-05 & 1.1e-04 \\\\\n",
      "transfusion & 2.8e-34 & 2.8e-34 & 6.5e-64 & 0.0e+00 & 7.4e-05 & 2.6e-33 \\\\\n",
      "ttt & 0.0e+00 & 0.0e+00 & 1.6e-10 & 5.5e-33 & 8.1e-05 & 2.6e-04 \\\\\n",
      "vote & 0.0e+00 & 0.0e+00 & 3.0e-11 & 4.3e-33 & 5.6e-05 & 8.1e-05 \\\\\n",
      "wbc & 5.7e-33 & 5.7e-33 & 3.0e-05 & 0.0e+00 & 9.9e-05 & 2.1e-33 \\\\\n",
      "\\hline\n",
      "Average & 7.6e-34 & 7.6e-34 & 6.2e-06 & 3.3e-33 & 6.8e-05 & 7.7e-05 \\\\\n"
     ]
    }
   ],
   "source": [
    "stab_rank = {}\n",
    "stab_val = {}\n",
    "average_results = {}\n",
    "for a in ['xGB','RF']:\n",
    "    average_results[a+'_stab_ce'] = {}\n",
    "    average_results[a+'_stab_cce'] = {}\n",
    "    average_results[a+'_stab_lime'] = {}\n",
    "    average_results[a+'_stab_lime_va'] = {}\n",
    "    average_results[a+'_stab_shap'] = {}\n",
    "    average_results[a+'_stab_shap_va'] = {}\n",
    "\n",
    "n = results['test_size']\n",
    "r = results['num_rep']\n",
    "print('Stability & xGB & xGB & xGB & xGB & xGB & xGB \\\\\\\\')\n",
    "print('Dataset & CE & CCE & L_VA & S_VA & L & S \\\\\\\\\\n\\\\hline')\n",
    "for d in np.sort([k for k in results.keys()]):\n",
    "    if d in ['test_size', 'num_rep']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    algorithms = results[d].keys()\n",
    "    for a in algorithms:\n",
    "        stability = ce[d][a]['stability']\n",
    "        \n",
    "        for key in ['ce', 'cce']:    \n",
    "            ranks = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                for i in range(r):\n",
    "                    rank.append(np.argsort(np.abs(stability[key][i][j]['predict']))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "            stab_rank[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            value = []\n",
    "            for j in range(n):\n",
    "                value.append([np.mean([stability[key][i][j]['predict'][stab_rank[key][j]] for i in range(r)]), np.var([stability[key][i][j]['predict'][stab_rank[key][j]] for i in range(r)])])\n",
    "            stab_val[key] = value \n",
    "\n",
    "        stability = results[d][a]['stability']\n",
    "                    \n",
    "        for key in ['lime', 'lime_va', 'shap', 'shap_va']:    \n",
    "            ranks = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                for i in range(r):\n",
    "                    rank.append(np.argsort(np.abs(stability[key][i][j]))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "            stab_rank[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            value = []\n",
    "            for j in range(n):\n",
    "                value.append([np.mean([stability[key][i][j][stab_rank[key][j]] for i in range(r)]), np.var([stability[key][i][j][stab_rank[key][j]] for i in range(r)])])\n",
    "            stab_val[key] = value \n",
    "        \n",
    "        for key in ['ce', 'cce', 'lime', 'lime_va', 'shap', 'shap_va']:\n",
    "            average_results[a+'_stab_'+key][d] = np.mean([t[1] for t in stab_val[key]])\n",
    "        # print(f'{np.mean([t[1] if t[1] > 1e-20 else 0 for t in stab_val[\"ce\"]]):.1e} & {np.var([t[1] if t[1] > 1e-20 else 0 for t in stab_val[\"cce\"]]):.1e} & ',end='')\n",
    "        \n",
    "        for key in ['ce', 'cce', 'lime_va', 'shap_va', 'lime', 'shap']:\n",
    "            print(f' & {average_results[a+\"_stab_\"+key][d]:.1e}',end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in algorithms:\n",
    "    for key in ['ce', 'cce', 'lime_va', 'shap_va', 'lime', 'shap']:\n",
    "        print(f' & {np.mean([v for v in average_results[a+\"_stab_\"+key].values()]):.1e}',end='')\n",
    "print(' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen above, the stability is practically 0 for both factual CE (CE) and counterfactual CE (CCE), illustrating that the method is stable by definition. Explanations extracted using SHAP (S_VA) from calibrated models are also practically 0. LIME on calibrated models (L_VA) and both LIME (L) and SHAP (S) on uncalibrated models are clearly less stable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Robustness & xGB & xGB & xGB & xGB & xGB & xGB & xGB & xGB \\\\\n",
      "Dataset & CE & CCE & L_VA & S_VA & VA & L & S & UC \\\\\n",
      "\\hline\n",
      "colic & 0.015 & 0.015 & 0.001 & 0.000 & 0.000 & 0.006 & 0.002 & 0.015 \\\\\n",
      "creditA & 0.022 & 0.022 & 0.000 & 0.000 & 0.000 & 0.002 & 0.002 & 0.014 \\\\\n",
      "diabetes & 0.017 & 0.017 & 0.000 & 0.000 & 0.001 & 0.004 & 0.005 & 0.020 \\\\\n",
      "german & 0.003 & 0.003 & 0.006 & 0.002 & 0.002 & 0.006 & 0.006 & 0.022 \\\\\n",
      "haberman & 0.010 & 0.010 & 0.000 & 0.000 & 0.003 & 0.008 & 0.011 & 0.024 \\\\\n",
      "heartC & 0.012 & 0.012 & 0.001 & 0.001 & 0.003 & 0.006 & 0.004 & 0.025 \\\\\n",
      "heartH & 0.017 & 0.017 & 0.171 & 0.002 & 0.003 & 0.006 & 0.004 & 0.025 \\\\\n",
      "heartS & 0.019 & 0.019 & 0.001 & 0.001 & 0.002 & 0.005 & 0.003 & 0.027 \\\\\n",
      "hepati & 0.022 & 0.022 & 0.000 & 0.001 & 0.003 & 0.011 & 0.006 & 0.028 \\\\\n",
      "iono & 0.028 & 0.028 & 0.025 & 0.005 & 0.003 & 0.015 & 0.004 & 0.025 \\\\\n",
      "je4042 & 0.018 & 0.018 & 0.004 & 0.001 & 0.003 & 0.013 & 0.010 & 0.027 \\\\\n",
      "je4243 & 0.010 & 0.010 & 0.003 & 0.000 & 0.003 & 0.005 & 0.008 & 0.027 \\\\\n",
      "kc1 & 0.011 & 0.011 & 0.002 & 0.000 & 0.003 & 0.002 & 0.003 & 0.027 \\\\\n",
      "kc2 & 0.018 & 0.018 & 0.000 & 0.000 & 0.003 & 0.011 & 0.009 & 0.028 \\\\\n",
      "kc3 & 0.007 & 0.007 & 0.013 & 0.000 & 0.004 & 0.003 & 0.001 & 0.027 \\\\\n",
      "liver & 0.025 & 0.025 & 0.000 & 0.000 & 0.004 & 0.003 & 0.006 & 0.027 \\\\\n",
      "pc1req & 0.014 & 0.014 & 0.009 & 0.004 & 0.004 & 0.017 & 0.011 & 0.028 \\\\\n",
      "pc4 & 0.009 & 0.009 & 0.000 & 0.000 & 0.004 & 0.002 & 0.002 & 0.027 \\\\\n",
      "sonar & 0.019 & 0.019 & 0.001 & 0.001 & 0.004 & 0.006 & 0.004 & 0.027 \\\\\n",
      "spect & 0.007 & 0.007 & 0.003 & 0.001 & 0.004 & 0.003 & 0.002 & 0.026 \\\\\n",
      "spectf & 0.006 & 0.006 & 0.000 & 0.000 & 0.004 & 0.001 & 0.002 & 0.026 \\\\\n",
      "transfusion & 0.009 & 0.009 & 0.000 & 0.000 & 0.004 & 0.004 & 0.008 & 0.026 \\\\\n",
      "ttt & 0.017 & 0.017 & 0.000 & 0.003 & 0.004 & 0.001 & 0.002 & 0.025 \\\\\n",
      "vote & 0.014 & 0.014 & 0.001 & 0.001 & 0.004 & 0.002 & 0.002 & 0.025 \\\\\n",
      "wbc & 0.021 & 0.021 & 0.001 & 0.000 & 0.004 & 0.008 & 0.003 & 0.025 \\\\\n",
      "\\hline\n",
      "Average & 0.015 & 0.015 & 0.010 & 0.001 & 0.003 & 0.006 & 0.005 & 0.025 \\\\\n"
     ]
    }
   ],
   "source": [
    "rob_rank = {}\n",
    "rob_val = {}\n",
    "rob_proba = []\n",
    "rob_proba_va = []\n",
    "# average_results = {}\n",
    "for a in ['xGB','RF']:\n",
    "    average_results[a+'_rob_ce'] = {}\n",
    "    average_results[a+'_rob_cce'] = {}\n",
    "    average_results[a+'_rob_lime'] = {}\n",
    "    average_results[a+'_rob_lime_va'] = {}\n",
    "    average_results[a+'_rob_shap'] = {}\n",
    "    average_results[a+'_rob_shap_va'] = {}\n",
    "    average_results[a+'_rob_proba'] = {}\n",
    "    average_results[a+'_rob_proba_va'] = {}\n",
    "\n",
    "n = results['test_size']\n",
    "r = results['num_rep']\n",
    "\n",
    "print('Robustness & xGB & xGB & xGB & xGB & xGB & xGB & xGB & xGB \\\\\\\\')\n",
    "print('Dataset & CE & CCE & L_VA & S_VA & VA & L & S & UC \\\\\\\\\\n\\\\hline')\n",
    "for d in np.sort([k for k in results.keys()]):\n",
    "    if d in ['test_size', 'num_rep']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    algorithms = results[d].keys()\n",
    "    for a in algorithms:\n",
    "        robustness = ce[d][a]['robustness']\n",
    "        \n",
    "        for key in ['ce', 'cce']:                \n",
    "            ranks = []\n",
    "            values = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                value = []\n",
    "                for i in range(r):\n",
    "                    rank.append(np.argsort(np.abs(robustness[key][i][j]['predict']))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "                values.append(value)\n",
    "            rob_rank[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            value = []\n",
    "            for j in range(n):\n",
    "                value.append([np.mean([robustness[key][i][j]['predict'][rob_rank[key][j]] for i in range(r)]), np.var([robustness[key][i][j]['predict'][rob_rank[key][j]] for i in range(r)])])\n",
    "            rob_val[key] = value\n",
    "\n",
    "        robustness = results[d][a]['robustness']\n",
    "            \n",
    "        for key in ['lime', 'lime_va', 'shap', 'shap_va']:    \n",
    "            ranks = []\n",
    "            for j in range(n):\n",
    "                rank = []\n",
    "                for i in range(r):\n",
    "                    rank.append(np.argsort(np.abs(robustness[key][i][j]))[-1:][0])\n",
    "                ranks.append(rank)\n",
    "            rob_rank[key] = st.mode(ranks, axis=1)[0] # Find most important feature per instance\n",
    "            value = []\n",
    "            for j in range(n):\n",
    "                value.append([np.mean([robustness[key][i][j][rob_rank[key][j]] for i in range(r)]), np.var([robustness[key][i][j][rob_rank[key][j]] for i in range(r)])])\n",
    "            rob_val[key] = value \n",
    "        \n",
    "        for inst in range(n):\n",
    "            rob_proba.append(np.var([robustness['proba'][j][inst] for j in range(r)]))\n",
    "            rob_proba_va.append(np.var([robustness['proba_va'][j][inst] for j in range(r)]))\n",
    "        \n",
    "        for key in ['ce', 'cce', 'lime', 'lime_va', 'shap', 'shap_va']:\n",
    "            average_results[a+'_rob_'+key][d] = np.mean([t[1] for t in rob_val[key]])\n",
    "        average_results[a+'_rob_proba'][d] = np.mean(rob_proba)\n",
    "        average_results[a+'_rob_proba_va'][d] = np.mean(rob_proba_va)\n",
    "        # print(f'{np.mean([t[1] if t[1] > 1e-20 else 0 for t in rob_val[\"ce\"]]):.1e} & {np.mean([t[1] if t[1] > 1e-20 else 0 for t in rob_val[\"cce\"]]):.1e} & ',end='')\n",
    "        \n",
    "        for key in ['ce', 'cce', 'lime_va', 'shap_va', 'proba_va', 'lime', 'shap', 'proba']:\n",
    "            print(f' & {average_results[a+\"_rob_\"+key][d]:.3f}',end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in algorithms:\n",
    "    for key in ['ce', 'cce', 'lime_va', 'shap_va', 'proba_va', 'lime', 'shap', 'proba']:\n",
    "        print(f' & {np.mean([v for v in average_results[a+\"_rob_\"+key].values()]):.3f}',end='')\n",
    "print(' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The robustness is not yet analyzed.  \n",
    "\n",
    "### 4 Computing time- not updated\n",
    "Now, lets look at the runtime taken to compute the explanations. The tabulated runtimes are the average time in seconds per instance. The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime & xGB & xGB & xGB & xGB & RF & RF & RF & RF & \\\\\n",
      "Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness & CE Stability & CCE Stability & CE Robustness & CCE Robustness & #Features\\\\\n",
      "\\hline\n",
      "colic & 0.38 & 0.41 & 0.38 & 0.41 & 1.03 & 1.12 & 1.05 & 3.40 & 60 \\\\\n",
      "creditA & 0.37 & 0.39 & 0.37 & 0.40 & 0.94 & 1.01 & 0.94 & 1.01 & 43 \\\\\n",
      "diabetes & 0.13 & 0.17 & 0.13 & 0.17 & 0.35 & 0.46 & 0.35 & 0.47 & 9 \\\\\n",
      "german & 0.18 & 0.18 & 0.19 & 0.19 & 0.45 & 0.45 & 0.46 & 0.46 & 28 \\\\\n",
      "haberman & 0.06 & 0.06 & 0.06 & 0.06 & 0.14 & 0.14 & 0.14 & 0.15 & 4 \\\\\n",
      "heartC & 0.20 & 0.23 & 0.21 & 0.25 & 0.51 & 0.56 & 0.50 & 0.58 & 23 \\\\\n",
      "heartH & 0.17 & 0.20 & 0.17 & 0.20 & 0.42 & 0.48 & 0.44 & 0.52 & 21 \\\\\n",
      "heartS & 0.16 & 0.19 & 0.16 & 0.19 & 0.37 & 0.44 & 0.38 & 0.45 & 14 \\\\\n",
      "hepati & 0.19 & 0.23 & 0.20 & 0.23 & 0.47 & 0.55 & 0.46 & 0.55 & 20 \\\\\n",
      "iono & 0.50 & 0.73 & 0.52 & 0.75 & 1.22 & 1.76 & 1.21 & 1.77 & 34 \\\\\n",
      "je4042 & 0.14 & 0.14 & 0.15 & 0.15 & 0.36 & 0.36 & 0.36 & 0.36 & 9 \\\\\n",
      "je4243 & 0.16 & 0.16 & 0.16 & 0.16 & 0.38 & 0.38 & 0.40 & 0.40 & 9 \\\\\n",
      "kc1 & 0.36 & 0.45 & 0.36 & 0.46 & 0.91 & 1.16 & 0.89 & 1.13 & 22 \\\\\n",
      "kc2 & 0.37 & 0.49 & 0.40 & 0.51 & 0.91 & 1.19 & 0.93 & 1.19 & 22 \\\\\n",
      "kc3 & 0.67 & 0.81 & 0.68 & 0.82 & 1.66 & 1.98 & 1.66 & 2.00 & 40 \\\\\n",
      "liver & 0.10 & 0.14 & 0.10 & 0.14 & 0.25 & 0.35 & 0.26 & 0.36 & 7 \\\\\n",
      "pc1req & 0.09 & 0.09 & 0.09 & 0.09 & 0.23 & 0.23 & 0.23 & 0.23 & 9 \\\\\n",
      "pc4 & 0.59 & 0.76 & 0.54 & 0.71 & 1.53 & 2.00 & 1.54 & 3.38 & 38 \\\\\n",
      "sonar & 1.04 & 1.38 & 1.05 & 1.38 & 2.56 & 3.41 & 2.52 & 3.32 & 61 \\\\\n",
      "spect & 0.15 & 0.15 & 0.15 & 0.15 & 0.34 & 0.34 & 0.33 & 0.32 & 23 \\\\\n",
      "spectf & 0.77 & 0.77 & 0.78 & 0.78 & 1.89 & 1.89 & 1.83 & 1.84 & 45 \\\\\n",
      "transfusion & 0.08 & 0.08 & 0.08 & 0.08 & 0.18 & 0.18 & 0.19 & 0.19 & 5 \\\\\n",
      "ttt & 0.16 & 0.16 & 0.16 & 0.16 & 0.41 & 0.42 & 0.48 & 0.50 & 28 \\\\\n",
      "vote & 0.11 & 0.11 & 0.11 & 0.10 & 0.25 & 0.25 & 0.24 & 0.24 & 17 \\\\\n",
      "wbc & 0.17 & 0.20 & 0.17 & 0.20 & 0.40 & 0.48 & 0.39 & 0.47 & 10 \\\\\n",
      "\\hline\n",
      "Average & 0.29 & 0.35 & 0.29 & 0.35 & 0.73 & 0.86 & 0.73 & 1.01 & 24.0 \\\\\n"
     ]
    }
   ],
   "source": [
    "results = ce\n",
    "s_timer = []\n",
    "r_timer = []\n",
    "n = results['test_size']\n",
    "r = results['num_rep']\n",
    "average_time = {}\n",
    "average_time['num_features'] = []\n",
    "for a in ['xGB', 'RF']:\n",
    "    average_time[a+'_stab_ce'] = []\n",
    "    average_time[a+'_stab_cce'] = []\n",
    "    average_time[a+'_rob_ce'] = []\n",
    "    average_time[a+'_rob_cce'] = []\n",
    "\n",
    "print('Runtime & xGB & xGB & xGB & xGB & RF & RF & RF & RF & \\\\\\\\')\n",
    "print('Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness & CE Stability & CCE Stability & CE Robustness & CCE Robustness & #Features\\\\\\\\\\n\\\\hline')\n",
    "for d in np.sort(np.sort([k for k in results.keys()])):\n",
    "    if d in ['test_size', 'num_rep']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    for a in results[d]:\n",
    "        print(' & ', end='')\n",
    "        s_time = results[d][a]['stab_timer']\n",
    "        r_time = results[d][a]['rob_timer']\n",
    "        average_time[a+'_stab_ce'].append(np.mean([t/n for t in s_time[\"ce\"]]))\n",
    "        average_time[a+'_stab_cce'].append(np.mean([t/n for t in s_time[\"cce\"]]))\n",
    "        average_time[a+'_rob_ce'].append(np.mean([t/n for t in r_time[\"ce\"]]))\n",
    "        average_time[a+'_rob_cce'].append(np.mean([t/n for t in r_time[\"cce\"]]))\n",
    "        average_time['num_features'].append(data_characteristics[d])\n",
    "        print(f'{np.mean([t/n for t in s_time[\"ce\"]]):.2f} & {np.mean([t/n for t in s_time[\"cce\"]]):.2f} & ',end='')\n",
    "        print(f'{np.mean([t/n for t in r_time[\"ce\"]]):.2f} & {np.mean([t/n for t in r_time[\"cce\"]]):.2f}',end='')\n",
    "    print(f' & {data_characteristics[d]}', end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    print(' & ', end='')\n",
    "    print(f'{np.mean(average_time[a+\"_stab_ce\"]):.2f} & {np.mean(average_time[a+\"_stab_cce\"]):.2f} & ',end='')\n",
    "    print(f'{np.mean(average_time[a+\"_rob_ce\"]):.2f} & {np.mean(average_time[a+\"_rob_cce\"]):.2f}',end='')\n",
    "print(f' & {np.mean(average_time[\"num_features\"]):.1f}', end='')\n",
    "print(' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the runtime is fairly low for both CE and CCE. As expected, there is very little difference between CE and CCE. The runtime for the factual CE is slightly lower than for the CCE. This is because the CCE method computes the counterfactuals, which occasionally require some additional calculations. The main difference in time stems from the underlying model used, with xGBoost being about twice as fast as Random Forest. \n",
    "\n",
    "It is reassuring that the runtime is close to identical for both the Stability and Robustness experiments. This indicates that the main source affecting runtime is the number of features and the machine learning algorithm used.\n",
    "\n",
    "Finally, lets look at the variation in runtime. The variation is measured as the standard deviation of the runtime over the 30 runs and 20 instances. The average variation is computed over the 20 instances. The results are printed as a latex table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime & xGB & xGB & xGB & xGB & RF & RF & RF & RF \\\\\n",
      "Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness & CE Stability & CCE Stability & CE Robustness & CCE Robustness \\\\\n",
      "\\hline\n",
      "colic & 2.52e-05 & 2.37e-05 & 9.83e-06 & 3.46e-05 & 1.60e-04 & 1.52e-04 & 1.10e-03 & 1.47e+02 \\\\\n",
      "creditA & 4.60e-05 & 2.41e-05 & 3.23e-04 & 2.40e-04 & 1.26e-04 & 2.38e-04 & 1.46e-03 & 1.47e-03 \\\\\n",
      "diabetes & 4.45e-06 & 5.56e-06 & 4.12e-06 & 8.40e-06 & 5.78e-05 & 7.14e-05 & 3.70e-05 & 6.95e-05 \\\\\n",
      "german & 1.56e-05 & 1.79e-05 & 1.07e-05 & 1.00e-05 & 3.73e-04 & 6.88e-04 & 3.93e-05 & 1.93e-05 \\\\\n",
      "haberman & 6.55e-06 & 6.81e-06 & 1.72e-06 & 3.05e-06 & 1.85e-05 & 1.96e-05 & 1.49e-05 & 1.91e-05 \\\\\n",
      "heartC & 1.10e-04 & 9.48e-05 & 4.67e-05 & 1.56e-04 & 4.45e-04 & 6.05e-04 & 3.61e-04 & 4.01e-04 \\\\\n",
      "heartH & 1.18e-05 & 1.10e-05 & 1.08e-05 & 1.55e-05 & 2.99e-05 & 9.33e-06 & 5.30e-04 & 1.38e-03 \\\\\n",
      "heartS & 1.98e-05 & 1.77e-05 & 3.17e-05 & 9.52e-05 & 1.72e-05 & 3.05e-05 & 2.05e-05 & 1.32e-04 \\\\\n",
      "hepati & 1.38e-04 & 2.69e-04 & 9.37e-05 & 2.06e-04 & 5.47e-04 & 8.31e-04 & 3.90e-04 & 7.07e-04 \\\\\n",
      "iono & 1.17e-03 & 2.03e-03 & 2.36e-04 & 3.66e-04 & 1.33e-04 & 4.18e-04 & 1.93e-03 & 2.82e-03 \\\\\n",
      "je4042 & 6.75e-06 & 5.67e-06 & 5.25e-06 & 4.79e-06 & 1.68e-05 & 2.35e-05 & 1.26e-05 & 9.70e-06 \\\\\n",
      "je4243 & 3.21e-05 & 7.69e-05 & 3.20e-05 & 2.77e-05 & 1.85e-04 & 1.15e-04 & 4.08e-04 & 4.12e-04 \\\\\n",
      "kc1 & 6.95e-05 & 9.86e-05 & 3.06e-05 & 6.87e-05 & 1.60e-04 & 4.09e-04 & 2.85e-04 & 1.76e-03 \\\\\n",
      "kc2 & 9.73e-05 & 2.72e-04 & 3.45e-04 & 3.30e-04 & 3.96e-04 & 5.42e-04 & 3.25e-04 & 7.15e-04 \\\\\n",
      "kc3 & 2.30e-04 & 4.40e-04 & 4.50e-04 & 4.32e-04 & 1.71e-03 & 2.74e-03 & 1.64e-03 & 3.51e-03 \\\\\n",
      "liver & 4.31e-06 & 4.48e-06 & 4.05e-06 & 1.50e-05 & 4.15e-06 & 9.10e-06 & 1.57e-04 & 4.07e-04 \\\\\n",
      "pc1req & 1.49e-05 & 2.26e-05 & 4.74e-05 & 4.80e-05 & 1.17e-04 & 7.46e-05 & 2.51e-04 & 2.74e-04 \\\\\n",
      "pc4 & 1.24e-03 & 1.69e-03 & 8.08e-05 & 2.00e-04 & 2.47e-03 & 3.67e-03 & 8.84e-03 & 5.52e+01 \\\\\n",
      "sonar & 3.35e-04 & 5.91e-04 & 6.90e-05 & 5.93e-04 & 1.87e-03 & 2.75e-03 & 4.22e-04 & 2.84e-03 \\\\\n",
      "spect & 6.54e-05 & 4.82e-05 & 1.55e-05 & 3.18e-05 & 1.03e-04 & 1.04e-04 & 2.45e-05 & 1.13e-05 \\\\\n",
      "spectf & 2.96e-04 & 1.87e-04 & 1.07e-04 & 1.07e-04 & 1.52e-03 & 1.39e-03 & 1.17e-04 & 6.55e-05 \\\\\n",
      "transfusion & 6.82e-06 & 8.13e-06 & 7.80e-06 & 5.06e-06 & 8.86e-05 & 4.65e-05 & 1.94e-04 & 7.74e-05 \\\\\n",
      "ttt & 2.30e-05 & 2.07e-05 & 5.94e-06 & 5.17e-06 & 2.28e-04 & 4.35e-04 & 1.45e-02 & 2.15e-02 \\\\\n",
      "vote & 2.22e-05 & 1.20e-05 & 2.22e-05 & 7.12e-06 & 7.94e-05 & 6.85e-05 & 9.89e-06 & 1.47e-05 \\\\\n",
      "wbc & 2.77e-05 & 5.45e-05 & 3.87e-05 & 2.34e-05 & 4.96e-04 & 2.46e-04 & 2.14e-04 & 6.96e-04 \\\\\n",
      "\\hline\n",
      "Average & 1.60e-04 & 2.41e-04 & 8.12e-05 & 1.21e-04 & 4.54e-04 & 6.28e-04 & 1.33e-03 & 8.08e+00 \\\\\n"
     ]
    }
   ],
   "source": [
    "s_timer = []\n",
    "r_timer = []\n",
    "n = results['test_size']\n",
    "r = results['num_rep']\n",
    "average_time = {}\n",
    "for a in ['xGB', 'RF']:\n",
    "    average_time[a+'_stab_ce'] = []\n",
    "    average_time[a+'_stab_cce'] = []\n",
    "    average_time[a+'_rob_ce'] = []\n",
    "    average_time[a+'_rob_cce'] = []\n",
    "\n",
    "print('Runtime & xGB & xGB & xGB & xGB & RF & RF & RF & RF \\\\\\\\')\n",
    "print('Dataset & CE Stability & CCE Stability & CE Robustness & CCE Robustness & CE Stability & CCE Stability & CE Robustness & CCE Robustness \\\\\\\\\\n\\\\hline')\n",
    "for d in np.sort([k for k in results.keys()]):\n",
    "    if d in ['test_size', 'num_rep']:\n",
    "        continue\n",
    "    print(d, end='')\n",
    "    for a in results[d]:\n",
    "        print(' & ', end='')\n",
    "        s_time = results[d][a]['stab_timer']\n",
    "        r_time = results[d][a]['rob_timer']\n",
    "        average_time[a+'_stab_ce'].append(np.var([t/n for t in s_time[\"ce\"]]))\n",
    "        average_time[a+'_stab_cce'].append(np.var([t/n for t in s_time[\"cce\"]]))\n",
    "        average_time[a+'_rob_ce'].append(np.var([t/n for t in r_time[\"ce\"]]))\n",
    "        average_time[a+'_rob_cce'].append(np.var([t/n for t in r_time[\"cce\"]]))\n",
    "        print(f'{np.var([t/n for t in s_time[\"ce\"]]):.2e} & {np.var([t/n for t in s_time[\"cce\"]]):.2e} & ',end='')\n",
    "        print(f'{np.var([t/n for t in r_time[\"ce\"]]):.2e} & {np.var([t/n for t in r_time[\"cce\"]]):.2e}',end='')\n",
    "    print(' \\\\\\\\')\n",
    "print('\\\\hline\\nAverage', end='')\n",
    "for a in ['xGB', 'RF']:\n",
    "    print(' & ', end='')\n",
    "    print(f'{np.mean(average_time[a+\"_stab_ce\"]):.2e} & {np.mean(average_time[a+\"_stab_cce\"]):.2e} & ',end='')\n",
    "    print(f'{np.mean(average_time[a+\"_rob_ce\"]):.2e} & {np.mean(average_time[a+\"_rob_cce\"]):.2e}',end='')\n",
    "print(' \\\\\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the variation in runtime per dataset is small. This indicates that the runtime is fairly stable and that the method is not overly sensitive to changes in the model or calibration set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "168dd73c7a7b76a0355e35f33a90e68c167b1dbb1e524891be00dd5c7b8524eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
