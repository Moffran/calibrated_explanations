{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrated_explanations v0.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from crepes import ConformalPredictiveSystem\n",
    "from crepes.extras import binning, DifficultyEstimator\n",
    "\n",
    "from calibrated_explanations import  VennAbers, __version__\n",
    "from calibrated_explanations.utils import transform_to_numeric\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"calibrated_explanations {__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = {'COMPAS': 'classification', 'Adult': 'classification', 'German': 'classification', 'Housing': 'regression', 'CaC': 'regression'}\n",
    "results = {}\n",
    "for name, type in datasets.items():\n",
    "    results[name] = {}\n",
    "    results[name]['type'] = type\n",
    "    for category in ['mondrian', 'mondrian_x', 'model_split']:\n",
    "        results[name][category] = {'time': 0, 'base': 0, 'rand': 0, 'race': 0, 'sex': 0, 'age': 0, 'edu': 0, 'crm': 0}\n",
    "\n",
    "num_rep = 1\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage(y_true, low, up):\n",
    "    return np.mean((y_true >= low) & (y_true <= up))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS\n",
    "Data preprocessing from [this notebook](https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_COMPAS_with_SHAP.ipynb#scrollTo=KF00pJvkeicT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18316, 40)\n"
     ]
    }
   ],
   "source": [
    "dataset = 'COMPAS'\n",
    "df = pd.read_csv('https://storage.googleapis.com/what-if-tool-resources/computefest2019/cox-violent-parsed_filt.csv')\n",
    "print(df.shape)\n",
    "# Preprocess the data\n",
    "\n",
    "# Filter out entries with no indication of recidivism or no compass score\n",
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['decile_score'] != -1]\n",
    "\n",
    "\n",
    "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
    "df['score_text'] = np.where(df['score_text'] == 'Low', 'Low', 'Not Low')\n",
    "\n",
    "target = 'score_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'score_text']\n",
    "# 'age_cat', 'is_recid', 'vr_charge_desc',  'c_charge_desc',, 'is_violent_recid''vr_charge_degree', 'c_charge_degree', 'decile_score', \n",
    "df = df[features_to_keep]\n",
    "df, categorical_features, categorical_labels, target_labels, mappings = transform_to_numeric(df, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count',\n",
      "       'juv_other_count', 'priors_count', 'score_text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "race = 2\n",
    "age = 1\n",
    "sex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 20 # number of instances to test\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop([target],axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':race, 'sex':sex, 'age':age}\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():                \n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "    \n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()                \n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                uncal = model.predict_proba(X_test_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['uncal'][attr].append(uncal[:,1])\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.0079 \t 0.0072 \t 0.0071\n",
      "rand width: \t 0.0231 \t 0.0219 \t 0.0198\n",
      "race width: \t 0.0192 \t 0.0189 \t 0.0185\n",
      "sex width: \t 0.0122 \t 0.0112 \t 0.0105\n",
      "age width: \t 0.0249 \t 0.0215 \t 0.0205\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base Accuracy: \t 0.7546 \t 0.7742 \t 0.7738 \t 0.7558 \t 0.7764 \t 0.7720\n",
      "rand Accuracy: \t 0.7499 \t 0.7738 \t 0.7292 \t 0.7558 \t 0.7764 \t 0.7276\n",
      "race Accuracy: \t 0.7579 \t 0.7754 \t 0.7720 \t 0.7558 \t 0.7764 \t 0.7702\n",
      "sex Accuracy: \t 0.7559 \t 0.7743 \t 0.7737 \t 0.7558 \t 0.7764 \t 0.7708\n",
      "age Accuracy: \t 0.7522 \t 0.7749 \t 0.7706 \t 0.7558 \t 0.7764 \t 0.7704\n",
      "\n",
      "base LogLoss: \t 0.4960 \t 0.4642 \t 0.4674 \t 0.6682 \t 0.7861 \t 0.7886\n",
      "rand LogLoss: \t 0.5010 \t 0.4685 \t 0.5420 \t 0.6682 \t 0.7861 \t 0.9364\n",
      "race LogLoss: \t 0.4860 \t 0.4631 \t 0.4691 \t 0.6682 \t 0.7861 \t 0.8425\n",
      "sex LogLoss: \t 0.4952 \t 0.4639 \t 0.4665 \t 0.6682 \t 0.7861 \t 0.7958\n",
      "age LogLoss: \t 0.4979 \t 0.4634 \t 0.4713 \t 0.6682 \t 0.7861 \t 0.7943\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Adult'\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<=50K', 1: '>50K'}\n"
     ]
    }
   ],
   "source": [
    "df = X\n",
    "target = 'Income'\n",
    "y = y.replace('<=50K.', '<=50K')\n",
    "y = y.replace('>50K.', '>50K')\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "edu = 3\n",
    "race = 8\n",
    "sex = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':race, 'sex':sex, 'edu':edu}\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():            \n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n"
     ]
    }
   ],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'edu': X_train[:,edu]}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        try:\n",
    "            for attr in attribute_names:\n",
    "                for bin in np.unique(train_bins[attr]):\n",
    "                    X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                    y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                    X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                    y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                    X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                    y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                    if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    model = RandomForestClassifier()\n",
    "                    model.fit(X_train_bin,y_train_bin)\n",
    "                    uncal = model.predict_proba(X_test_bin)\n",
    "                    va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                    proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                    model_split['uncal'][attr].append(uncal[:,1])\n",
    "                    model_split['proba'][attr].append(proba[:,1])\n",
    "                    model_split['low'][attr].append(low)\n",
    "                    model_split['high'][attr].append(high)\n",
    "                    model_split['width'][attr].append(high - low)\n",
    "                    model_split['y'][attr].append(y_test_bin)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'attr: {attr} bin: {bin}')    \n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.0028 \t 0.0029 \t 0.0030\n",
      "rand width: \t 0.0091 \t 0.0096 \t 0.0098\n",
      "race width: \t 0.0064 \t 0.0068 \t 0.0066\n",
      "sex width: \t 0.0045 \t 0.0046 \t 0.0046\n",
      "edu width: \t 0.0153 \t 0.0159 \t 0.0150\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base Accuracy: \t 0.8315 \t 0.8552 \t 0.8547 \t 0.8322 \t 0.8558 \t 0.8545\n",
      "rand Accuracy: \t 0.8308 \t 0.8539 \t 0.8483 \t 0.8322 \t 0.8558 \t 0.8490\n",
      "race Accuracy: \t 0.8311 \t 0.8554 \t 0.8517 \t 0.8322 \t 0.8558 \t 0.8512\n",
      "sex Accuracy: \t 0.8309 \t 0.8553 \t 0.8533 \t 0.8322 \t 0.8558 \t 0.8534\n",
      "edu Accuracy: \t 0.8333 \t 0.8543 \t 0.8495 \t 0.8322 \t 0.8558 \t 0.8487\n",
      "\n",
      "base LogLoss: \t 0.3612 \t 0.3186 \t 0.3180 \t 0.4158 \t 0.3705 \t 0.3670\n",
      "rand LogLoss: \t 0.3628 \t 0.3203 \t 0.3306 \t 0.4158 \t 0.3705 \t 0.3652\n",
      "race LogLoss: \t 0.3616 \t 0.3188 \t 0.3225 \t 0.4158 \t 0.3705 \t 0.3605\n",
      "sex LogLoss: \t 0.3607 \t 0.3179 \t 0.3210 \t 0.4158 \t 0.3705 \t 0.3730\n",
      "edu LogLoss: \t 0.3600 \t 0.3199 \t 0.3313 \t 0.4158 \t 0.3705 \t 0.3901\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'German'\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = statlog_german_credit_data.variables.description[:-1]\n",
    "feature_names[0] = 'Status'\n",
    "feature_names[7] = 'Installment rate'\n",
    "feature_names[15] = 'Existing credits'\n",
    "feature_names[17] = 'Num people liable'\n",
    "target_labels = {1: 'Good', 0: 'Bad'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         Status\n",
      "1                       Duration\n",
      "2                 Credit history\n",
      "3                        Purpose\n",
      "4                  Credit amount\n",
      "5          Savings account/bonds\n",
      "6       Present employment since\n",
      "7               Installment rate\n",
      "8        Personal status and sex\n",
      "9     Other debtors / guarantors\n",
      "10       Present residence since\n",
      "11                      Property\n",
      "12                           Age\n",
      "13       Other installment plans\n",
      "14                       Housing\n",
      "15              Existing credits\n",
      "16                           Job\n",
      "17             Num people liable\n",
      "18                     Telephone\n",
      "19                foreign worker\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)\n",
    "age = 12\n",
    "sex = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X\n",
    "target = 'Class'\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, _, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values\n",
    "y[y == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'sex':sex, 'age':age}\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():\n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()                \n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                uncal = model.predict_proba(X_test_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['uncal'][attr].append(uncal[:,1])\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.0369 \t 0.0467 \t 0.0419\n",
      "rand width: \t 0.1191 \t 0.1350 \t 0.1181\n",
      "sex width: \t 0.0962 \t 0.1008 \t 0.0892\n",
      "age width: \t 0.1198 \t 0.1381 \t 0.1255\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base Accuracy: \t 0.7730 \t 0.7480 \t 0.7390 \t 0.7680 \t 0.7460 \t 0.7520\n",
      "rand Accuracy: \t 0.7620 \t 0.7540 \t 0.7070 \t 0.7680 \t 0.7460 \t 0.7120\n",
      "sex Accuracy: \t 0.7710 \t 0.7370 \t 0.7200 \t 0.7680 \t 0.7460 \t 0.7390\n",
      "age Accuracy: \t 0.7590 \t 0.7660 \t 0.7130 \t 0.7680 \t 0.7460 \t 0.7340\n",
      "\n",
      "base LogLoss: \t 0.5089 \t 0.4988 \t 0.5182 \t 0.5111 \t 0.5037 \t 0.5136\n",
      "rand LogLoss: \t 0.5164 \t 0.5065 \t 0.5572 \t 0.5111 \t 0.5037 \t 0.5483\n",
      "sex LogLoss: \t 0.5151 \t 0.5023 \t 0.5435 \t 0.5111 \t 0.5037 \t 0.5366\n",
      "age LogLoss: \t 0.5242 \t 0.5004 \t 0.5505 \t 0.5111 \t 0.5037 \t 0.5374\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'Housing'\n",
    "df = pd.read_csv('../data/reg/HousingData.csv', na_values='NA')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]\n",
    "print(feature_names)\n",
    "crm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'MEDV'\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "Xd, yd = df.drop(target,axis=1), df[target]\n",
    "X, y = df.drop(target,axis=1).values, df[target].values\n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Regression\n",
    "Default confidence of 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'crm':crm}\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['median'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['median'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        residuals_cal = model.predict(x_cal) - y_cal\n",
    "        y_test_hat = model.predict(x_test)\n",
    "        mondrian_x['y'].append(y_test)        \n",
    "        \n",
    "        for attr, a in attributes.items():                \n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian_x['uncal'][attr].append(y_test_hat)\n",
    "            mondrian_x['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian_x['low'][attr].append(values[:,0])\n",
    "            mondrian_x['high'][attr].append(values[:,2])\n",
    "            mondrian_x['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['median'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['median'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian['uncal'][attr].append(y_test_hat)\n",
    "            mondrian['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian['low'][attr].append(values[:,0])\n",
    "            mondrian['high'][attr].append(values[:,2])\n",
    "            mondrian['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['median'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['median'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "        crm_train_bin = binning(X_train[:,crm], crm_cal_boundaries)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'crm': crm_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin,:]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin,:]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin,:]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestRegressor()\n",
    "                model.fit(X_train_bin, y_train_bin)\n",
    "                \n",
    "                residuals_cal = model.predict(X_cal_bin) - y_cal_bin\n",
    "                y_test_bin_hat = model.predict(X_test_bin)\n",
    "            \n",
    "                cps[attr] = ConformalPredictiveSystem()\n",
    "                cps[attr].fit(residuals_cal)\n",
    "                values = cps[attr].predict(y_test_bin_hat, lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "                model_split['uncal'][attr].append(y_test_bin_hat)\n",
    "                model_split['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "                model_split['low'][attr].append(values[:,0])\n",
    "                model_split['high'][attr].append(values[:,2])\n",
    "                model_split['width'][attr].append(values[:,2]-values[:,0])\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['median'][attr] = np.concatenate(mondrian_x['median'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['median'][attr] = np.concatenate(mondrian['median'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['median'][attr] = np.concatenate(model_split['median'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 12.4268 \t 11.6665 \t 11.6932 \n",
      "rand width: \t 17.0033 \t 16.2824 \t 22.4043 \n",
      "crm width: \t 20.2667 \t 21.4670 \t 21.4383 \n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base MAE: \t 0.9391 \t 0.9289 \t 0.9010\n",
      "rand MAE: \t 0.9112 \t 0.9391 \t 0.8909\n",
      "crm MAE: \t 0.9670 \t 0.9543 \t 0.9594\n",
      "base MAE: \t 2.3866 \t 2.6365 \t 2.4569 \t 2.3834 \t 2.3444 \t 2.4730\n",
      "rand MAE: \t 2.3831 \t 2.6630 \t 3.4656 \t 2.3834 \t 2.3444 \t 3.3479\n",
      "crm MAE: \t 2.4731 \t 2.6402 \t 2.5975 \t 2.3834 \t 2.3444 \t 2.5554\n",
      "base R2: \t 0.8380 \t 0.8177 \t 0.7962 \t 0.8388 \t 0.8349 \t 0.7969\n",
      "rand R2: \t 0.8394 \t 0.8139 \t 0.6820 \t 0.8388 \t 0.8349 \t 0.7026\n",
      "crm R2: \t 0.8344 \t 0.8184 \t 0.8164 \t 0.8388 \t 0.8349 \t 0.8210\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} MAE: \\t{coverage(mondrian_x[\"y\"], mondrian_x[\"low\"][attr], mondrian_x[\"high\"][attr]): .4f} \\t{coverage(mondrian[\"y\"], mondrian[\"low\"][attr], mondrian[\"high\"][attr]): .4f} \\t{coverage(model_split[\"y\"][attr], model_split[\"low\"][attr], model_split[\"high\"][attr]): .4f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} MAE: \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} R2: \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')    \n",
    "    print(f' \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities and Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'CaC'\n",
    "# Load the CSV file\n",
    "df = pd.read_csv('../data/reg/communities.csv')\n",
    "\n",
    "# Remove columns with missing values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Remove string columns\n",
    "df = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:state, 1:fold, 2:population, 3:householdsize, 4:racepctblack, 5:racePctWhite, 6:racePctAsian, 7:racePctHisp, 8:agePct12t21, 9:agePct12t29, 10:agePct16t24, 11:agePct65up, 12:numbUrban, 13:pctUrban, 14:medIncome, 15:pctWWage, 16:pctWFarmSelf, 17:pctWInvInc, 18:pctWSocSec, 19:pctWPubAsst, 20:pctWRetire, 21:medFamInc, 22:perCapInc, 23:whitePerCap, 24:blackPerCap, 25:indianPerCap, 26:AsianPerCap, 27:HispPerCap, 28:NumUnderPov, 29:PctPopUnderPov, 30:PctLess9thGrade, 31:PctNotHSGrad, 32:PctBSorMore, 33:PctUnemployed, 34:PctEmploy, 35:PctEmplManu, 36:PctEmplProfServ, 37:PctOccupManu, 38:PctOccupMgmtProf, 39:MalePctDivorce, 40:MalePctNevMarr, 41:FemalePctDiv, 42:TotalPctDiv, 43:PersPerFam, 44:PctFam2Par, 45:PctKids2Par, 46:PctYoungKids2Par, 47:PctTeen2Par, 48:PctWorkMomYoungKids, 49:PctWorkMom, 50:NumIlleg, 51:PctIlleg, 52:NumImmig, 53:PctImmigRecent, 54:PctImmigRec5, 55:PctImmigRec8, 56:PctImmigRec10, 57:PctRecentImmig, 58:PctRecImmig5, 59:PctRecImmig8, 60:PctRecImmig10, 61:PctSpeakEnglOnly, 62:PctNotSpeakEnglWell, 63:PctLargHouseFam, 64:PctLargHouseOccup, 65:PersPerOccupHous, 66:PersPerOwnOccHous, 67:PersPerRentOccHous, 68:PctPersOwnOccup, 69:PctPersDenseHous, 70:PctHousLess3BR, 71:MedNumBR, 72:HousVacant, 73:PctHousOccup, 74:PctHousOwnOcc, 75:PctVacantBoarded, 76:PctVacMore6Mos, 77:MedYrHousBuilt, 78:PctHousNoPhone, 79:PctWOFullPlumb, 80:OwnOccLowQuart, 81:OwnOccMedVal, 82:OwnOccHiQuart, 83:RentLowQ, 84:RentMedian, 85:RentHighQ, 86:MedRent, 87:MedRentPctHousInc, 88:MedOwnCostPctInc, 89:MedOwnCostPctIncNoMtg, 90:NumInShelters, 91:NumStreet, 92:PctForeignBorn, 93:PctBornSameState, 94:PctSameHouse85, 95:PctSameCity85, 96:PctSameState85, 97:LandArea, 98:PopDens, 99:PctUsePubTrans, 100:LemasPctOfficDrugUn, "
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    print(f'{i}:{feature_name}', end=\", \") \n",
    "blk = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ViolentCrimesPerPop'\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd, yd = df.drop(target,axis=1), df[target]\n",
    "X, y = df.drop(target,axis=1).values, df[target].values\n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':blk}\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['median'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['median'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        x_train, x_cal, x_test = X_train, X_cal, X_test        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(x_train, a, axis=1)\n",
    "                x_cal = np.delete(x_cal, a, axis=1)\n",
    "                x_test = np.delete(x_test, a, axis=1)\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(x_train,y_train)\n",
    "        \n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=5)\n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        residuals_cal = model.predict(x_cal) - y_cal\n",
    "        y_test_hat = model.predict(x_test)\n",
    "        mondrian_x['y'].append(y_test)        \n",
    "        \n",
    "        for attr, a in attributes.items():                \n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian_x['uncal'][attr].append(y_test_hat)\n",
    "            mondrian_x['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian_x['low'][attr].append(values[:,0])\n",
    "            mondrian_x['high'][attr].append(values[:,2])\n",
    "            mondrian_x['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian_x']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, blk]\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['median'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['median'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=5)\n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian['uncal'][attr].append(y_test_hat)\n",
    "            mondrian['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian['low'][attr].append(values[:,0])\n",
    "            mondrian['high'][attr].append(values[:,2])\n",
    "            mondrian['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results[dataset]['mondrian']['time'] = time() - time_mondrian\n",
    "results[dataset]['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, blk]\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['median'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['median'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=5)\n",
    "        blk_train_bin = binning(X_train[:,blk], blk_cal_boundaries)  \n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)  \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': blk_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin,:]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin,:]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin,:]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestRegressor()\n",
    "\n",
    "                model.fit(X_train_bin, y_train_bin)\n",
    "                \n",
    "                residuals_cal = model.predict(X_cal_bin) - y_cal_bin\n",
    "                y_test_bin_hat = model.predict(X_test_bin)\n",
    "            \n",
    "                cps[attr] = ConformalPredictiveSystem()\n",
    "                cps[attr].fit(residuals_cal)\n",
    "                values = cps[attr].predict(y_test_bin_hat, lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "                model_split['uncal'][attr].append(y_test_bin_hat)\n",
    "                model_split['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "                model_split['low'][attr].append(values[:,0])\n",
    "                model_split['high'][attr].append(values[:,2])\n",
    "                model_split['width'][attr].append(values[:,2]-values[:,0])\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results[dataset]['model_split']['time'] = time() - time_split\n",
    "results[dataset]['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['median'][attr] = np.concatenate(mondrian_x['median'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['median'][attr] = np.concatenate(mondrian['median'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['median'][attr] = np.concatenate(model_split['median'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.4778 \t 0.4597 \t 0.4360 \n",
      "rand width: \t 0.5128 \t 0.4975 \t 0.5145 \n",
      "race width: \t 0.4511 \t 0.4395 \t 0.4235 \n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results[dataset]['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results[dataset]['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results[dataset]['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base MAE: \t 0.9052 \t 0.8967 \t 0.8882\n",
      "rand MAE: \t 0.9168 \t 0.9082 \t 0.8887\n",
      "race MAE: \t 0.9142 \t 0.9007 \t 0.8806\n",
      "base MAE: \t 0.0989 \t 0.1032 \t 0.1026 \t 0.0942 \t 0.0949 \t 0.0943\n",
      "rand MAE: \t 0.0988 \t 0.1032 \t 0.1107 \t 0.0942 \t 0.0949 \t 0.1018\n",
      "race MAE: \t 0.0994 \t 0.1041 \t 0.1055 \t 0.0942 \t 0.0949 \t 0.0973\n",
      "base R2: \t 0.6460 \t 0.6376 \t 0.6364 \t 0.6530 \t 0.6524 \t 0.6523\n",
      "rand R2: \t 0.6462 \t 0.6364 \t 0.5837 \t 0.6530 \t 0.6524 \t 0.6041\n",
      "race R2: \t 0.6434 \t 0.6320 \t 0.6174 \t 0.6530 \t 0.6524 \t 0.6365\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} MAE: \\t{coverage(mondrian_x[\"y\"], mondrian_x[\"low\"][attr], mondrian_x[\"high\"][attr]): .4f} \\t{coverage(mondrian[\"y\"], mondrian[\"low\"][attr], mondrian[\"high\"][attr]): .4f} \\t{coverage(model_split[\"y\"][attr], model_split[\"low\"][attr], model_split[\"high\"][attr]): .4f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} MAE: \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} R2: \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')    \n",
    "    print(f' \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{dataset}_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\t Mondrian_x\t Mondrian\t Model Split\tType\n",
      "COMPAS\t 12.52\t\t 15.77\t\t 81.94\t\tclassification\n",
      "Adult\t 68.95\t\t 65.43\t\t 281.76\t\tclassification\n",
      "German\t 4.29\t\t 4.37\t\t 37.07\t\tclassification\n",
      "Housing\t 4.87\t\t 5.00\t\t 24.26\t\tregression\n",
      "CaC\t 139.48\t\t 135.64\t\t 399.27\t\tregression\n"
     ]
    }
   ],
   "source": [
    "categories = ['mondrian_x','mondrian','model_split',]\n",
    "print('Dataset\\t Mondrian_x\\t Mondrian\\t Model Split\\tType')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for category in categories:\n",
    "        print(f'{results[name][category][\"time\"]: 0.2f}\\t\\t', end='')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Width\n",
    "#### Mondrian vs model split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t\n",
      "Dataset\t base\t\t base\t\t base\t\t rand\t\t rand\t\t rand\t\t race\t\t race\t\t race\t\t sex\t\t sex\t\t sex\t\t age\t\t age\t\t age\t\t edu\t\t edu\t\t edu\t\t crm\t\t crm\t\t crm\t\tType\n",
      "COMPAS\t 0.008\t\t 0.007\t\t 0.007\t\t 0.023\t\t 0.022\t\t 0.020\t\t 0.019\t\t 0.019\t\t 0.019\t\t 0.012\t\t 0.011\t\t 0.011\t\t 0.025\t\t 0.021\t\t 0.020\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\tclassification\n",
      "Adult\t 0.003\t\t 0.003\t\t 0.003\t\t 0.009\t\t 0.010\t\t 0.010\t\t 0.006\t\t 0.007\t\t 0.007\t\t 0.004\t\t 0.005\t\t 0.005\t\t -\t\t -\t\t -\t\t 0.015\t\t 0.016\t\t 0.015\t\t -\t\t -\t\t -\t\tclassification\n",
      "German\t 0.037\t\t 0.047\t\t 0.042\t\t 0.119\t\t 0.135\t\t 0.118\t\t -\t\t -\t\t -\t\t 0.096\t\t 0.101\t\t 0.089\t\t 0.120\t\t 0.138\t\t 0.126\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\tclassification\n",
      "Housing\t 12.427\t\t 11.667\t\t 11.693\t\t 17.003\t\t 16.282\t\t 22.404\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t 20.267\t\t 21.467\t\t 21.438\t\tregression\n",
      "CaC\t 0.478\t\t 0.460\t\t 0.436\t\t 0.513\t\t 0.498\t\t 0.514\t\t 0.451\t\t 0.440\t\t 0.423\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in categories:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in categories:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        for category in categories:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t\n",
      "Dataset\t base\t\t rand\t\t race\t\t sex\t\t age\t\t edu\t\t crm\t\tType\n",
      "COMPAS\t 0.007\t\t 0.022\t\t 0.019\t\t 0.011\t\t 0.021\t\t -\t\t -\t\tclassification\n",
      "Adult\t 0.003\t\t 0.010\t\t 0.007\t\t 0.005\t\t -\t\t 0.016\t\t -\t\tclassification\n",
      "German\t 0.047\t\t 0.135\t\t -\t\t 0.101\t\t 0.138\t\t -\t\t -\t\tclassification\n",
      "Housing\t 11.667\t\t 16.282\t\t -\t\t -\t\t -\t\t -\t\t 21.467\t\tregression\n",
      "CaC\t 0.460\t\t 0.498\t\t 0.440\t\t -\t\t -\t\t -\t\t -\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        for category in ['mondrian']:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(f'../evaluation/results_mondrian_{str(num_rep)}.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
