{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrated_explanations v0.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from crepes import ConformalPredictiveSystem\n",
    "from crepes.extras import binning, DifficultyEstimator\n",
    "\n",
    "from calibrated_explanations import  VennAbers, __version__\n",
    "from calibrated_explanations.utils import transform_to_numeric\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"calibrated_explanations {__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = {'COMPAS': 'classification', 'adult': 'classification', 'german': 'classification', 'boston': 'regression', }\n",
    "results = {}\n",
    "for name, type in datasets.items():\n",
    "    results[name] = {}\n",
    "    results[name]['type'] = type\n",
    "    for category in ['mondrian', 'model_split']:\n",
    "        results[name][category] = {'time': 0, 'base': 0, 'rand': 0, 'race': 0, 'sex': 0, 'age': 0, 'edu': 0, 'crm': 0}\n",
    "\n",
    "num_rep = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS\n",
    "Data preprocessing from [this notebook](https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_COMPAS_with_SHAP.ipynb#scrollTo=KF00pJvkeicT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18316, 40)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/what-if-tool-resources/computefest2019/cox-violent-parsed_filt.csv')\n",
    "print(df.shape)\n",
    "# Preprocess the data\n",
    "\n",
    "# Filter out entries with no indication of recidivism or no compass score\n",
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['decile_score'] != -1]\n",
    "\n",
    "\n",
    "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
    "df['score_text'] = np.where(df['score_text'] == 'Low', 'Low', 'Not Low')\n",
    "\n",
    "target = 'score_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'score_text']\n",
    "# 'age_cat', 'is_recid', 'vr_charge_desc',  'c_charge_desc',, 'is_violent_recid''vr_charge_degree', 'c_charge_degree', 'decile_score', \n",
    "df = df[features_to_keep]\n",
    "df, categorical_features, categorical_labels, target_labels, mappings = transform_to_numeric(df, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count',\n",
      "       'juv_other_count', 'priors_count', 'score_text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "race = 2\n",
    "age = 1\n",
    "sex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 20 # number of instances to test\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop([target],axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results['COMPAS']['mondrian']['time'] = time() - time_mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "    \n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()\n",
    "                \n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results['COMPAS']['model_split']['time'] = time() - time_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base width: \t 0.00736803 \t 0.00746037\n",
      "rand width: \t 0.0227246 \t 0.0211287\n",
      "race width: \t 0.0192262 \t 0.0188397\n",
      "sex width: \t 0.0111202 \t 0.0115664\n",
      "age width: \t 0.0215532 \t 0.0210299\n"
     ]
    }
   ],
   "source": [
    "for attr in attribute_names:\n",
    "    results['COMPAS']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['COMPAS']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): 2g} \\t{np.mean(model_split[\"width\"][attr]): 2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<=50K', 1: '>50K'}\n"
     ]
    }
   ],
   "source": [
    "df = X\n",
    "target = 'Income'\n",
    "y = y.replace('<=50K.', '<=50K')\n",
    "y = y.replace('>50K.', '>50K')\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "edu = 3\n",
    "race = 8\n",
    "sex = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cal, X_test = X[train_index], X[test_index]\n",
    "    y_train_cal, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "    rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "    cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "    test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "    \n",
    "    mondrian['y'].append(y_test)\n",
    "    \n",
    "    for attr in attribute_names:\n",
    "        va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "        proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "        mondrian['proba'][attr].append(proba[:,1])\n",
    "        mondrian['low'][attr].append(low)\n",
    "        mondrian['high'][attr].append(high)\n",
    "        mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results['adult']['mondrian']['time'] = time() - time_mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "model_split = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cal, X_test = X[train_index], X[test_index]\n",
    "    y_train_cal, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "    \n",
    "\n",
    "    rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "    rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "    rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "    train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'edu': X_train[:,edu]}\n",
    "    cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "    test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "    \n",
    "    try:\n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "            \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()\n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'attr: {attr} bin: {bin}')    \n",
    "\n",
    "results['adult']['model_split']['time'] = time() - time_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base width: \t 0.00326076 \t 0.00354104\n",
      "rand width: \t 0.0109691 \t 0.0112308\n",
      "race width: \t 0.00751947 \t 0.00761529\n",
      "sex width: \t 0.00522884 \t 0.00529675\n",
      "edu width: \t 0.0178852 \t 0.0170594\n"
     ]
    }
   ],
   "source": [
    "for attr in attribute_names:\n",
    "    results['adult']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['adult']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): 2g} \\t{np.mean(model_split[\"width\"][attr]): 2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = statlog_german_credit_data.variables.description[:-1]\n",
    "feature_names[0] = 'Status'\n",
    "feature_names[7] = 'Installment rate'\n",
    "feature_names[15] = 'Existing credits'\n",
    "feature_names[17] = 'Num people liable'\n",
    "target_labels = {1: 'Good', 0: 'Bad'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         Status\n",
      "1                       Duration\n",
      "2                 Credit history\n",
      "3                        Purpose\n",
      "4                  Credit amount\n",
      "5          Savings account/bonds\n",
      "6       Present employment since\n",
      "7               Installment rate\n",
      "8        Personal status and sex\n",
      "9     Other debtors / guarantors\n",
      "10       Present residence since\n",
      "11                      Property\n",
      "12                           Age\n",
      "13       Other installment plans\n",
      "14                       Housing\n",
      "15              Existing credits\n",
      "16                           Job\n",
      "17             Num people liable\n",
      "18                     Telephone\n",
      "19                foreign worker\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)\n",
    "age = 12\n",
    "sex = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X\n",
    "target = 'Class'\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, _, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values\n",
    "y[y == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cal, X_test = X[train_index], X[test_index]\n",
    "    y_train_cal, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(X_train,y_train)\n",
    "    \n",
    "    age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "    age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "    rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "    rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "    cal_bins = {base: None, rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "    test_bins = {base: None, rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "    \n",
    "    mondrian['y'].append(y_test)\n",
    "    \n",
    "    for attr in attribute_names:\n",
    "        va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "        proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "        mondrian['proba'][attr].append(proba[:,1])\n",
    "        mondrian['low'][attr].append(low)\n",
    "        mondrian['high'][attr].append(high)\n",
    "        mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results['german']['mondrian']['time'] = time() - time_mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cal, X_test = X[train_index], X[test_index]\n",
    "    y_train_cal, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "    \n",
    "    age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "    age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "    age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "    rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "    rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "    rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "    train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "    cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "    test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "    \n",
    "    \n",
    "    for attr in attribute_names:\n",
    "        for bin in np.unique(train_bins[attr]):\n",
    "            X_train_bin = X_train[train_bins[attr] == bin]\n",
    "            y_train_bin = y_train[train_bins[attr] == bin]\n",
    "            X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "            y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "            X_test_bin = X_test[test_bins[attr] == bin]\n",
    "            y_test_bin = y_test[test_bins[attr] == bin]\n",
    "            \n",
    "            model = RandomForestClassifier()\n",
    "            model.fit(X_train_bin,y_train_bin)\n",
    "            va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "            proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "            model_split['proba'][attr].append(proba[:,1])\n",
    "            model_split['low'][attr].append(low)\n",
    "            model_split['high'][attr].append(high)\n",
    "            model_split['width'][attr].append(high - low)\n",
    "            model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results['german']['model_split']['time'] = time() - time_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base width: \t 0.0449486 \t 0.0469801\n",
      "rand width: \t 0.134121 \t 0.119509\n",
      "sex width: \t 0.099784 \t 0.101003\n",
      "age width: \t 0.131775 \t 0.125053\n"
     ]
    }
   ],
   "source": [
    "for attr in attribute_names:\n",
    "    results['german']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['german']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): 2g} \\t{np.mean(model_split[\"width\"][attr]): 2g}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/reg/HousingData.csv', na_values='NA')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]\n",
    "print(feature_names)\n",
    "crm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'MEDV'\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "Xd, yd = df.drop(target,axis=1), df[target]\n",
    "X, y = df.drop(target,axis=1).values, df[target].values\n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Regression\n",
    "Default confidence of 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "mondrian = {}\n",
    "mondrian['median'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian['median'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cal, X_test = X[train_index], X[test_index]\n",
    "    y_train_cal, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "    \n",
    "    model = RandomForestRegressor()\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "    crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "    rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "    rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "    cal_bins = {base: None, rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "    test_bins = {base: None, rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "    residuals_cal = model.predict(X_cal) - y_cal\n",
    "    y_test_hat = model.predict(X_test)\n",
    "    mondrian['y'].append(y_test)\n",
    "    \n",
    "    for attr in attribute_names:\n",
    "        cps[attr] = ConformalPredictiveSystem()\n",
    "        cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "        values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "        mondrian['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "        mondrian['low'][attr].append(values[:,0])\n",
    "        mondrian['high'][attr].append(values[:,2])\n",
    "        mondrian['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results['boston']['mondrian']['time'] = time() - time_mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "model_split = {}\n",
    "model_split['median'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    model_split['median'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train_cal, X_test = X[train_index], X[test_index]\n",
    "    y_train_cal, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "    \n",
    "    \n",
    "    crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "    crm_train_bin = binning(X_train[:,crm], crm_cal_boundaries)\n",
    "    crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "    rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "    rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "    rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "    train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'crm': crm_train_bin}\n",
    "    cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "    test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "    \n",
    "    \n",
    "    for attr in attribute_names:\n",
    "        for bin in np.unique(train_bins[attr]):\n",
    "            X_train_bin = X_train[train_bins[attr] == bin,:]\n",
    "            y_train_bin = y_train[train_bins[attr] == bin]\n",
    "            X_cal_bin = X_cal[cal_bins[attr] == bin,:]\n",
    "            y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "            X_test_bin = X_test[test_bins[attr] == bin,:]\n",
    "            y_test_bin = y_test[test_bins[attr] == bin]\n",
    "            \n",
    "            if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                continue\n",
    "            \n",
    "            model = RandomForestRegressor()\n",
    "\n",
    "            model.fit(X_train_bin, y_train_bin)\n",
    "            \n",
    "            residuals_cal = model.predict(X_cal_bin) - y_cal_bin\n",
    "            y_test_bin_hat = model.predict(X_test_bin)\n",
    "        \n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal)\n",
    "            values = cps[attr].predict(y_test_bin_hat, lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            model_split['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            model_split['low'][attr].append(values[:,0])\n",
    "            model_split['high'][attr].append(values[:,2])\n",
    "            model_split['width'][attr].append(values[:,2]-values[:,0])\n",
    "            model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results['boston']['model_split']['time'] = time() - time_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian['median'][attr] = np.concatenate(mondrian['median'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['median'][attr] = np.concatenate(model_split['median'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "base width: \t 9.90189 \t 9.83211 \n",
      "rand width: \t 12.7567 \t 17.8389 \n",
      "crm width: \t 13.8097 \t 15.034 \n"
     ]
    }
   ],
   "source": [
    "for attr in attribute_names:\n",
    "    results['boston']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['boston']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian[\"width\"][attr]): 2g} \\t{np.mean(model_split[\"width\"][attr]): 2g} ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\t Model Split\t Mondrian\tType\n",
      "COMPAS\t 70.26\t\t 12.93\t\tclassification\n",
      "adult\t 333.01\t\t 72.51\t\tclassification\n",
      "german\t 29.83\t\t 3.97\t\tclassification\n",
      "boston\t 22.18\t\t 6.18\t\tregression\n"
     ]
    }
   ],
   "source": [
    "categories = ['model_split', 'mondrian', ]\n",
    "print('Dataset\\t Model Split\\t Mondrian\\tType')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for category in categories:\n",
    "        print(f'{results[name][category][\"time\"]: 0.2f}\\t\\t', end='')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Width\n",
    "#### Mondrian vs model split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t model_split\t mondrian\t model_split\t mondrian\t model_split\t mondrian\t model_split\t mondrian\t model_split\t mondrian\t model_split\t mondrian\t model_split\t mondrian\t\n",
      "Dataset\t base\t\t base\t\t rand\t\t rand\t\t race\t\t race\t\t sex\t\t sex\t\t age\t\t age\t\t edu\t\t edu\t\t crm\t\t crm\t\tType\n",
      "COMPAS\t 0.007\t\t 0.007\t\t 0.021\t\t 0.023\t\t 0.019\t\t 0.019\t\t 0.012\t\t 0.011\t\t 0.021\t\t 0.022\t\t -\t\t -\t\t -\t\t -\t\tclassification\n",
      "adult\t 0.004\t\t 0.003\t\t 0.011\t\t 0.011\t\t 0.008\t\t 0.008\t\t 0.005\t\t 0.005\t\t -\t\t -\t\t 0.017\t\t 0.018\t\t -\t\t -\t\tclassification\n",
      "german\t 0.047\t\t 0.045\t\t 0.120\t\t 0.134\t\t -\t\t -\t\t 0.101\t\t 0.100\t\t 0.125\t\t 0.132\t\t -\t\t -\t\t -\t\t -\t\tclassification\n",
      "boston\t 9.832\t\t 9.902\t\t 17.839\t\t 12.757\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t 15.034\t\t 13.810\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr == 'time':\n",
    "        continue\n",
    "    for category in categories:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr == 'time':\n",
    "        continue\n",
    "    for category in categories:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr == 'time':\n",
    "            continue\n",
    "        for category in categories:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t\n",
      "Dataset\t base\t\t rand\t\t race\t\t sex\t\t age\t\t edu\t\t crm\t\tType\n",
      "COMPAS\t 0.007\t\t 0.023\t\t 0.019\t\t 0.011\t\t 0.022\t\t -\t\t -\t\tclassification\n",
      "adult\t 0.003\t\t 0.011\t\t 0.008\t\t 0.005\t\t -\t\t 0.018\t\t -\t\tclassification\n",
      "german\t 0.045\t\t 0.134\t\t -\t\t 0.100\t\t 0.132\t\t -\t\t -\t\tclassification\n",
      "boston\t 9.902\t\t 12.757\t\t -\t\t -\t\t -\t\t -\t\t 13.810\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr == 'time':\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr == 'time':\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr == 'time':\n",
    "            continue\n",
    "        for category in ['mondrian']:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
