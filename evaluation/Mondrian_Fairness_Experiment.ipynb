{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calibrated_explanations v0.3.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from crepes import ConformalPredictiveSystem\n",
    "from crepes.extras import binning, DifficultyEstimator\n",
    "\n",
    "from calibrated_explanations import  VennAbers, __version__\n",
    "from calibrated_explanations.utils import transform_to_numeric\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"calibrated_explanations {__version__}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "datasets = {'COMPAS': 'classification', 'adult': 'classification', 'german': 'classification', 'boston': 'regression', 'CaC': 'regression'}\n",
    "results = {}\n",
    "for name, type in datasets.items():\n",
    "    results[name] = {}\n",
    "    results[name]['type'] = type\n",
    "    for category in ['mondrian', 'mondrian_x', 'model_split']:\n",
    "        results[name][category] = {'time': 0, 'base': 0, 'rand': 0, 'race': 0, 'sex': 0, 'age': 0, 'edu': 0, 'crm': 0}\n",
    "\n",
    "num_rep = 10\n",
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS\n",
    "Data preprocessing from [this notebook](https://colab.research.google.com/github/pair-code/what-if-tool/blob/master/WIT_COMPAS_with_SHAP.ipynb#scrollTo=KF00pJvkeicT)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18316, 40)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://storage.googleapis.com/what-if-tool-resources/computefest2019/cox-violent-parsed_filt.csv')\n",
    "print(df.shape)\n",
    "# Preprocess the data\n",
    "\n",
    "# Filter out entries with no indication of recidivism or no compass score\n",
    "df = df[df['is_recid'] != -1]\n",
    "df = df[df['decile_score'] != -1]\n",
    "\n",
    "\n",
    "# Make the COMPASS label column numeric (0 and 1), for use in our model\n",
    "df['score_text'] = np.where(df['score_text'] == 'Low', 'Low', 'Not Low')\n",
    "\n",
    "target = 'score_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_keep = ['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count', 'juv_other_count', 'priors_count', 'score_text']\n",
    "# 'age_cat', 'is_recid', 'vr_charge_desc',  'c_charge_desc',, 'is_violent_recid''vr_charge_degree', 'c_charge_degree', 'decile_score', \n",
    "df = df[features_to_keep]\n",
    "df, categorical_features, categorical_labels, target_labels, mappings = transform_to_numeric(df, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['sex', 'age', 'race', 'juv_fel_count', 'juv_misd_count',\n",
      "       'juv_other_count', 'priors_count', 'score_text'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "race = 2\n",
    "age = 1\n",
    "sex = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 20 # number of instances to test\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop([target],axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':race, 'sex':sex, 'age':age}\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(X_train, a, axis=1)\n",
    "                x_cal = np.delete(X_cal, a, axis=1)\n",
    "                x_test = np.delete(X_test, a, axis=1)\n",
    "                model = RandomForestClassifier()\n",
    "                model.fit(x_train,y_train)\n",
    "            else:\n",
    "                x_train = X_train\n",
    "                x_cal = X_cal\n",
    "                x_test = X_test\n",
    "                \n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results['COMPAS']['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results['COMPAS']['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results['COMPAS']['mondrian']['time'] = time() - time_mondrian\n",
    "results['COMPAS']['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, age]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "    \n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()                \n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                uncal = model.predict_proba(X_test_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['uncal'][attr].append(uncal[:,1])\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results['COMPAS']['model_split']['time'] = time() - time_split\n",
    "results['COMPAS']['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.0073 \t 0.0072 \t 0.0073\n",
      "rand width: \t 0.0222 \t 0.0220 \t 0.0200\n",
      "race width: \t 0.0186 \t 0.0186 \t 0.0181\n",
      "sex width: \t 0.0112 \t 0.0111 \t 0.0111\n",
      "age width: \t 0.0279 \t 0.0207 \t 0.0208\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results['COMPAS']['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results['COMPAS']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['COMPAS']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base Accuracy: \t 0.7738 \t 0.7736 \t 0.7734 \t 0.7733 \t 0.7732 \t 0.7727\n",
      "rand Accuracy: \t 0.7719 \t 0.7720 \t 0.7277 \t 0.7733 \t 0.7732 \t 0.7281\n",
      "race Accuracy: \t 0.7650 \t 0.7729 \t 0.7732 \t 0.7614 \t 0.7732 \t 0.7720\n",
      "sex Accuracy: \t 0.7691 \t 0.7730 \t 0.7730 \t 0.7683 \t 0.7732 \t 0.7729\n",
      "age Accuracy: \t 0.7460 \t 0.7721 \t 0.7713 \t 0.7093 \t 0.7732 \t 0.7722\n",
      "\n",
      "base LogLoss: \t 0.4657 \t 0.4652 \t 0.4657 \t 0.7931 \t 0.7915 \t 0.7859\n",
      "rand LogLoss: \t 0.4697 \t 0.4691 \t 0.5407 \t 0.7931 \t 0.7915 \t 0.9481\n",
      "race LogLoss: \t 0.4782 \t 0.4644 \t 0.4660 \t 0.7171 \t 0.7915 \t 0.8141\n",
      "sex LogLoss: \t 0.4700 \t 0.4655 \t 0.4663 \t 0.7441 \t 0.7915 \t 0.7911\n",
      "age LogLoss: \t 0.5051 \t 0.4639 \t 0.4686 \t 0.6140 \t 0.7915 \t 0.7881\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../evaluation/results_mondrian.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "adult = fetch_ucirepo(id=2) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = adult.data.features \n",
    "y = adult.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<=50K', 1: '>50K'}\n"
     ]
    }
   ],
   "source": [
    "df = X\n",
    "target = 'Income'\n",
    "y = y.replace('<=50K.', '<=50K')\n",
    "y = y.replace('>50K.', '>50K')\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)\n",
    "print(target_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
      "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
      "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
      "       'Income'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n",
    "edu = 3\n",
    "race = 8\n",
    "sex = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':race, 'sex':sex, 'edu':edu}\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(X_train, a, axis=1)\n",
    "                x_cal = np.delete(X_cal, a, axis=1)\n",
    "                x_test = np.delete(X_test, a, axis=1)\n",
    "                model = RandomForestClassifier()\n",
    "                model.fit(x_train,y_train)\n",
    "            else:\n",
    "                x_train = X_train\n",
    "                x_cal = X_cal\n",
    "                x_test = X_test\n",
    "            \n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results['adult']['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results['adult']['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results['adult']['mondrian']['time'] = time() - time_mondrian\n",
    "results['adult']['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n",
      "index 1 is out of bounds for axis 1 with size 1\n",
      "attr: edu bin: 14\n"
     ]
    }
   ],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, race, sex, edu]\n",
    "attribute_names = [base, rand, 'race', 'sex', 'edu']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': X_train[:,race], 'sex': X_train[:,sex], 'edu': X_train[:,edu]}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': X_cal[:,race], 'sex': X_cal[:,sex], 'edu': X_cal[:,edu]}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': X_test[:,race], 'sex': X_test[:,sex], 'edu': X_test[:,edu]}\n",
    "        \n",
    "        try:\n",
    "            for attr in attribute_names:\n",
    "                for bin in np.unique(train_bins[attr]):\n",
    "                    X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                    y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                    X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                    y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                    X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                    y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                    if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    model = RandomForestClassifier()\n",
    "                    model.fit(X_train_bin,y_train_bin)\n",
    "                    uncal = model.predict_proba(X_test_bin)\n",
    "                    va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                    proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                    model_split['uncal'][attr].append(uncal[:,1])\n",
    "                    model_split['proba'][attr].append(proba[:,1])\n",
    "                    model_split['low'][attr].append(low)\n",
    "                    model_split['high'][attr].append(high)\n",
    "                    model_split['width'][attr].append(high - low)\n",
    "                    model_split['y'][attr].append(y_test_bin)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f'attr: {attr} bin: {bin}')    \n",
    "\n",
    "results['adult']['model_split']['time'] = time() - time_split\n",
    "results['adult']['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.0030 \t 0.0030 \t 0.0030\n",
      "rand width: \t 0.0097 \t 0.0098 \t 0.0098\n",
      "race width: \t 0.0068 \t 0.0068 \t 0.0066\n",
      "sex width: \t 0.0047 \t 0.0047 \t 0.0047\n",
      "edu width: \t 0.0161 \t 0.0161 \t 0.0152\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results['adult']['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results['adult']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['adult']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base Accuracy: \t 0.8554 \t 0.8547 \t 0.8550 \t 0.8555 \t 0.8550 \t 0.8552\n",
      "rand Accuracy: \t 0.8543 \t 0.8543 \t 0.8491 \t 0.8555 \t 0.8550 \t 0.8499\n",
      "race Accuracy: \t 0.8552 \t 0.8545 \t 0.8535 \t 0.8552 \t 0.8550 \t 0.8536\n",
      "sex Accuracy: \t 0.8554 \t 0.8548 \t 0.8541 \t 0.8557 \t 0.8550 \t 0.8543\n",
      "edu Accuracy: \t 0.8574 \t 0.8556 \t 0.8508 \t 0.8573 \t 0.8550 \t 0.8504\n",
      "\n",
      "base LogLoss: \t 0.3175 \t 0.3181 \t 0.3183 \t 0.3646 \t 0.3650 \t 0.3676\n",
      "rand LogLoss: \t 0.3196 \t 0.3202 \t 0.3306 \t 0.3646 \t 0.3650 \t 0.3633\n",
      "race LogLoss: \t 0.3183 \t 0.3185 \t 0.3221 \t 0.3722 \t 0.3650 \t 0.3663\n",
      "sex LogLoss: \t 0.3167 \t 0.3176 \t 0.3203 \t 0.3710 \t 0.3650 \t 0.3726\n",
      "edu LogLoss: \t 0.3164 \t 0.3196 \t 0.3311 \t 0.3588 \t 0.3650 \t 0.3887\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../evaluation/results_mondrian.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ucimlrepo import fetch_ucirepo \n",
    "  \n",
    "# fetch dataset \n",
    "statlog_german_credit_data = fetch_ucirepo(id=144) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "X = statlog_german_credit_data.data.features \n",
    "y = statlog_german_credit_data.data.targets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = statlog_german_credit_data.variables.description[:-1]\n",
    "feature_names[0] = 'Status'\n",
    "feature_names[7] = 'Installment rate'\n",
    "feature_names[15] = 'Existing credits'\n",
    "feature_names[17] = 'Num people liable'\n",
    "target_labels = {1: 'Good', 0: 'Bad'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                         Status\n",
      "1                       Duration\n",
      "2                 Credit history\n",
      "3                        Purpose\n",
      "4                  Credit amount\n",
      "5          Savings account/bonds\n",
      "6       Present employment since\n",
      "7               Installment rate\n",
      "8        Personal status and sex\n",
      "9     Other debtors / guarantors\n",
      "10       Present residence since\n",
      "11                      Property\n",
      "12                           Age\n",
      "13       Other installment plans\n",
      "14                       Housing\n",
      "15              Existing credits\n",
      "16                           Job\n",
      "17             Num people liable\n",
      "18                     Telephone\n",
      "19                foreign worker\n",
      "Name: description, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(feature_names)\n",
    "age = 12\n",
    "sex = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = X\n",
    "target = 'Class'\n",
    "df[target] = y\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, _, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "df = df.sample(frac=1, random_state=42).sort_values(by=[target])\n",
    "Xd, yd = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]\n",
    "\n",
    "# select test instances from each class and split into train, cal and test\n",
    "X, y = Xd.values, yd.values\n",
    "y[y == 2] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'sex':sex, 'age':age}\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "va = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['proba'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "time_mondrian_x = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['proba'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "\n",
    "        model.fit(X_train,y_train)\n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian_x['y'].append(y_test)\n",
    "        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(X_train, a, axis=1)\n",
    "                x_cal = np.delete(X_cal, a, axis=1)\n",
    "                x_test = np.delete(X_test, a, axis=1)\n",
    "                model = RandomForestClassifier()\n",
    "                model.fit(x_train,y_train)\n",
    "            else:\n",
    "                x_train = X_train\n",
    "                x_cal = X_cal\n",
    "                x_test = X_test\n",
    "            \n",
    "            uncal = model.predict_proba(x_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(x_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(x_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian_x['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian_x['proba'][attr].append(proba[:,1])\n",
    "            mondrian_x['low'][attr].append(low)\n",
    "            mondrian_x['high'][attr].append(high)\n",
    "            mondrian_x['width'][attr].append(high-low)\n",
    "\n",
    "results['german']['mondrian_x']['time'] = time() - time_mondrian_x\n",
    "results['german']['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "va = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['proba'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "time_mondrian = time()\n",
    "for attr in attribute_names:\n",
    "    va[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['proba'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestClassifier()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            uncal = model.predict_proba(X_test)\n",
    "            va[attr] = VennAbers(model.predict_proba(X_cal), y_cal, model, bins=cal_bins[attr])\n",
    "            proba, low, high = va[attr].predict_proba(X_test, output_interval=True, bins=test_bins[attr])\n",
    "            mondrian['uncal'][attr].append(uncal[:,1])\n",
    "            mondrian['proba'][attr].append(proba[:,1])\n",
    "            mondrian['low'][attr].append(low)\n",
    "            mondrian['high'][attr].append(high)\n",
    "            mondrian['width'][attr].append(high-low)\n",
    "\n",
    "results['german']['mondrian']['time'] = time() - time_mondrian\n",
    "results['german']['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, sex, age]\n",
    "attribute_names = [base, rand, 'sex', 'age']\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['proba'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['proba'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        age_cal_bin, age_cal_boundaries = binning(X_cal[:,age], bins=5)\n",
    "        age_train_bin = binning(X_train[:,age], age_cal_boundaries)\n",
    "        age_test_bin = binning(X_test[:,age], age_cal_boundaries)\n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'sex': X_train[:,sex], 'age': age_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'sex': X_cal[:,sex], 'age': age_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'sex': X_test[:,sex], 'age': age_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestClassifier()                \n",
    "                model.fit(X_train_bin,y_train_bin)\n",
    "                uncal = model.predict_proba(X_test_bin)\n",
    "                va = VennAbers(model.predict_proba(X_cal_bin), y_cal_bin, model)\n",
    "                proba, low, high = va.predict_proba(X_test_bin, output_interval=True)\n",
    "                model_split['uncal'][attr].append(uncal[:,1])\n",
    "                model_split['proba'][attr].append(proba[:,1])\n",
    "                model_split['low'][attr].append(low)\n",
    "                model_split['high'][attr].append(high)\n",
    "                model_split['width'][attr].append(high - low)\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results['german']['model_split']['time'] = time() - time_split\n",
    "results['german']['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['proba'][attr] = np.concatenate(mondrian_x['proba'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['proba'][attr] = np.concatenate(mondrian['proba'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['proba'][attr] = np.concatenate(model_split['proba'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.0437 \t 0.0442 \t 0.0447\n",
      "rand width: \t 0.1271 \t 0.1280 \t 0.1173\n",
      "sex width: \t 0.0996 \t 0.0996 \t 0.0928\n",
      "age width: \t 0.1246 \t 0.1252 \t 0.1203\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results['german']['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results['german']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['german']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base Accuracy: \t 0.7530 \t 0.7503 \t 0.7576 \t 0.7589 \t 0.7543 \t 0.7582\n",
      "rand Accuracy: \t 0.7448 \t 0.7442 \t 0.7172 \t 0.7589 \t 0.7543 \t 0.7294\n",
      "sex Accuracy: \t 0.7492 \t 0.7450 \t 0.7294 \t 0.7629 \t 0.7543 \t 0.7347\n",
      "age Accuracy: \t 0.7467 \t 0.7429 \t 0.7274 \t 0.7565 \t 0.7543 \t 0.7338\n",
      "\n",
      "base LogLoss: \t 0.5120 \t 0.5159 \t 0.5127 \t 0.5043 \t 0.5081 \t 0.5064\n",
      "rand LogLoss: \t 0.5261 \t 0.5280 \t 0.5611 \t 0.5043 \t 0.5081 \t 0.5503\n",
      "sex LogLoss: \t 0.5201 \t 0.5217 \t 0.5396 \t 0.5086 \t 0.5081 \t 0.5303\n",
      "age LogLoss: \t 0.5236 \t 0.5256 \t 0.5486 \t 0.5146 \t 0.5081 \t 0.5319\n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} Accuracy: \\t{np.mean((mondrian_x[\"proba\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"proba\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"proba\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}', end='')\n",
    "    print(f' \\t{np.mean((mondrian_x[\"uncal\"][attr] > 0.5) == (mondrian_x[\"y\"] == 1)): .4f} \\t{np.mean((mondrian[\"uncal\"][attr] > 0.5) == (mondrian[\"y\"] == 1)): .4f} \\t{np.mean((model_split[\"uncal\"][attr] > 0.5) == (model_split[\"y\"][attr] == 1)): .4f}')\n",
    "print()\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} LogLoss: \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"proba\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"proba\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"proba\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{log_loss(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{log_loss(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{log_loss(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../evaluation/results_mondrian.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/reg/HousingData.csv', na_values='NA')\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
      "       'PTRATIO', 'B', 'LSTAT'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]\n",
    "print(feature_names)\n",
    "crm = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'MEDV'\n",
    "df = df.dropna()\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 10 # number of instances to test, one from each class\n",
    "\n",
    "Xd, yd = df.drop(target,axis=1), df[target]\n",
    "X, y = df.drop(target,axis=1).values, df[target].values\n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Regression\n",
    "Default confidence of 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'crm':crm}\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['median'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['median'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian_x['y'].append(y_test)        \n",
    "        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(X_train, a, axis=1)\n",
    "                x_cal = np.delete(X_cal, a, axis=1)\n",
    "                x_test = np.delete(X_test, a, axis=1)\n",
    "                model = RandomForestRegressor()\n",
    "                model.fit(x_train,y_train)\n",
    "                residuals_cal = model.predict(x_cal) - y_cal\n",
    "                y_test_hat = model.predict(x_test)\n",
    "                \n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian_x['uncal'][attr].append(y_test_hat)\n",
    "            mondrian_x['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian_x['low'][attr].append(values[:,0])\n",
    "            mondrian_x['high'][attr].append(values[:,2])\n",
    "            mondrian_x['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results['boston']['mondrian_x']['time'] = time() - time_mondrian\n",
    "results['boston']['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['median'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['median'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian['uncal'][attr].append(y_test_hat)\n",
    "            mondrian['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian['low'][attr].append(values[:,0])\n",
    "            mondrian['high'][attr].append(values[:,2])\n",
    "            mondrian['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results['boston']['mondrian']['time'] = time() - time_mondrian\n",
    "results['boston']['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, crm]\n",
    "attribute_names = [base, rand, 'crm']\n",
    "cps = {}\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['median'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['median'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        crm_cal_bin, crm_cal_boundaries = binning(X_cal[:,crm], bins=3)\n",
    "        crm_train_bin = binning(X_train[:,crm], crm_cal_boundaries)\n",
    "        crm_test_bin = binning(X_test[:,crm], crm_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'crm': crm_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'crm': crm_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'crm': crm_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin,:]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin,:]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin,:]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestRegressor()\n",
    "                model.fit(X_train_bin, y_train_bin)\n",
    "                \n",
    "                residuals_cal = model.predict(X_cal_bin) - y_cal_bin\n",
    "                y_test_bin_hat = model.predict(X_test_bin)\n",
    "            \n",
    "                cps[attr] = ConformalPredictiveSystem()\n",
    "                cps[attr].fit(residuals_cal)\n",
    "                values = cps[attr].predict(y_test_bin_hat, lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "                model_split['uncal'][attr].append(y_test_bin_hat)\n",
    "                model_split['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "                model_split['low'][attr].append(values[:,0])\n",
    "                model_split['high'][attr].append(values[:,2])\n",
    "                model_split['width'][attr].append(values[:,2]-values[:,0])\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results['boston']['model_split']['time'] = time() - time_split\n",
    "results['boston']['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['median'][attr] = np.concatenate(mondrian_x['median'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['median'][attr] = np.concatenate(mondrian['median'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['median'][attr] = np.concatenate(model_split['median'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 10.5660 \t 11.0025 \t 10.2621 \n",
      "rand width: \t 15.5957 \t 15.8963 \t 18.9047 \n",
      "crm width: \t 17.9458 \t 18.5122 \t 17.5247 \n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results['boston']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['boston']['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results['boston']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base MAE: \t 2.3867 \t 2.3959 \t 2.3894 \t 2.3435 \t 2.3462 \t 2.3477\n",
      "rand MAE: \t 2.4382 \t 2.4308 \t 3.3884 \t 2.3435 \t 2.3462 \t 3.2275\n",
      "crm MAE: \t 2.3993 \t 2.4248 \t 2.5377 \t 2.3469 \t 2.3462 \t 2.4523\n",
      "base R2: \t 0.8387 \t 0.8413 \t 0.8409 \t 0.8408 \t 0.8439 \t 0.8433\n",
      "rand R2: \t 0.8346 \t 0.8378 \t 0.7089 \t 0.8408 \t 0.8439 \t 0.7241\n",
      "crm R2: \t 0.8379 \t 0.8381 \t 0.8335 \t 0.8421 \t 0.8439 \t 0.8392\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} MAE: \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} R2: \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')    \n",
    "    print(f' \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../evaluation/results_mondrian.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Communities and Crimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('../data/reg/communities.csv')\n",
    "\n",
    "# Remove columns with missing values\n",
    "df = df.dropna(axis=1)\n",
    "\n",
    "# Remove string columns\n",
    "df = df.select_dtypes(exclude=['object'])\n",
    "\n",
    "# df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:state, 1:fold, 2:population, 3:householdsize, 4:racepctblack, 5:racePctWhite, 6:racePctAsian, 7:racePctHisp, 8:agePct12t21, 9:agePct12t29, 10:agePct16t24, 11:agePct65up, 12:numbUrban, 13:pctUrban, 14:medIncome, 15:pctWWage, 16:pctWFarmSelf, 17:pctWInvInc, 18:pctWSocSec, 19:pctWPubAsst, 20:pctWRetire, 21:medFamInc, 22:perCapInc, 23:whitePerCap, 24:blackPerCap, 25:indianPerCap, 26:AsianPerCap, 27:HispPerCap, 28:NumUnderPov, 29:PctPopUnderPov, 30:PctLess9thGrade, 31:PctNotHSGrad, 32:PctBSorMore, 33:PctUnemployed, 34:PctEmploy, 35:PctEmplManu, 36:PctEmplProfServ, 37:PctOccupManu, 38:PctOccupMgmtProf, 39:MalePctDivorce, 40:MalePctNevMarr, 41:FemalePctDiv, 42:TotalPctDiv, 43:PersPerFam, 44:PctFam2Par, 45:PctKids2Par, 46:PctYoungKids2Par, 47:PctTeen2Par, 48:PctWorkMomYoungKids, 49:PctWorkMom, 50:NumIlleg, 51:PctIlleg, 52:NumImmig, 53:PctImmigRecent, 54:PctImmigRec5, 55:PctImmigRec8, 56:PctImmigRec10, 57:PctRecentImmig, 58:PctRecImmig5, 59:PctRecImmig8, 60:PctRecImmig10, 61:PctSpeakEnglOnly, 62:PctNotSpeakEnglWell, 63:PctLargHouseFam, 64:PctLargHouseOccup, 65:PersPerOccupHous, 66:PersPerOwnOccHous, 67:PersPerRentOccHous, 68:PctPersOwnOccup, 69:PctPersDenseHous, 70:PctHousLess3BR, 71:MedNumBR, 72:HousVacant, 73:PctHousOccup, 74:PctHousOwnOcc, 75:PctVacantBoarded, 76:PctVacMore6Mos, 77:MedYrHousBuilt, 78:PctHousNoPhone, 79:PctWOFullPlumb, 80:OwnOccLowQuart, 81:OwnOccMedVal, 82:OwnOccHiQuart, 83:RentLowQ, 84:RentMedian, 85:RentHighQ, 86:MedRent, 87:MedRentPctHousInc, 88:MedOwnCostPctInc, 89:MedOwnCostPctIncNoMtg, 90:NumInShelters, 91:NumStreet, 92:PctForeignBorn, 93:PctBornSameState, 94:PctSameHouse85, 95:PctSameCity85, 96:PctSameState85, 97:LandArea, 98:PopDens, 99:PctUsePubTrans, 100:LemasPctOfficDrugUn, "
     ]
    }
   ],
   "source": [
    "feature_names = df.columns[:-1]\n",
    "for i, feature_name in enumerate(feature_names):\n",
    "    print(f'{i}:{feature_name}', end=\", \") \n",
    "blk = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'ViolentCrimesPerPop'\n",
    "df, categorical_features, categorical_labels, target_labels, _ = transform_to_numeric(df, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xd, yd = df.drop(target,axis=1), df[target]\n",
    "X, y = df.drop(target,axis=1).values, df[target].values\n",
    "no_of_classes = len(np.unique(yd))\n",
    "no_of_features = Xd.shape[1]\n",
    "no_of_instances = Xd.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with feature exclusion\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = {base:base, rand:rand, 'race':blk}\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "mondrian_x = {}\n",
    "mondrian_x['uncal'] = {}\n",
    "mondrian_x['median'] = {}\n",
    "mondrian_x['low'] = {}\n",
    "mondrian_x['high'] = {}\n",
    "mondrian_x['width'] = {}\n",
    "mondrian_x['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian_x['uncal'][attr] = []\n",
    "    mondrian_x['median'][attr] = []\n",
    "    mondrian_x['low'][attr] = []\n",
    "    mondrian_x['high'][attr] = []\n",
    "    mondrian_x['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "        \n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=5)\n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian_x['y'].append(y_test)        \n",
    "        \n",
    "        for attr, a in attributes.items():\n",
    "            if attr not in [base, rand]:\n",
    "                x_train = np.delete(X_train, a, axis=1)\n",
    "                x_cal = np.delete(X_cal, a, axis=1)\n",
    "                x_test = np.delete(X_test, a, axis=1)\n",
    "                model = RandomForestRegressor()\n",
    "                model.fit(x_train,y_train)\n",
    "                residuals_cal = model.predict(x_cal) - y_cal\n",
    "                y_test_hat = model.predict(x_test)\n",
    "                \n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian_x['uncal'][attr].append(y_test_hat)\n",
    "            mondrian_x['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian_x['low'][attr].append(values[:,0])\n",
    "            mondrian_x['high'][attr].append(values[:,2])\n",
    "            mondrian_x['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results['CaC']['mondrian_x']['time'] = time() - time_mondrian\n",
    "results['CaC']['mondrian_x']['struct'] = mondrian_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mondrian with all features\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, blk]\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "mondrian = {}\n",
    "mondrian['uncal'] = {}\n",
    "mondrian['median'] = {}\n",
    "mondrian['low'] = {}\n",
    "mondrian['high'] = {}\n",
    "mondrian['width'] = {}\n",
    "mondrian['y'] = []\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    mondrian['uncal'][attr] = []\n",
    "    mondrian['median'][attr] = []\n",
    "    mondrian['low'][attr] = []\n",
    "    mondrian['high'][attr] = []\n",
    "    mondrian['width'][attr] = []\n",
    "\n",
    "time_mondrian = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train,y_train)\n",
    "\n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=5)\n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)    \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        cal_bins = {base: None, rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: None, rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        residuals_cal = model.predict(X_cal) - y_cal\n",
    "        y_test_hat = model.predict(X_test)\n",
    "        mondrian['y'].append(y_test)\n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            cps[attr] = ConformalPredictiveSystem()\n",
    "            cps[attr].fit(residuals_cal, bins=cal_bins[attr])\n",
    "            values = cps[attr].predict(y_test_hat, bins=test_bins[attr], lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "            mondrian['uncal'][attr].append(y_test_hat)\n",
    "            mondrian['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "            mondrian['low'][attr].append(values[:,0])\n",
    "            mondrian['high'][attr].append(values[:,2])\n",
    "            mondrian['width'][attr].append(values[:,2]-values[:,0])\n",
    "\n",
    "results['CaC']['mondrian']['time'] = time() - time_mondrian\n",
    "results['CaC']['mondrian']['struct'] = mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model split based on Mondrian categories\n",
    "\n",
    "base = 'base'\n",
    "rand = 'rand'\n",
    "attributes = [base, rand, blk]\n",
    "attribute_names = [base, rand, 'race']\n",
    "cps = {}\n",
    "model_split = {}\n",
    "model_split['uncal'] = {}\n",
    "model_split['median'] = {}\n",
    "model_split['low'] = {}\n",
    "model_split['high'] = {}\n",
    "model_split['width'] = {}\n",
    "model_split['y'] = {}\n",
    "for attr in attribute_names:\n",
    "    cps[attr] = None\n",
    "    model_split['uncal'][attr] = []\n",
    "    model_split['median'][attr] = []\n",
    "    model_split['low'][attr] = []\n",
    "    model_split['high'][attr] = []\n",
    "    model_split['width'][attr] = []\n",
    "    model_split['y'][attr] = []\n",
    "\n",
    "time_split = time()\n",
    "for l in range(num_rep):\n",
    "    np.random.seed = l\n",
    "    indeces = np.random.permutation(no_of_instances)\n",
    "    X = X[indeces,:]\n",
    "    y = y[indeces]\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train_cal, X_test = X[train_index], X[test_index]\n",
    "        y_train_cal, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        X_train, X_cal, y_train, y_cal = train_test_split(X_train_cal, y_train_cal, test_size=0.3, random_state=42)\n",
    "        \n",
    "        \n",
    "        blk_cal_bin, blk_cal_boundaries = binning(X_cal[:,blk], bins=5)\n",
    "        blk_train_bin = binning(X_train[:,blk], blk_cal_boundaries)  \n",
    "        blk_test_bin = binning(X_test[:,blk], blk_cal_boundaries)  \n",
    "        rand_cal_bin, rand_cal_boundaries = binning(np.random.rand(len(y_cal)), bins=5)\n",
    "        rand_train_bin = binning(np.random.rand(len(y_train)), rand_cal_boundaries)\n",
    "        rand_test_bin = binning(np.random.rand(len(y_test)), rand_cal_boundaries)\n",
    "        train_bins = {base: np.ones(len(y_train)), rand: rand_train_bin, 'race': blk_train_bin}\n",
    "        cal_bins = {base: np.ones(len(y_cal)), rand: rand_cal_bin, 'race': blk_cal_bin}\n",
    "        test_bins = {base: np.ones(len(y_test)), rand: rand_test_bin, 'race': blk_test_bin}\n",
    "        \n",
    "        \n",
    "        for attr in attribute_names:\n",
    "            for bin in np.unique(train_bins[attr]):\n",
    "                X_train_bin = X_train[train_bins[attr] == bin,:]\n",
    "                y_train_bin = y_train[train_bins[attr] == bin]\n",
    "                X_cal_bin = X_cal[cal_bins[attr] == bin,:]\n",
    "                y_cal_bin = y_cal[cal_bins[attr] == bin]\n",
    "                X_test_bin = X_test[test_bins[attr] == bin,:]\n",
    "                y_test_bin = y_test[test_bins[attr] == bin]\n",
    "                \n",
    "                if len(y_train_bin) == 0 or len(y_cal_bin) == 0 or len(y_test_bin) == 0:\n",
    "                    continue\n",
    "                \n",
    "                model = RandomForestRegressor()\n",
    "\n",
    "                model.fit(X_train_bin, y_train_bin)\n",
    "                \n",
    "                residuals_cal = model.predict(X_cal_bin) - y_cal_bin\n",
    "                y_test_bin_hat = model.predict(X_test_bin)\n",
    "            \n",
    "                cps[attr] = ConformalPredictiveSystem()\n",
    "                cps[attr].fit(residuals_cal)\n",
    "                values = cps[attr].predict(y_test_bin_hat, lower_percentiles=[5, 50], higher_percentiles=[95, 50])\n",
    "                model_split['uncal'][attr].append(y_test_bin_hat)\n",
    "                model_split['median'][attr].append(np.mean(values[:,[1, 3]], axis=1))\n",
    "                model_split['low'][attr].append(values[:,0])\n",
    "                model_split['high'][attr].append(values[:,2])\n",
    "                model_split['width'][attr].append(values[:,2]-values[:,0])\n",
    "                model_split['y'][attr].append(y_test_bin)\n",
    "\n",
    "results['CaC']['model_split']['time'] = time() - time_split\n",
    "results['CaC']['model_split']['struct'] = model_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "for attr in attribute_names:\n",
    "    mondrian_x['uncal'][attr] = np.concatenate(mondrian_x['uncal'][attr])\n",
    "    mondrian_x['median'][attr] = np.concatenate(mondrian_x['median'][attr]) \n",
    "    mondrian_x['low'][attr] = np.concatenate(mondrian_x['low'][attr]) \n",
    "    mondrian_x['high'][attr] = np.concatenate(mondrian_x['high'][attr]) \n",
    "    mondrian_x['width'][attr] = np.concatenate(mondrian_x['width'][attr]) \n",
    "    mondrian['uncal'][attr] = np.concatenate(mondrian['uncal'][attr])\n",
    "    mondrian['median'][attr] = np.concatenate(mondrian['median'][attr]) \n",
    "    mondrian['low'][attr] = np.concatenate(mondrian['low'][attr]) \n",
    "    mondrian['high'][attr] = np.concatenate(mondrian['high'][attr]) \n",
    "    mondrian['width'][attr] = np.concatenate(mondrian['width'][attr]) \n",
    "    model_split['uncal'][attr] = np.concatenate(model_split['uncal'][attr])\n",
    "    model_split['median'][attr] = np.concatenate(model_split['median'][attr]) \n",
    "    model_split['low'][attr] = np.concatenate(model_split['low'][attr]) \n",
    "    model_split['high'][attr] = np.concatenate(model_split['high'][attr]) \n",
    "    model_split['width'][attr] = np.concatenate(model_split['width'][attr]) \n",
    "    model_split['y'][attr] = np.concatenate(model_split['y'][attr]) \n",
    "\n",
    "mondrian_x['y'] = np.concatenate(mondrian_x['y']) \n",
    "mondrian['y'] = np.concatenate(mondrian['y']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\n",
      "base width: \t 0.4596 \t 0.4608 \t 0.4692 \n",
      "rand width: \t 0.4904 \t 0.4935 \t 0.5319 \n",
      "race width: \t 0.4301 \t 0.4350 \t 0.4491 \n"
     ]
    }
   ],
   "source": [
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split')\n",
    "for attr in attribute_names:\n",
    "    results['CaC']['mondrian'][attr] = np.mean(mondrian['width'][attr])\n",
    "    results['CaC']['mondrian_x'][attr] = np.mean(mondrian_x['width'][attr])\n",
    "    results['CaC']['model_split'][attr] = np.mean(model_split['width'][attr])\n",
    "    print(f'{attr} width: \\t{np.mean(mondrian_x[\"width\"][attr]): .4f} \\t{np.mean(mondrian[\"width\"][attr]): .4f} \\t{np.mean(model_split[\"width\"][attr]): .4f} ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category\t Mondrian_x\t Mondrian\t Model_split\t UMondrian_x\t UMondrian\t UModel_split\n",
      "base MAE: \t 0.1025 \t 0.1018 \t 0.1027 \t 0.0950 \t 0.0947 \t 0.0952\n",
      "rand MAE: \t 0.1027 \t 0.1019 \t 0.1092 \t 0.0950 \t 0.0947 \t 0.1011\n",
      "race MAE: \t 0.1034 \t 0.1022 \t 0.1048 \t 0.0952 \t 0.0947 \t 0.0969\n",
      "base R2: \t 0.6346 \t 0.6376 \t 0.6333 \t 0.6483 \t 0.6496 \t 0.6469\n",
      "rand R2: \t 0.6332 \t 0.6369 \t 0.5887 \t 0.6483 \t 0.6496 \t 0.6052\n",
      "race R2: \t 0.6298 \t 0.6332 \t 0.6177 \t 0.6479 \t 0.6496 \t 0.6382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, r2_score\n",
    "\n",
    "print('Category\\t Mondrian_x\\t Mondrian\\t Model_split\\t UMondrian_x\\t UMondrian\\t UModel_split')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} MAE: \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')\n",
    "    print(f' \\t{mean_absolute_error(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{mean_absolute_error(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')\n",
    "for attr in attribute_names:\n",
    "    print(f'{attr} R2: \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"median\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"median\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"median\"][attr]): .4f}', end='')    \n",
    "    print(f' \\t{r2_score(mondrian_x[\"y\"], mondrian_x[\"uncal\"][attr]): .4f} \\t{r2_score(mondrian[\"y\"], mondrian[\"uncal\"][attr]): .4f} \\t{r2_score(model_split[\"y\"][attr], model_split[\"uncal\"][attr]): .4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "### Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset\t Mondrian_x\t Mondrian\t Model Split\tType\n",
      "COMPAS\t 351.88\t\t 156.05\t\t 8892.53\t\tclassification\n",
      "adult\t 25967.90\t\t 748.27\t\t 2969.38\t\tclassification\n",
      "german\t 65.61\t\t 29.36\t\t 273.06\t\tclassification\n",
      "boston\t 101.25\t\t 48.64\t\t 204.55\t\tregression\n",
      "CaC\t 2885.50\t\t 1294.56\t\t 10366.43\t\tregression\n"
     ]
    }
   ],
   "source": [
    "categories = ['mondrian_x','mondrian','model_split',]\n",
    "print('Dataset\\t Mondrian_x\\t Mondrian\\t Model Split\\tType')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for category in categories:\n",
    "        print(f'{results[name][category][\"time\"]: 0.2f}\\t\\t', end='')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Width\n",
    "#### Mondrian vs model split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t mondrian_x\t mondrian\t model_split\t\n",
      "Dataset\t base\t\t base\t\t base\t\t rand\t\t rand\t\t rand\t\t race\t\t race\t\t race\t\t sex\t\t sex\t\t sex\t\t age\t\t age\t\t age\t\t edu\t\t edu\t\t edu\t\t crm\t\t crm\t\t crm\t\tType\n",
      "COMPAS\t 0.007\t\t 0.007\t\t 0.007\t\t 0.022\t\t 0.022\t\t 0.020\t\t 0.019\t\t 0.019\t\t 0.018\t\t 0.011\t\t 0.011\t\t 0.011\t\t 0.028\t\t 0.021\t\t 0.021\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\tclassification\n",
      "adult\t 0.003\t\t 0.003\t\t 0.003\t\t 0.010\t\t 0.010\t\t 0.010\t\t 0.007\t\t 0.007\t\t 0.007\t\t 0.005\t\t 0.005\t\t 0.005\t\t -\t\t -\t\t -\t\t 0.016\t\t 0.016\t\t 0.015\t\t -\t\t -\t\t -\t\tclassification\n",
      "german\t 0.044\t\t 0.044\t\t 0.045\t\t 0.127\t\t 0.128\t\t 0.117\t\t -\t\t -\t\t -\t\t 0.100\t\t 0.100\t\t 0.093\t\t 0.125\t\t 0.125\t\t 0.120\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\tclassification\n",
      "boston\t 10.566\t\t 11.003\t\t 10.262\t\t 15.596\t\t 15.896\t\t 18.905\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t 17.946\t\t 18.512\t\t 17.525\t\tregression\n",
      "CaC\t 0.460\t\t 0.461\t\t 0.469\t\t 0.490\t\t 0.493\t\t 0.532\t\t 0.430\t\t 0.435\t\t 0.449\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\t -\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in categories:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in categories:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        for category in categories:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only Mondrian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t mondrian\t\n",
      "Dataset\t base\t\t rand\t\t race\t\t sex\t\t age\t\t edu\t\t crm\t\tType\n",
      "COMPAS\t 0.007\t\t 0.022\t\t 0.019\t\t 0.011\t\t 0.021\t\t -\t\t -\t\tclassification\n",
      "adult\t 0.003\t\t 0.010\t\t 0.007\t\t 0.005\t\t -\t\t 0.016\t\t -\t\tclassification\n",
      "german\t 0.044\t\t 0.128\t\t -\t\t 0.100\t\t 0.125\t\t -\t\t -\t\tclassification\n",
      "boston\t 11.003\t\t 15.896\t\t -\t\t -\t\t -\t\t -\t\t 18.512\t\tregression\n",
      "CaC\t 0.461\t\t 0.493\t\t 0.435\t\t -\t\t -\t\t -\t\t -\t\tregression\n"
     ]
    }
   ],
   "source": [
    "print('', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {category}', end='\\t')\n",
    "print('\\nDataset', end='\\t')\n",
    "for attr in results[name]['mondrian'].keys():\n",
    "    if attr in ['time', 'struct']:\n",
    "        continue\n",
    "    for category in ['mondrian']:\n",
    "        print(f' {attr}', end='\\t\\t')\n",
    "print('Type')\n",
    "for name, type in datasets.items():\n",
    "    print(f'{name}\\t', end='')\n",
    "    for attr in results[name]['mondrian'].keys():\n",
    "        if attr in ['time', 'struct']:\n",
    "            continue\n",
    "        for category in ['mondrian']:\n",
    "            val = results[name][category][attr]\n",
    "            print(f'{val: 0.3f}', end='\\t\\t') if val > 0 else print(' -', end='\\t\\t')\n",
    "    print(f'{type}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../evaluation/results_mondrian.pkl', 'wb') as file:\n",
    "    pickle.dump(results, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ce",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
