{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibrated Explanations for Regression\n",
    "## Demonstrated on the Californa Housing data set\n",
    "\n",
    "Author: Tuwe Löfström (tuwe.lofstrom@ju.se)  \n",
    "Copyright 2023 Tuwe Löfström  \n",
    "License: BSD 3 clause\n",
    "Sources:\n",
    "1. [California Housing data set [kaggle]](https://www.kaggle.com/datasets/camnugent/california-housing-prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import packages, data and train an underlying model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import packages\n",
    "\n",
    "In the examples below, we will be using `NumPy`, `pandas`, `sklearn`, and `crepes`. From `crepes`, we import `ConformalPredictiveSystem` and some helper functions from `crepes.extras`. `CalibratedExplainer` is imported from `calibrated_explanations`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from calibrated_explanations import CalibratedExplainer\n",
    "\n",
    "from crepes import ConformalPredictiveSystem\n",
    "from crepes.extras import DifficultyEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Import data and train a model\n",
    "Let us import the Califronia Housing data set (see sources at the top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataSet = 'housing.csv'\n",
    "delimiter = ';'\n",
    "categorical_labels = {8: {0: 'INLAND', 1: 'NEAR BAY', 2: '<1H OCEAN', 3: 'NEAR OCEAN', 4: 'ISLAND'}}\n",
    "\n",
    "fileName = '../data/reg/' + dataSet\n",
    "df = pd.read_csv(fileName, delimiter=delimiter, dtype=np.float64)\n",
    "target = 'median_house_value'\n",
    "df.dropna(inplace=True)\n",
    "X, y = df.drop(target,axis=1), df[target] \n",
    "feature_names = df.drop(target,axis=1).columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the data set into a training and a test set, and further split the training set into a proper training set and a calibration set. Let us fit a random forest to the proper training set. We also set a random seed to be able to rerun the notebook and get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 1\n",
    "\n",
    "trainCalX, testX, trainCalY, testY = train_test_split(X.values, y.values, test_size=num_to_test, random_state=42)\n",
    "trainX, calX, trainY, calY = train_test_split(trainCalX, trainCalY, test_size=0.33, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, oob_score=True)\n",
    "\n",
    "model.fit(trainX,trainY)  \n",
    "\n",
    "len(trainX), len(calX), len(testX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before extracting an explanation, lets see what the output from a Conformal Predictive System (cps) is for the test instance(s). Three use cases are explored:\n",
    "1. using percentiles to get the lower and upper bounds of an interval.\n",
    "2. using the 50th percentile(s) to get the median prediction which can be used as a calibrated prediction from the underlying model.\n",
    "3. getting the probability of the prediction being below a certain threshold. 250 000 is used as threshold, as it is close to the midpoint in the possible range of prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calY_pred = model.predict(calX)\n",
    "testY_pred = model.predict(testX)\n",
    "\n",
    "cps = ConformalPredictiveSystem()\n",
    "cps.fit(residuals=calY-calY_pred)\n",
    "\n",
    "interval = cps.predict(y_hat=testY_pred, lower_percentiles=[5,50], higher_percentiles=[95,50])\n",
    "\n",
    "p_values = cps.predict(y_hat=testY_pred, y=250000)\n",
    "\n",
    "print('5th percentile, prediction, 50th percentile, 95th percentile, true value, p-value (cpsd<250000)')\n",
    "print(*zip(np.round(interval[:,0], decimals=1), \n",
    "           np.round(testY_pred, decimals=1), \n",
    "           np.round((interval[:,1] + interval[:,3])/2, decimals=1), \n",
    "           np.round(interval[:,2], decimals=1), \n",
    "           np.round(testY,decimals=1), \n",
    "           np.round(p_values*100, decimals=1)),sep='\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the `CalibratedExplainer` by feeding the model, the calibration set, and mode='regression' as a minimum. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CalibratedExplainer(model, \n",
    "                        calX, \n",
    "                        calY, \n",
    "                        feature_names=feature_names, \n",
    "                        categorical_labels=categorical_labels,\n",
    "                        mode='regression')  \n",
    "display(ce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the examples below, all intervals will be with 95% certainty and can be either two-sided or one-sided. The intervals are defined by assigning a pair of values to the `low_high_percentiles` attribute (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsi = (2.5,97.5) # two-sided interval with 95% confidence\n",
    "osli = (5,np.inf) # one-sided lower-bounded interval with 95% confidence\n",
    "osui = (-np.inf,95) # one-sided upper-bounded interval with 95% confidence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-sided interval with 95% confidence\n",
    "When using regular or uncertainty plots, the recommended (and for regression default) `Discretizer` is the `BinaryDiscretizer`. As no discretizer was assigned at initialization, it is already assigned `BinaryDiscretizer`. \n",
    "\n",
    "Since we are defining two-sided intervals, `low_high_percentiles=tsi`.\n",
    "\n",
    "Once the explanations are extracted, we can visualize them using various plots. The regular plot include an uncertainty estimate for the prediction and the weights of the most influential features. The shaded area is the the prediction interval with 95% confidence. The solid line in the middle of the shaded interval is the median in the conformal predictive distribution.\n",
    "\n",
    "Regular plots are shown by calling the function `plot_regular`, with `num_to_show` indicating the number of features to include, in order of importance. To save the plots to disk, `save_ext` can take one or several of the following extensions `['pdf','svg','png']` creating a plot for each instance and file format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce.get_factuals(testX, low_high_percentiles=tsi)\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncertainty plots are similar to regular plots but also provide an uncertainty estimate for the impact of each feature. Here, the shaded area is the range of possible changes with the assigned confidence interval (here a two-sided interval with 95% confidence, as defined above). The solid line in the midle of the shaded interval is the median in the conformal predictive distribution.\n",
    "\n",
    "To get uncertainty plots, the `plot_uncertainty` function can be called with the same parameters as `plot_regular`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_uncertainty(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-sided lower-bounded interval with 95% confidence\n",
    "To change confidence or interval type, new explanations must be extracted. Here `low_high_percentiles=osli` to get a one-sided lower-bounded interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osli)\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-sided upper-bounded interval with 95% confidence\n",
    "Here `low_high_percentiles=osui` to get a one-sided upper-bounded interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osui)\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two-sided counterfactual rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'decile'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, low_high_percentiles=tsi)\n",
    "exp.add_conjunctive_counterfactual_rules(num_to_include=5).plot_counterfactuals(num_to_show=15, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-sided counterfactual rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osli)\n",
    "exp.plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osui)\n",
    "exp.plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized explanations using knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three ways to set the difficulty estimator (sigma) for the CalibratedExplainer when using k-nearest neighbor.\n",
    "* alternative 1: by the (Euclidean) distances to the nearest neighbors\n",
    "* alternative 2: by the standard deviation of the targets of the nearest neighbors\n",
    "* alternative 3: by the absolute errors of the k nearest neighbors\n",
    "\n",
    "See the documentation of crepes for further details on how the `DifficultyEstimator` works, see [here](https://crepes.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative 1: by the (Euclidean) distances to the nearest neighbors\n",
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, scaler=True))\n",
    "\n",
    "# alternative 2: by the standard deviation of the targets of the nearest neighbors\n",
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, y=trainY, scaler=True))\n",
    "\n",
    "# alternative 3: by the absolute errors of the k nearest neighbors\n",
    "oob_predictions = model.oob_prediction_ # requires the model to have been trained with oob_score=True, available for RandomForestRegressor\n",
    "residuals_oob = trainY - oob_predictions\n",
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, residuals=residuals_oob, scaler=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'binary'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, low_high_percentiles=tsi)\n",
    "exp.add_conjunctive_factual_rules(num_to_include=5)\n",
    "exp.plot_regular(num_to_show=15, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_uncertainty(num_to_show=15, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules()\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_uncertainty(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osli)\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osui)\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized counterfactuals using knn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'decile'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, low_high_percentiles=tsi)\n",
    "exp.add_conjunctive_counterfactual_rules(num_to_include=5).plot_counterfactuals(num_to_show=15, save_ext=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osli)\n",
    "exp.plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osui)\n",
    "exp.plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized explanations using variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, learner=model, scaler=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'binary'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, low_high_percentiles=tsi)\n",
    "exp.add_conjunctive_factual_rules(num_to_include=5)\n",
    "exp.plot_regular(num_to_show=15, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_uncertainty(num_to_show=15, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules()\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.plot_uncertainty(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osli)\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osui)\n",
    "exp.plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized counterfactuals using variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'decile'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, low_high_percentiles=tsi)\n",
    "exp.add_conjunctive_counterfactual_rules(num_to_include=5).plot_counterfactuals(num_to_show=15, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osli)\n",
    "exp.plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp = ce(testX, low_high_percentiles=osui)\n",
    "exp.plot_counterfactuals(num_to_show=10, save_ext=[])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "168dd73c7a7b76a0355e35f33a90e68c167b1dbb1e524891be00dd5c7b8524eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
