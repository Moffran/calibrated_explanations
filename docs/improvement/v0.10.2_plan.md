# v0.10.2 Release Task Implementation Plan

This plan expands the v0.10.2 tasks from `docs/improvement/RELEASE_PLAN_v1.md` with
implementation details grounded in ADRs, engineering standards, and the current
code layout. Each section lists concrete work items, impacted modules,
verification steps, and open questions needed to satisfy the release gate.

## Source references reviewed

- Release task list + ADR gap appendix: `docs/improvement/RELEASE_PLAN_v1.md` (v0.10.2 section).
- ADRs: `docs/improvement/adrs/ADR-006-plugin-registry-trust-model.md`,
  `docs/improvement/adrs/ADR-010-core-vs-evaluation-split-and-distribution.md`,
  `docs/improvement/adrs/ADR-013-interval-calibrator-plugin-strategy.md`,
  `docs/improvement/adrs/ADR-015-explanation-plugin.md`,
  `docs/improvement/adrs/ADR-021-calibrated-interval-semantics.md`,
  `docs/improvement/adrs/ADR-026-explanation-plugin-semantics.md`,
  `docs/improvement/adrs/ADR-029-reject-integration-strategy.md`,
  `docs/improvement/adrs/ADR-027-fast-feature-filtering.md`,
  `docs/improvement/adrs/ADR-028-logging-and-governance-observability.md`.
- Standards: `docs/standards/STD-005-logging-and-observability-standard.md`.
- Logging analysis: `docs/improvement/ignore/Logging_Analysis.md`.
- Anti-pattern remediation guidance: `docs/improvement/ANTI_PATTERN_REMEDIATION_PLAN.md`,
  `docs/improvement/PATTERN_1_REMEDIATION_PLAN.md`.
- Packaging/evaluation docs: `pyproject.toml`, `evaluation/README.md`.
- Relevant runtime surfaces:
  - `src/calibrated_explanations/plugins/registry.py`
  - `src/calibrated_explanations/plugins/manager.py`
  - `src/calibrated_explanations/plugins/builtins.py`
  - `src/calibrated_explanations/plugins/intervals.py`
  - `src/calibrated_explanations/core/prediction/orchestrator.py`
  - `src/calibrated_explanations/core/explain/orchestrator.py`
  - `src/calibrated_explanations/explanations/explanations.py`
  - `src/calibrated_explanations/plugins/cli.py`

---

## 1) ADR-006 trust controls and diagnostics

**Goal:** Enforce opt-in trust for third-party plugins, enforce deny lists at
registration/discovery, and provide clear diagnostics + documentation warnings
about the lack of sandboxing.

**Key ADR gaps to close (from ADR-006 appendix):**
- Trust flags in third-party metadata auto-enable plugins.
- `CE_DENY_PLUGIN` not enforced during discovery.
- Untrusted entry-point metadata not surfaced in diagnostics.
- Missing user-facing “no sandbox” warning.

**Implementation steps**
1. **Constrain trust-by-default to in-tree plugins.**
   - Update `src/calibrated_explanations/plugins/registry.py` so `_should_trust(...)`
     only returns `True` for:
     - built-in plugins registered in `_register_builtins()` (explicit flag from
       the registry), and
     - identifiers explicitly trusted via `CE_TRUST_PLUGIN` or `trust_plugin(...)`.
   - Ignore third-party `plugin_meta["trusted"]` unless explicitly allowlisted.
   - Store a `source`/`origin` flag on descriptors (builtins vs. entry points) to
     support this decision in a stable, testable way.

2. **Enforce `CE_DENY_PLUGIN` at discovery and registration.**
   - Gate entry-point loading in `load_entrypoint_plugins(...)` to skip denied
     identifiers and emit a structured warning (or audit log) that includes
     `identifier`, `provider`, and the deny source.
   - Ensure `register_explanation_plugin`, `register_interval_plugin`,
     `register_plot_builder`, and `register_plot_renderer` refuse registration
     when `is_identifier_denied(identifier)` is true.

3. **Add diagnostics for skipped plugins.**
   - Introduce a `PluginDiscoveryReport` or similar structure in
     `plugins/registry.py` that records:
     - skipped_untrusted, skipped_denied, checksum_failures, and accepted.
   - Expose this report via:
     - `ce.plugins list --include-skipped` or a new `ce.plugins report` command.
   - Extend CLI output (in `plugins/cli.py`) to include the reason for a skip.

4. **Document the “no sandbox” warning.**
   - Update the plugin docs (`docs/plugins.md`) or a trust section in
     contributor guidance to clearly state plugins run in-process without
     isolation, per ADR-006.

**Decisions**
- Treat `trusted=True` in third-party metadata as informational only unless the
  plugin is explicitly trusted by the operator.
- Persist a discovery report to make “skipped” states observable without
  requiring debug logs.

**Decisions (resolved)**
1. **Where should explicit trust decisions live?**
   - **Suggestion A:** Environment-only (`CE_TRUST_PLUGIN`).
     - **Pros:** Simple, already documented.
     - **Cons:** Ephemeral and not version-controlled.
   - **Suggestion B:** Add a pyproject allowlist
     (`[tool.calibrated_explanations.plugins] trusted = [...]`).
     - **Pros:** Auditable, versioned, aligns with existing config surfaces.
     - **Cons:** Requires config plumbing and precedence rules.
   - **Suggestion C:** CLI `ce.plugins trust <id>` that writes to config.
     - **Pros:** User-friendly workflow, auditable in repo.
     - **Cons:** Adds persistence UX and config editing complexity.
   - **Decision:** **B**, for auditable, versioned trust decisions.

2. **How should skipped plugin diagnostics be exposed by default?**
   - **Suggestion A:** Always include skipped plugins in `list_plugins()`.
     - **Pros:** Maximum visibility.
     - **Cons:** Noisy for casual users.
   - **Suggestion B:** Gate behind `include_untrusted=True`.
     - **Pros:** Clear opt-in; minimal noise.
     - **Cons:** Easy to miss issues.
   - **Suggestion C:** Include in API with flags; CLI hides unless `--verbose`.
     - **Pros:** Balanced UX; explicit when needed.
     - **Cons:** Requires CLI format changes.
   - **Decision:** **C**, to balance visibility and noise.

**Verification checklist**
- Entry-point plugins never auto-trust solely from metadata.
- Denied plugins are skipped at discovery/registration and appear in CLI diagnostics.
- Docs mention that plugins execute in-process without sandboxing.

---

## 2) ADR-013 protocol compliance for interval plugins

**Goal:** Enforce interval plugin protocol validation, deliver a protocol-compliant
FAST calibrator, freeze interval contexts, add CLI diagnostics, and return frozen
legacy defaults.

**Key ADR gaps to close (from ADR-013 appendix):**
- Interval plugins are not validated against protocol requirements.
- FAST plugin returns lists instead of protocol objects.
- Interval contexts remain mutable.
- Default plugin re-instantiates calibrators rather than returning frozen instances.
- Missing CLI validation helpers.

**Implementation steps**
1. **Add protocol validation to interval resolution.**
   - In `core/prediction/orchestrator.py`, validate the object returned by
     `plugin.create(...)` using `ClassificationIntervalCalibrator` and
     `RegressionIntervalCalibrator` runtime protocols (`plugins/intervals.py`).
   - Add shape/invariant checks using a lightweight probe (single-row call to
     `predict_proba` / `predict_uncertainty` where safe) and surface failures as
     `ConfigurationError` with plugin identifiers.

2. **Replace FAST list returns with a protocol-compliant wrapper.**
   - Introduce a `FastIntervalCalibrator` class (likely in
     `plugins/intervals.py` or a new module) that:
     - wraps the per-feature calibrator list,
     - implements `predict_proba`, `predict_uncertainty`, `predict_probability`,
       and `__getitem__` to preserve the existing per-feature indexing behavior,
     - exposes `.calibrators` as a tuple for introspection.
   - Update `BuiltinFastIntervalCalibratorPlugin.create(...)` in
     `plugins/builtins.py` to return this wrapper instead of a list.
   - Adjust call sites that check for `list` to also accept the wrapper.

3. **Freeze interval contexts and metadata.**
   - In `core/prediction/orchestrator.py`, wrap `bins`, `residuals`, `difficulty`,
     and `metadata` with `MappingProxyType` (or a frozen dataclass) before
     constructing `IntervalCalibratorContext`.
   - Ensure nested lists/tuples are copied (e.g., `bins` arrays) so plugins cannot
     mutate the explainer state indirectly.

4. **Return frozen defaults from the legacy plugin.**
   - Change `LegacyIntervalCalibratorPlugin.create(...)` to reuse the existing
     explainer `interval_learner` (or `context.metadata["calibrator"]`) rather
     than re-instantiating `IntervalRegressor`/`VennAbers`.
   - Cache the resolved calibrator in the interval context metadata to reuse
     across calls without mutation.

5. **Add CLI diagnostics for interval validation.**
   - Extend `plugins/cli.py` with commands such as
     `ce.plugins validate-interval --plugin <id>` and
     `ce.plugins explain-interval --plugin <id>` to:
       - instantiate the plugin,
       - validate protocol conformance,
       - report fast compatibility and dependencies.

**Decisions**
- Use a dedicated wrapper for FAST calibrators to keep protocol compliance and
  compatibility with per-feature indexing.
- Treat protocol validation failures as configuration errors (fail fast before
  explanation execution).

**Decisions (resolved)**
1. **Where should the FAST wrapper live?**
   - **Suggestion A:** `plugins/intervals.py` (near protocol definitions).
     - **Pros:** Central, easy to discover for plugin authors.
     - **Cons:** Adds implementation detail to a protocol module.
   - **Suggestion B:** `plugins/builtins.py` (built-in only).
     - **Pros:** Keeps protocol module minimal.
     - **Cons:** Harder for external plugins to reuse.
   - **Suggestion C:** New module `plugins/interval_wrappers.py`.
     - **Pros:** Clear separation of protocol vs. implementation.
     - **Cons:** Extra file and import surface.
   - **Decision:** **C** for clarity and reuse by external plugins.

2. **How strict should runtime protocol validation be?**
   - **Suggestion A:** Structural checks only (methods exist, is callable).
     - **Pros:** Minimal overhead.
     - **Cons:** Misses shape/invariant errors early.
   - **Suggestion B:** Structural + single-sample shape checks.
     - **Pros:** Catches most errors without large cost.
     - **Cons:** Adds a tiny runtime hit during plugin resolution.
   - **Suggestion C:** Full reference parity checks against legacy outputs.
     - **Pros:** Maximum correctness.
     - **Cons:** Heavy, likely too slow for runtime.
   - **Decision:** **A**, to enforce strict contract safety at the gate.

3. **Should frozen context use deep immutability or a read-only view?**
   - **Suggestion A:** Deep immutability (copy + freeze).
     - **Pros:** Strongest protection against mutation.
     - **Cons:** Higher memory and CPU overhead.
   - **Suggestion B:** Shallow read-only view (`MappingProxyType` only).
     - **Pros:** Low overhead.
     - **Cons:** Underlying mutable references can leak.
   - **Suggestion C:** Hybrid: freeze critical structures only
     (bins, residuals, metadata).
     - **Pros:** Protects core integrity with lower overhead.
     - **Cons:** Requires careful field selection.
   - **Decision:** **C**, balancing protection with performance.

**Verification checklist**
- FAST interval plugin returns a protocol-compliant wrapper.
- Interval contexts are immutable to plugins.
- Legacy interval plugin returns the same calibrator instance on repeat calls.
- CLI can validate interval plugins without running explanations.

---

## 3) ADR-015 explanation plugin integration hardening

**Goal:** Ship an in-tree FAST explanation plugin, rebuild collections with
canonical metadata, tighten trust enforcement, align environment variables, and
expose immutable plugin handles.

**Key ADR gaps to close (from ADR-015 appendix):**
- In-tree FAST plugin missing (fallback path requires external plugin).
- `CalibratedExplanations.from_batch` bypasses canonical reconstruction.
- Trust enforcement during resolution is lax.
- Env var names diverge from ADR expectations.
- Plugins receive mutable explainer handles.

**Implementation steps**
1. **Ensure in-tree FAST explanation plugin is always registered.**
   - Confirm `_register_builtin_fast_plugins()` runs during
     `ensure_builtin_plugins()` and add tests that `core.explanation.fast`
     is available without external extras.
   - Align plugin metadata with ADR-015 (`interval_dependency`,
     `plot_dependency`, capabilities).

2. **Rebuild explanation collections with canonical metadata.**
   - Update `CalibratedExplanations.from_batch` to construct a new container from
     `batch.instances` instead of returning a pre-built container.
   - Preserve metadata from `batch.collection_metadata` (task, interval/plot
     sources, telemetry) and ensure derived attributes (`feature_names`,
     `prediction_interval`, etc.) are populated via the same initialization
     path as legacy collections.

3. **Tighten trust enforcement in explanation resolution.**
   - In `core/explain/orchestrator.py`, enforce trusted-only selection unless
     the caller explicitly passes a plugin override.
   - Emit configuration errors when untrusted plugins are forced by env/pyproject
     without explicit operator trust.

4. **Align environment variables with ADR-015.**
   - Update `plugins/manager.py` to honor
     `CE_EXPLANATION_PLUGIN` and `CE_EXPLANATION_PLUGIN_FAST` as top-level
     defaults, while still supporting mode-specific overrides as fallbacks.
   - Update docs and CLI help strings accordingly.

5. **Provide immutable plugin handles in `ExplanationContext`.**
   - Replace raw explainer handles in `helper_handles` with a read-only wrapper
     exposing a constrained API (e.g., `predict`, `get_metadata`,
     `get_preprocessor_state`).
   - Use `MappingProxyType` for `helper_handles` so plugins cannot mutate shared
     state.

**Decisions**
- Default to strict trust enforcement; explicit overrides may opt into untrusted
  plugins but must log warnings.
- Normalize to ADR-015 environment variable names while preserving backward
  compatibility for mode-specific keys.

**Decisions (resolved)**
1. **Where should the FAST explanation plugin live?**
   - **Suggestion A:** Keep in `plugins/builtins.py`.
     - **Pros:** Co-locates built-ins; consistent with defaults.
     - **Cons:** File grows large; harder to maintain.
   - **Suggestion B:** New `plugins/explanations_fast.py`.
     - **Pros:** Clear separation; easier evolution.
     - **Cons:** Adds a dedicated module.
   - **Suggestion C:** Place in `plugins/explanations.py` alongside protocol.
     - **Pros:** Keeps protocol + reference implementation together.
     - **Cons:** Mixes interface and implementation.
   - **Decision:** **B**, to keep builtins focused and enable expansion.

2. **Should explanation plugin handles include resolved dependencies?**
   - **Suggestion A:** Metadata only.
     - **Pros:** Simple, less coupling.
     - **Cons:** Harder to debug dependency chains.
   - **Suggestion B:** Metadata + resolved dependencies.
     - **Pros:** Better observability and auditability.
     - **Cons:** Exposes dynamic runtime details.
   - **Suggestion C:** Metadata + dependencies only when `debug=True`.
     - **Pros:** Balanced visibility.
     - **Cons:** Adds branching and config complexity.
   - **Decision:** **B**, for auditability and traceability.

**Verification checklist**
- `core.explanation.fast` is always registered and trusted in core installs.
- Explanation collections reconstructed via a canonical, metadata-preserving path.
- Env var resolution honors `CE_EXPLANATION_PLUGIN[_FAST]`.
- Plugins receive read-only handles and cannot mutate explainer state.

---

## 4) ADR-010 optional dependency split + packaging compliance

**Goal:** Make the core install lean, complete extras for viz/eval/notebooks, and
ensure tests/docs respect optional dependencies.

**Key ADR gaps to close (from ADR-010 appendix):**
- Core dependencies still include heavy packages (`ipython`, `lime`, `matplotlib`).
- `[eval]` extra missing packages used in evaluation scripts.
- Visualization tests do not skip when extras are missing.
- Missing evaluation environment lockfile and inaccurate extras docs.
- CONTRIBUTING lacks guidance for extras.

**Implementation steps**
1. **Trim core dependencies.**
   - Remove `ipython`, `lime`, and `matplotlib` from `[project].dependencies` in
     `pyproject.toml` and ensure they live in `viz`, `notebooks`, or `eval`
     extras as appropriate.

2. **Complete extras and lockfiles.**
   - Expand `[project.optional-dependencies].eval` with packages used by
     evaluation scripts (e.g., `xgboost`, `lime`, `seaborn`, any
     `openml`/`imblearn` dependencies discovered in `evaluation/`).
   - Add `evaluation/requirements.txt` or `evaluation/environment.yml` to
     mirror the eval extra, referenced in `evaluation/README.md`.

3. **Auto-skip viz tests when extras are unavailable.**
   - Add a pytest hook in `tests/conftest.py` to skip `@pytest.mark.viz` tests
     when matplotlib is not installed.
   - Ensure docs tests or quickstart tests use `pytest.importorskip` for
     optional visualization components.

4. **Update documentation and contributor guidance.**
   - Update README install matrix and `docs/plugins.md` or contributor guides
     to clarify `core`, `viz`, `notebooks`, `eval`, and `external-plugins` extras.
   - Add a CONTRIBUTING section detailing how to run tests with and without
     extras.

**Decisions**
- Core dependencies should only include libraries required for runtime
  calibrated explanations (numpy/pandas/scikit-learn/crepes/venn-abers/etc.).
- Evaluation assets should have a reproducible requirements file aligned with
  `[eval]` extras.

**Decisions (resolved)**
1. **What is the minimal core dependency set for default install?**
   - **Suggestion A:** Minimal runtime only (numpy, pandas, scikit-learn, crepes,
     venn-abers).
     - **Pros:** Leanest install; aligns with ADR-010.
     - **Cons:** Requires explicit extras for plotting/notebooks.
   - **Suggestion B:** Include matplotlib by default.
     - **Pros:** Plotting works out-of-the-box.
     - **Cons:** Heavy dependency; violates ADR-010.
   - **Suggestion C:** Include ipython but not matplotlib.
     - **Pros:** Helps notebooks with smaller footprint.
     - **Cons:** Inconsistent with lean-core goal.
   - **Decision:** **A**, to keep the core lean and explicit.

2. **What format should the evaluation environment use?**
   - **Suggestion A:** `evaluation/requirements.txt` (pip-first).
     - **Pros:** Simple, aligns with extras and CI.
     - **Cons:** Less expressive for non-pip users.
   - **Suggestion B:** `evaluation/environment.yml` (conda-first).
     - **Pros:** Better for data science workflows.
     - **Cons:** Adds conda dependency management.
   - **Suggestion C:** Provide both with README mapping.
     - **Pros:** Maximum flexibility.
     - **Cons:** Higher maintenance cost.
   - **Decision:** **C** if maintenance budget allows; otherwise **A**.

3. **Should viz tests be skipped or xfailed when matplotlib is missing?**
   - **Suggestion A:** Skip tests with `pytest.importorskip` on collection.
     - **Pros:** Clean output, no failure noise.
     - **Cons:** Might hide issues unless CI installs viz extras.
   - **Suggestion B:** Mark xfail with a clear reason.
     - **Pros:** Visible in test summary.
     - **Cons:** Still counts as failing in strict CI settings.
   - **Suggestion C:** Gate on a `CE_VIZ_TESTS=1` env flag.
     - **Pros:** Explicit opt-in.
     - **Cons:** More configuration complexity.
   - **Decision:** **A**, paired with a viz-enabled CI job.

**Verification checklist**
- Core installation succeeds without `ipython`, `lime`, or `matplotlib`.
- Evaluation instructions install required packages via `[eval]` and lockfile.
- Viz tests are skipped on core-only installs, but still run in viz-enabled CI.

---

## 5) ADR-021/ADR-026 telemetry extensions

**Goal:** Extend runtime telemetry to include FAST probability cubes, interval
dependency hints, and frozen bin metadata in explanation payloads.

**Key ADR gaps to close (from ADR-026 appendix and v0.10.2 tasks):**
- Telemetry omits interval dependency hints in some payloads.
- FAST probability cubes are not surfaced consistently in telemetry.
- Mondrian bin metadata remains mutable rather than frozen in requests.

**Implementation steps**
1. **Surface interval dependency hints in telemetry.**
   - Ensure `core/explain/orchestrator.py` always includes
     `interval_dependencies` in both collection metadata and telemetry payloads
     (including fast mode).
   - Propagate the dependency list into `CalibratedExplanations.telemetry` when
     `from_batch` materializes the collection.

2. **Expose FAST probability cubes.**
   - Ensure `FastExplanation`/`FastExplanationPipeline` propagates
     `__full_probabilities__` in instance payloads.
   - Extend `ExplanationOrchestrator.build_instance_telemetry_payload` to include
     the probability cube (or its shape) in telemetry for FAST mode.

3. **Freeze Mondrian bin metadata in requests.**
   - In `plugins/explanations.py` (ExplanationRequest) and the orchestrator,
     convert `bins` to tuples or immutable structures before passing to plugins
     or recording telemetry.

**Decisions**
- Telemetry should be additive and backward-compatible; avoid removing existing
  fields even if deprecated.
- For large probability cubes, expose a compact representation in telemetry
  (e.g., shape + summary stats) rather than full arrays.

**Decisions (resolved)**
1. **How should probability cube telemetry be represented?**
   - **Suggestion A:** Full arrays in telemetry payloads.
     - **Pros:** Maximum fidelity for diagnostics.
     - **Cons:** Large payloads and serialization costs.
   - **Suggestion B:** Collection metadata + telemetry.
     - **Pros:** Full observability and export alignment.
     - **Cons:** Larger payloads without a size cap.
   - **Suggestion C:** Collection metadata only, telemetry includes shapes.
     - **Pros:** Keeps telemetry light while preserving access.
     - **Cons:** Requires downstream code to know where to look.
   - **Decision:** **B**, to keep analytics and export aligned.

2. **How should frozen bin metadata be represented?**
   - **Suggestion A:** Raw bins arrays.
     - **Pros:** Precise and easy to inspect.
     - **Cons:** Large and expensive to serialize.
   - **Suggestion B:** Hash + summary statistics only.
     - **Pros:** Compact, log-friendly.
     - **Cons:** Harder to debug mismatches.
   - **Suggestion C:** Summary + optional raw bins under a debug flag.
     - **Pros:** Balances size and detail.
     - **Cons:** Adds conditional logic.
   - **Decision:** **C**, for observability without payload bloat.

**Verification checklist**
- `interval_dependencies` appear in collection metadata and telemetry for all
  modes.
- FAST explanation telemetry includes probability cube details.
- Bins and dependency metadata are immutable in plugin contexts.

---

## 6) Anti-Pattern Remediation Phase 3 (private member enforcement)

**Goal:** Enforce zero private member usage in tests through CI/linting to prevent
regressions, per the remediation plan.

**Key remediation gaps to close:**
- Tests still rely on private members (Pattern 1 allowlist remains non-empty).
- CI guard only enforces “no new violations,” not zero usage.

**Implementation steps**
1. **Retain a legacy-only allowlist with explicit expiry.**
   - Keep `.github/private_member_allowlist.json` limited to `legacy/` tests,
     include expiry versions, and fail any new non-legacy private usage in
     `tests/conftest.py`.

2. **Refactor remaining tests to public APIs.**
   - Use `scripts/anti-pattern-analysis/scan_private_usage.py` to locate
     remaining private references.
   - Update tests to use public methods or introduce public helpers where
     necessary (per `PATTERN_1_REMEDIATION_PLAN.md`).

3. **Make CI enforcement unconditional for non-legacy tests.**
   - Remove conditional gating on `GITHUB_ACTIONS` or `CE_FAIL_PRIVATE_TESTS`
     so local runs fail like CI when non-legacy violations are present.

**Decisions**
- Enforce zero private-member access for core/runtime tests by v0.10.2, with a
  legacy-only allowlist that carries explicit expiry versions.

**Open questions**
1. **Should any exceptions be preserved for legacy modules?**
   - **Suggestion A:** No exceptions; refactor all tests to public APIs.
     - **Pros:** Strongest enforcement, consistent policy.
     - **Cons:** Might require new public helper APIs.
   - **Suggestion B:** Allow a small legacy allowlist for `legacy/` modules only.
     - **Pros:** Lower refactor effort.
     - **Cons:** Weakens the "zero usage" guarantee.
   - **Suggestion C:** Introduce sanctioned public testing hooks (e.g.,
     `testing_utils`) instead of private calls.
     - **Pros:** Keeps tests stable without private access.
     - **Cons:** Adds maintenance surface.
   - **Decision:** **B**, with expiry-bound allowlist entries limited to
     `legacy/` tests.

**Verification checklist**
- No private member usage detected across `tests/`.
- CI fails on any new private member usage without allowlist exemptions.

---

## 7) ADR-027 finalization (FAST-based feature filtering)

**Goal:** Complete the implementation of ADR-027 by aligning runtime logging with the observability policy, documenting per-instance ignore masks metadata, and providing performance tuning examples, in a way that is consistent with ADR-028 and Standard-005.

**Key ADR follow-ups to close (ADR-027 + ADR-028/Standard-005 alignment):**
- Runtime logging not aligned with debug-by-default policy.
- Governance vs operational logging domains not consistently applied for feature filter events.
- Per-instance ignore masks metadata not documented.
- No performance tuning examples provided.

**Implementation steps**
1. **Align runtime logging with observability policy and ADR-028.**
   - Update `core.explain._feature_filter` and related logging in `plugins.builtins` to emit at debug level by default, using the appropriate domain logger (`calibrated_explanations.core.*` for operational events).
   - For governance-relevant filter events (for example, strict observability mode decisions that materially change behaviour), emit additional governance logs via `calibrated_explanations.governance.*` where appropriate.
   - Add a strict observability mode config hook (e.g., `CE_STRICT_OBSERVABILITY`) to emit warnings on filter errors or skips, with structured fields populated via the shared logging context helper defined in ADR-028.

2. **Document metadata exposure for per-instance ignore masks.**
   - Update explanation collection docs to describe the best-effort metadata for per-instance masks.
   - Add transparency notes in advanced user guides for debugging filtered explanations.

3. **Provide examples in performance tuning and governance documentation.**
   - Extend `docs/practitioner/performance-tuning.md` (or create if needed) with examples of using feature filtering for large feature spaces, including sample logs that respect Standard-005 (domains, levels, and data minimisation).
   - Include telemetry event examples for `filter_enabled`, `filter_skipped`, and `filter_error`, and show how governance logs from ADR-028 can be routed separately from core runtime logs.

**Decisions**
- Keep filtering experimental and opt-in, with clear documentation on configuration precedence.

**Open questions**
1. **Where to document performance tuning examples?**
   - **Suggestion A:** Extend existing practitioner docs.
     - **Pros:** Keeps tuning info with user-facing guides.
     - **Cons:** Might clutter if not widely used.
   - **Suggestion B:** Add to contributor docs as advanced optimization.
     - **Pros:** Targets advanced users.
     - **Cons:** Less discoverable for practitioners.
   - **Decision:** **A**, to support performance-conscious practitioners.

**Verification checklist**
- Logging emits at debug level by default, with warnings only in strict mode.
- Governance vs core logging domains are correctly applied for feature filter events.
- Documentation includes metadata exposure and tuning examples that follow Standard-005.
- Telemetry events are emitted for filter states.

---

## 8) ADR-028 and Standard-005 enforcement (logging & governance observability)

**Goal:** Apply ADR-028 and Standard-005 to v0.10.2-scope changes so that logging and governance observability are consistent across core, plugins, and governance surfaces touched by this release.

**Key follow-ups to close:**
- Logger usage in core, plugins, and feature-filter paths is not yet aligned with the domain-based hierarchy (`core.*`, `plugins.*`, `telemetry.*`, `governance.*`).
- No shared context helper is wired into v0.10.2 surfaces to propagate explainer/checkpoint/plugin/tenant identifiers into logs.
- Governance-relevant events (e.g. plugin trust/deny, strict observability mode decisions) are not consistently emitted via governance loggers.

**Implementation steps**
1. **Normalize logger domains for v0.10.2-affected modules.**
   - For modules touched by v0.10.2 work items (plugin registry/manager, interval/explanation orchestration, feature filtering, packaging-related governance surfaces), ensure loggers are named under the correct domains per ADR-028 (`calibrated_explanations.core.*`, `calibrated_explanations.plugins.*`, `calibrated_explanations.telemetry.*`, `calibrated_explanations.governance.*`).
   - Replace ad-hoc logger instantiation in these modules with a consistent pattern (`logging.getLogger(__name__)` where the module path already reflects the domain, or explicit domain names otherwise).

2. **Introduce and wire the shared logging context helper.**
   - Implement the shared logging context helper and filter described in ADR-028 (e.g. a small `calibrated_explanations.logging` utility).
   - At minimum, instrument the following entry points in v0.10.2 scope to set context fields (explainer ID, plugin identifier, checkpoint ID where applicable):
     - Plugin resolution/trust paths targeted by ADR-006/ADR-015.
     - Interval orchestration paths targeted by ADR-013.
     - Feature filter and FAST paths targeted by ADR-027.
   - Ensure that governance log records emitted from these paths carry the relevant context via the filter.

3. **Tag governance vs operational events explicitly.**
   - For plugin trust/deny and configuration decisions (ADR-006/ADR-015), emit governance logs under `calibrated_explanations.governance.plugins` (or similar) in addition to any operational logs.
   - For optional-dependency and packaging compliance surfaces where governance is involved (for example, enforcement of core vs extras per ADR-010), emit governance logs when configuration changes or policy decisions are made.

4. **Update documentation and examples.**
   - Update `docs/foundations/governance/optional_telemetry.md` to reference the new logging domains and context helper.
   - Reference Standard-005 and ADR-028 from contributor and practitioner docs where logging examples are shown.

**Verification checklist**
- v0.10.2-touched modules use loggers under the correct `calibrated_explanations.*` domains.
- The shared logging context helper is present and propagates identifiers into logs for core plugin/trust/interval/filter flows.
- Governance-relevant events for v0.10.2 tasks emit logs via `calibrated_explanations.governance.*` with structured fields, and examples in docs conform to Standard-005.

---

## 9) ADR-029 reject integration strategy (documentation and implementation decisions)

**Goal:** Publish and implement the reject integration ADR decisions, capture deferred strategy/visualization questions, and document follow-up alternatives without changing runtime behavior.

**Implementation steps**
1. Ensure ADR-029 reflects the final decisions:
   - A3: Policy Enum for invocation (explicit behavior, flexible integration).
   - C3: structured wrapper/envelope for output integration (reject-aware outputs).
   - B2: internal registry for strategy extensibility.
   - D1: no visualization integration.
2. Record open questions and alternatives for Policies (A3) and strategy extensibility (B2)to make an informed choice.
3. Publish ADR-029 to the `docs/improvement/adrs/` directory with decisions from 2.
4. Develop an implementation plan based on ADR-029 (see below).
5. Implement according to the plan, starting with non-breaking shims that preserve `NONE` semantics.
6. Link ADR-029 from the v0.10.2 release milestone in `RELEASE_PLAN_v1.md`.

**Decisions (resolved for v0.10.2)**
1. Invocation model: **A3 (Policy Enum)**.
2. Output integration: **C3 (Structured Wrapper)**.

**Decisions (sequenced)**
1. Invocation model: adopt A3 (Policy Enum) only but decide on what strategies and policies to expose.
2. Strategy extensibility: adopt B2 (registry) only.
3. Visualization integration: D1 (no visualization integration). No further action is necessary at this point.

**Open questions and alternatives (for follow-up)**
1. **Invocation model**
  - Define `RejectPolicy` enum members and initial semantics. Proposed members:
    - `NONE` (default): no reject integration, preserve legacy behaviour.
    - `PREDICT_AND_FLAG`: always predict; include `rejected` flag in the envelope but do not change explanation production.
    - `EXPLAIN_ALL`: always explain all instances; include reject status.
    - `EXPLAIN_REJECTS`: explain only rejected instances.
    - `EXPLAIN_NON_REJECTS`: explain only non-rejected instances.
    - `SKIP_ON_REJECT`: skip prediction/explanation for rejected instances.
2. **Output integration**
   - Define structure of `RejectResult` envelope.
3. **Strategy extensibility model**
   - **B2:** Registry inside `RejectOrchestrator`.
     - **Pros:** Lightweight; minimal infrastructure.
     - **Cons:** Less alignment with plugin architecture.
   - **Recommendation:** Adopt B2.

**Verification checklist**
- ADR-029 published with updated decisions, dates, and open questions.
- v0.10.2 release plan references ADR-029.

**Implementation plan (v0.10.2 scope)**

- Add `RejectPolicy` enum to `src/calibrated_explanations/core/reject.py` with the initial members above and docstrings describing semantics.
- Implement `RejectResult` envelope dataclass in `src/calibrated_explanations/explanations/reject.py` with fields: `prediction`, `explanation`, `rejected: bool`, `policy: RejectPolicy`, `metadata`.
- Add `RejectOrchestrator` in `src/calibrated_explanations/core/prediction/reject_orchestrator.py` that provides a registry for strategies and an `apply_policy(...)` entry point.
- Wire a `reject_policy: RejectPolicy = RejectPolicy.NONE` parameter into the explanation entrypoints in `core/explain/orchestrator.py` and `core/prediction/orchestrator.py`. When `policy != NONE`, delegate to `RejectOrchestrator` and return a `RejectResult`.
- Wire a `reject_policy: RejectPolicy = RejectPolicy.NONE` parameter into the explanation entrypoints in `core/explain/orchestrator.py` and `core/prediction/orchestrator.py`. When `policy != NONE`, delegate to `RejectOrchestrator` and return a `RejectResult`.
  - Support per-call policy selection (e.g., `explainer.explain(..., reject_policy=...)`) so invocation behavior can vary across calls on the same explainer instance.
  - Support an explainer-level default policy settable in the explainer constructor (e.g., `CalibratedExplainer(..., default_reject_policy=...)`) or (for a `WrapCalibratedExplainer`) via `explainer.calibrate(..., default_reject_policy=...)`. Per-call `reject_policy` should override the explainer-level default.
  - Selecting any non-`NONE` `RejectPolicy` MUST implicitly enable reject orchestration (equivalent to `reject=True`) for the affected call(s) or explainer-level default. This ensures policy-driven invocation always evaluates rejection status even when the legacy `reject` flag is `False`.
- Register a `builtin.default` strategy preserving existing semantics and add tests that assert `NONE` preserves current behaviour.
- Add unit tests for each policy to validate schema and semantics; add a small example notebook demonstrating common policies if scope/time permits.
- Update user docs and release notes to document the policy enum and recommended usage patterns.
- Update user docs and release notes to document per-call vs explainer-level policy configuration, examples for both `CalibratedExplainer` and  `WrapCalibratedExplainer`, and guidance on when to use each pattern.

**Notes**
- Implementation should prioritize non-breaking behavior: when `reject_policy` is omitted or `NONE`, call sites and return types must be identical to current behaviour.

**Future direction (out of scope for v0.10.2)**
- Define registry interfaces (selection, lifecycle hooks, telemetry).
