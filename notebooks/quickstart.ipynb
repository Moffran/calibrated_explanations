{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with calibrated-explanations\n",
    "Author: Tuwe Löfström (tuwe.lofstrom@ju.se)  \n",
    "Copyright 2023 Tuwe Löfström  \n",
    "License: BSD 3 clause\n",
    "## Classification\n",
    "Let us illustrate how we may use `calibrated_explanations` to generate explanations from a classifier trained on a dataset from\n",
    "[www.openml.org](https://www.openml.org), which we first split into a\n",
    "training and a test set using `train_test_split` from\n",
    "[sklearn](https://scikit-learn.org), and then further split the\n",
    "training set into a proper training set and a calibration set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "dataset = fetch_openml(name=\"wine\", version=7, as_frame=True)\n",
    "\n",
    "X = dataset.data.values.astype(float)\n",
    "y = (dataset.target.values == 'True').astype(int)\n",
    "\n",
    "feature_names = dataset.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=2,stratify=y)\n",
    "\n",
    "X_prop_train, X_cal, y_prop_train, y_cal = train_test_split(X_train, y_train,\n",
    "                                                            test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now fit a model on our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "\n",
    "rf.fit(X_prop_train, y_prop_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us explain a test instance using the `CalibratedExplainer` class in `calibrated_explanations`. The method used to get factual explanations is `explain_factual`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calibrated_explanations import CalibratedExplainer, __version__\n",
    "print(__version__)\n",
    "\n",
    "explainer = CalibratedExplainer(rf, X_cal, y_cal, feature_names=feature_names)\n",
    "\n",
    "factual_explanations = explainer.explain_factual(X_test)\n",
    "\n",
    "display(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the explanations, we can plot all of them using `plot_all`. Default, a regular plot, without uncertainty intervals included, is created. To include uncertainty intervals, change the parameter `uncertainty=True`. To plot only a single instance, the `plot_factual` function can be called, submitting the index of the test instance to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_explanations.plot_all()\n",
    "factual_explanations.plot_all(uncertainty=True)\n",
    "\n",
    "factual_explanations.plot_factual(0, uncertainty=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add and remove conjunctive rules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "factual_explanations.add_conjunctive_factual_rules().plot_all()\n",
    "factual_explanations.remove_conjunctive_rules().plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Counterfactual Explanations\n",
    "An alternative to factual rules is to extract counterfactual rules. \n",
    "`explain_counterfactual` can be called to get counterfactual rules with an appropriate discretizer automatically assigned. An alternative is to first change the discretizer to `entropy` (for classification) and then call the `CalibratedExplainer` object as above.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_explanations = explainer.explain_counterfactual(X_test)\n",
    "display(explainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counterfactuals are also visualized using the `plot_all`. Plotting an individual counterfactual explanation is done using `plot_counterfactual`, submitting the index to plot. Adding or removing conjunctions is done as before. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_explanations.plot_all()\n",
    "counterfactual_explanations.add_conjunctive_counterfactual_rules().plot_all()\n",
    "counterfactual_explanations.remove_conjunctive_rules().plot_all()\n",
    "\n",
    "counterfactual_explanations.plot_counterfactual(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`calibrated_explanations` supports multiclass which is demonstrated in [demo_multiclass](https://github.com/Moffran/calibrated_explanations/blob/main/notebooks/demo_multiclass.ipynb). That notebook also demonstrates how both feature names and target and categorical labels can be added to improve the interpretability. \n",
    "## Regression\n",
    "Extracting explanations for regression is very similar to how it is done for classification. First we load and divide the dataset.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_openml(name=\"house_sales\", version=3)\n",
    "\n",
    "X = dataset.data.values.astype(float)\n",
    "y = dataset.target.values\n",
    "\n",
    "feature_names = dataset.feature_names\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1)\n",
    "\n",
    "X_prop_train, X_cal, y_prop_train, y_cal = train_test_split(X_train, y_train,\n",
    "                                                            test_size=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now fit a `RandomForestRegressor` from\n",
    "[sklearn](https://scikit-learn.org) to the proper training\n",
    "set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "rf.fit(X_prop_train, y_prop_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Factual Explanations\n",
    "Define a `CalibratedExplainer` object using the new model and data. The `mode` parameter must be explicitly set to regression. By default, explanations based on a two-sided interval with 90% confidence are provided. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = CalibratedExplainer(rf, X_cal, y_cal, mode='regression', feature_names=feature_names)\n",
    "\n",
    "factual_explanations = explainer.explain_factual(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression also offer both regular and uncertainty plots for factual explanations with or without conjunctive rules, in almost exactly the same way as for classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factual_explanations.plot_all()\n",
    "factual_explanations.plot_all(uncertainty=True)\n",
    "\n",
    "factual_explanations.add_conjunctive_factual_rules().plot_all()\n",
    "factual_explanations.remove_conjunctive_rules().plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `explain_counterfactual` will work exactly the same as for classification. Otherwise, the discretizer must be set explicitly and the 'decile' discretizer is recommended. Counterfactual plots work as for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactual_explanations = explainer.explain_counterfactual(X_test)\n",
    "\n",
    "counterfactual_explanations.plot_all()\n",
    "counterfactual_explanations.add_conjunctive_counterfactual_rules().plot_all()\n",
    "counterfactual_explanations.remove_conjunctive_rules().plot_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression offers many more options but to learn more about them, see the [demo_regression](https://github.com/Moffran/calibrated_explanations/blob/main/notebooks/demo_regression.ipynb) or the [demo_probabilistic_regression](https://github.com/Moffran/calibrated_explanations/blob/main/notebooks/demo_probabilistic_regression.ipynb) notebooks."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e14fe98f360bed4093bab26da9581d5c2feb5ee20210386a1ced5a5e3c396d00"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
