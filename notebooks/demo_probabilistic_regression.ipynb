{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <ins>C</ins>alibrated <ins>E</ins>xplanations for Regression (ce)\n",
    "## Demonstrated on the Californa Housing data set\n",
    "\n",
    "Author: Tuwe Löfström (tuwe.lofstrom@ju.se)  \n",
    "Copyright 2023 Tuwe Löfström  \n",
    "License: BSD 3 clause\n",
    "Sources:\n",
    "1. [California Housing data set [kaggle]](https://www.kaggle.com/datasets/camnugent/california-housing-prices)\n",
    "2. [Calibrated Explanations for Regression [Arxiv]](https://arxiv.org/pdf/....pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Import packages, data and train an underlying model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Import packages\n",
    "\n",
    "In the examples below, we will be using `NumPy`, `pandas`, `sklearn`, and `crepes`. From `crepes`, we import `ConformalPredictiveSystem` and some helper functions from `crepes.extras`. `CalibratedExplainer` is imported from `ce`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from calibrated_explanations import CalibratedExplainer\n",
    "\n",
    "from crepes import ConformalPredictiveSystem\n",
    "from crepes.extras import DifficultyEstimator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Import data and train a model\n",
    "Let us import the Califronia Housing data set (see sources at the top)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "dataSet = 'housing.csv'\n",
    "delimiter = ';'\n",
    "categorical_labels = {8: {0: 'INLAND', 1: 'NEAR BAY', 2: '<1H OCEAN', 3: 'NEAR OCEAN', 4: 'ISLAND'}}\n",
    "\n",
    "fileName = '../data/reg/' + dataSet\n",
    "df = pd.read_csv(fileName, delimiter=delimiter, dtype=np.float64)\n",
    "target = 'median_house_value'\n",
    "df.dropna(inplace=True)\n",
    "X, y = df.drop(target,axis=1), df[target] \n",
    "feature_names = df.drop(target,axis=1).columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the data set into a training and a test set, and further split the training set into a proper training set and a calibration set. Let us fit a random forest to the proper training set. We also set a random seed to be able to rerun the notebook and get the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_test = 1\n",
    "\n",
    "trainCalX, testX, trainCalY, testY = train_test_split(X.values, y.values, test_size=num_to_test, random_state=42)\n",
    "trainX, calX, trainY, calY = train_test_split(trainCalX, trainCalY, test_size=0.33, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, oob_score=True)\n",
    "\n",
    "model.fit(trainX,trainY)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before extracting an explanation, lets see what the output from a Conformal Predictive System (cps) is for the test instances. Three use cases are explored:\n",
    "1. using percentiles to get the lower and upper bounds of an interval.\n",
    "2. using the 50th percentile(s) to get the median prediction which can be used as a calibrated prediction from the underlying model.\n",
    "3. getting the probability of the prediction being below a certain threshold. 250 000 is used as threshold, as it is close to the midpoint in the possible range of prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calY_pred = model.predict(calX)\n",
    "testY_pred = model.predict(testX)\n",
    "\n",
    "cps = ConformalPredictiveSystem()\n",
    "cps.fit(residuals=calY-calY_pred)\n",
    "\n",
    "interval = cps.predict(y_hat=testY_pred, lower_percentiles=[5,50], higher_percentiles=[95,50])\n",
    "\n",
    "p_values = cps.predict(y_hat=testY_pred, y=250000)\n",
    "\n",
    "print('5th percentile, prediction, 50th percentile, 95th percentile, true value, p-value (cpsd<250000)')\n",
    "print(*zip(np.round(interval[:,0], decimals=1), \n",
    "           np.round(testY_pred, decimals=1), \n",
    "           np.round((interval[:,1] + interval[:,3])/2, decimals=1), \n",
    "           np.round(interval[:,2], decimals=1), \n",
    "           np.round(testY,decimals=1), \n",
    "           np.round(p_values*100, decimals=1)),sep='\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CalibratedExplainer(model, \n",
    "                        calX, \n",
    "                        calY, \n",
    "                        feature_names=feature_names, \n",
    "                        categorical_labels=categorical_labels,\n",
    "                        mode='regression')  \n",
    "display(ce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsi = (10,90) # two-sided interval with 80% confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'binary'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, 180000, low_high_percentiles=tsi)\n",
    "\n",
    "exp.add_conjunctive_factual_rules().plot_regular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_regular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'decile'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, 180000, low_high_percentiles=tsi)\n",
    "\n",
    "exp.add_conjunctive_counterfactual_rules().plot_counterfactuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_counterfactuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized explanations using knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three ways to set the difficulty estimator (sigma) for the CalibratedExplainer when using k-nearest neighbor.\n",
    "* alternative 1: by the (Euclidean) distances to the nearest neighbors\n",
    "* alternative 2: by the standard deviation of the targets of the nearest neighbors\n",
    "* alternative 3: by the absolute errors of the k nearest neighbors\n",
    "\n",
    "See the documentation of crepes for further details, see [here](https://crepes.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative 1: by the (Euclidean) distances to the nearest neighbors\n",
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, scaler=True))\n",
    "\n",
    "# alternative 2: by the standard deviation of the targets of the nearest neighbors\n",
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, y=trainY, scaler=True))\n",
    "\n",
    "# alternative 3: by the absolute errors of the k nearest neighbors\n",
    "oob_predictions = model.oob_prediction_ # requires the model to have been trained with oob_score=True, available for RandomForestRegressor\n",
    "residuals_oob = trainY - oob_predictions\n",
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, residuals=residuals_oob, scaler=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'binary'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, 180000, low_high_percentiles=tsi)\n",
    "\n",
    "exp.add_conjunctive_factual_rules(num_to_include=5).plot_regular(num_to_show=15, save_ext=[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized counterfactuals using knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'decile'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, 180000, low_high_percentiles=tsi)\n",
    "\n",
    "exp.add_conjunctive_counterfactual_rules().plot_counterfactuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_counterfactuals()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized explanations using variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce.set_difficultyEstimator(DifficultyEstimator().fit(X=trainX, learner=model, scaler=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'binary'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, 180000, low_high_percentiles=tsi)\n",
    "\n",
    "exp.add_conjunctive_factual_rules().plot_regular()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_regular(num_to_show=10, save_ext=[])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalized counterfactuals using variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discretizer = 'decile'\n",
    "ce.set_discretizer(discretizer)\n",
    "exp = ce(testX, 180000, low_high_percentiles=tsi)\n",
    "\n",
    "exp.add_conjunctive_counterfactual_rules().plot_counterfactuals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp.remove_conjunctive_rules().plot_counterfactuals()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "168dd73c7a7b76a0355e35f33a90e68c167b1dbb1e524891be00dd5c7b8524eb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
