{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from calibrated_explanations import CalibratedExplainer\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from lime.lime_tabular import LimeTabularExplainer\n",
    "from shap import Explainer\n",
    "from VennAbers import VennAbers\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataSet = 'pc1req'\n",
    "delimiter = ';'\n",
    "num_to_test = 4\n",
    "model = 'xGB'\n",
    "print(dataSet)\n",
    "\n",
    "fileName = '../data/' + dataSet + \".csv\"\n",
    "df = pd.read_csv(fileName, delimiter=delimiter, dtype=np.float64)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'Y'\n",
    "X, y = df.drop(target,axis=1), df[target] \n",
    "no_of_classes = len(np.unique(y))\n",
    "no_of_features = X.shape[1]\n",
    "no_of_instances = X.shape[0]\n",
    "categorical_features = [i for i in range(no_of_features) if len(np.unique(X.iloc[:,i])) < 10]\n",
    "# # sort targets to make sure equal presence of both classes in test set (see definition of test_index after outer loop below)\n",
    "idx = np.argsort(y.values).astype(int)\n",
    "X, y = X.values[idx,:], y.values[idx]\n",
    "# Select num_to_test/2 from top and num_to_test/2 from bottom of list of instances\n",
    "test_index = np.array([*range(int(num_to_test/2)), *range(no_of_instances-1, no_of_instances-int(num_to_test/2)-1,-1)])\n",
    "train_index = np.setdiff1d(np.array(range(no_of_instances)), test_index)   \n",
    "trainCalX, testX = X[train_index,:], X[test_index,:]\n",
    "trainCalY, testY = y[train_index], y[test_index]\n",
    "trainX, calX, trainY, calY = train_test_split(trainCalX, trainCalY, test_size=0.33,random_state=42, stratify=trainCalY)\n",
    "print(testY)\n",
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = DecisionTreeClassifier()\n",
    "r1 = RandomForestClassifier(n_estimators=100)\n",
    "g1 = xgb.XGBClassifier(objective='binary:logistic', use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "model_dict = {'xGB':(g1,\"xGB\"),'RF':(r1,\"RF\"),'DT': (t1,\"DT\")}\n",
    "model, model_name = model_dict[model] \n",
    "model.fit(trainX,trainY)  \n",
    "\n",
    "va = VennAbers(calX, calY, model)\n",
    "va_preds = va.predict(testX)\n",
    "va_proba, low, high = va.predict_proba(testX, output_interval=True)\n",
    "print(*zip(low, va_proba[:,1],high, va_preds,testY),sep='\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce = CalibratedExplainer(model, copy.deepcopy(calX), copy.deepcopy(calY), \\\n",
    "                    feature_names=df.columns, \\\n",
    "                    categorical_features=categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for num_neighbors in [1.0]:\n",
    "    ce.set_num_neighbors(num_neighbors)\n",
    "    discretizer = 'entropy'\n",
    "    ce.set_discretizer(discretizer)\n",
    "    tic = time.time()\n",
    "    exp = ce(copy.deepcopy(testX))\n",
    "    toc = time.time()\n",
    "    print(toc-tic)\n",
    "    exp.plot_counterfactuals(title=dataSet + ' ' + str(num_neighbors) + ' counterfactuals ' + discretizer, num_to_show=10)\n",
    "\n",
    "    discretizer = 'binaryEntropy'\n",
    "    ce.set_discretizer(discretizer)\n",
    "    exp = ce(copy.deepcopy(testX))\n",
    "    exp.plot_uncertainty(title=dataSet + ' ' + str(num_neighbors) + ' uncertainty ' + discretizer, num_to_show=10)\n",
    "    exp.plot_regular(title=dataSet + ' ' + str(num_neighbors) + ' regular ' + discretizer, num_to_show=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Running the exp 20 times and saving the results\n",
    "\n",
    "reg = []\n",
    "l = []\n",
    "h = []\n",
    "\n",
    "stability = {'predict':[],'low':[],'high':[]} #Create the structure stability with three lists for each of the different values for each iteration\n",
    "\n",
    "for i in range (20):\n",
    "    ce.set_random_state(i)\n",
    "    exp = ce(copy.deepcopy(testX))\n",
    "    stability['predict'].append(exp.feature_weights['predict'][1][:])\n",
    "    stability['low'].append(exp.feature_weights['low'][1][:])\n",
    "    stability['high'].append(exp.feature_weights['high'][1][:])\n",
    "    # print(stability['regularized'][i][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(np.array(stability['predict'][0]))\n",
    "print(*zip(np.array(stability['predict']).min(axis=0,),np.array(stability['predict']).max(axis=0,)),sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_as_lime = exp.as_lime()\n",
    "for e in ce_as_lime:\n",
    "    e.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_lime=False\n",
    "if run_lime:    \n",
    "    lime = LimeTabularExplainer(calX,training_labels=calY, feature_names=df.columns, class_names=['0','1'], mode='classification',discretizer='binaryEntropy')\n",
    "    lime_weights = []\n",
    "    for x in testX:\n",
    "        exp = lime.explain_instance(x, va.predict_proba, num_features=no_of_features)\n",
    "        exp.show_in_notebook(show_table=True, show_all=False)\n",
    "        feature_order = [exp.local_exp[1][f][0] for f in range(no_of_features)]\n",
    "        lime_values = np.zeros(no_of_features)\n",
    "        for i, f in enumerate(feature_order):\n",
    "            lime_values[f] = exp.local_exp[1][i][1]\n",
    "        lime_weights.append([exp.local_exp[1][exp.local_exp[1][f][0]][1] for f in range(no_of_features)])\n",
    "    print(lime_weights, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_as_shap = exp.as_shap_values()\n",
    "\n",
    "from shap.plots import waterfall, force, scatter, heatmap, bar, violin, beeswarm\n",
    "beeswarm(ce_as_shap)\n",
    "heatmap(ce_as_shap)\n",
    "bar(ce_as_shap)\n",
    "for e in ce_as_shap:\n",
    "    e.feature_names = ce_as_shap.feature_names\n",
    "    waterfall(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: va.predict_proba(x)[:,1]\n",
    "shap = Explainer(f, calX, feature_names=df.columns)\n",
    "shap_exp = shap(testX)\n",
    "from shap.plots import waterfall, force, scatter, heatmap, bar, violin, beeswarm\n",
    "beeswarm(shap_exp)\n",
    "heatmap(shap_exp)\n",
    "bar(shap_exp)\n",
    "for e in shap_exp:\n",
    "    waterfall(e)\n",
    "scatter(shap_exp)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
